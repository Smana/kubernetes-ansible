## roles/adduser/defaults/main.yml <==
---
kube_owner: kube
kube_cert_group: kube-cert
etcd_data_dir: "/var/lib/etcd"

addusers:
  etcd:
    name: etcd
    comment: "Etcd user"
    create_home: false
    system: true
    shell: /sbin/nologin
  kube:
    name: kube
    comment: "Kubernetes user"
    create_home: false
    system: true
    shell: /sbin/nologin
    group: "{{ kube_cert_group }}"

adduser:
  name: "{{ user.name }}"
  group: "{{ user.name | default(None) }}"
  comment: "{{ user.comment | default(None) }}"
  shell: "{{ user.shell | default(None) }}"
  system: "{{ user.system | default(None) }}"
  create_home: "{{ user.create_home | default(None) }}"

## roles/bastion-ssh-config/defaults/main.yml <==
---
ssh_bastion_confing__name: ssh-bastion.conf

## roles/bootstrap-os/defaults/main.yml <==
---
## CentOS/RHEL/AlmaLinux specific variables
# Use the fastestmirror yum plugin
centos_fastestmirror_enabled: false

## Flatcar Container Linux specific variables
# Disable locksmithd or leave it in its current state
coreos_locksmithd_disable: false

## Oracle Linux specific variables
# Install public repo on Oracle Linux
use_oracle_public_repo: true

## Ubuntu specific variables
# Disable unattended-upgrades for Linux kernel and all packages start with linux- on Ubuntu
ubuntu_kernel_unattended_upgrades_disabled: false

fedora_coreos_packages:
  - python
  - python3-libselinux
  - ethtool                 # required in kubeadm preflight phase for verifying the environment
  - ipset                   # required in kubeadm preflight phase for verifying the environment
  - conntrack-tools         # required by kube-proxy
  - containernetworking-plugins  # required by crio

## General
# Set the hostname to inventory_hostname
override_system_hostname: true

is_fedora_coreos: false

skip_http_proxy_on_os_packages: false

# If this is true, debug information will be displayed but
# may contain some private data, so it is recommended to set it to false
# in the production environment.
unsafe_show_logs: false

## roles/container-engine/containerd-common/defaults/main.yml <==
---
# We keep these variables around to allow migration from package
# manager controlled installs to direct download ones.
containerd_package: 'containerd.io'
yum_repo_dir: /etc/yum.repos.d

# Keep minimal repo information around for cleanup
containerd_repo_info:
  repos:

# Ubuntu docker-ce repo
containerd_ubuntu_repo_base_url: "https://download.docker.com/linux/ubuntu"
containerd_ubuntu_repo_component: "stable"

# Debian docker-ce repo
containerd_debian_repo_base_url: "https://download.docker.com/linux/debian"
containerd_debian_repo_component: "stable"

## roles/container-engine/containerd/defaults/main.yml <==
---
containerd_storage_dir: "/var/lib/containerd"
containerd_state_dir: "/run/containerd"
containerd_systemd_dir: "/etc/systemd/system/containerd.service.d"
# The default value is not -999 here because containerd's oom_score_adj has been
# set to the -999 even if containerd_oom_score is 0.
# Ref: https://github.com/kubernetes-sigs/kubespray/pull/9275#issuecomment-1246499242
containerd_oom_score: 0

containerd_default_runtime: "runc"
containerd_snapshotter: "overlayfs"

containerd_runc_runtime:
  name: runc
  type: "io.containerd.runc.v2"
  engine: ""
  root: ""
  base_runtime_spec: cri-base.json
  options:
    systemdCgroup: "{{ containerd_use_systemd_cgroup | ternary('true', 'false') }}"
    binaryName: "{{ bin_dir }}/runc"

containerd_additional_runtimes: []
# Example for Kata Containers as additional runtime:
#  - name: kata
#    type: "io.containerd.kata.v2"
#    engine: ""
#    root: ""

containerd_base_runtime_spec_rlimit_nofile: 65535

containerd_default_base_runtime_spec_patch:
  process:
    rlimits:
      - type: RLIMIT_NOFILE
        hard: "{{ containerd_base_runtime_spec_rlimit_nofile }}"
        soft: "{{ containerd_base_runtime_spec_rlimit_nofile }}"

# Can help reduce disk usage
# https://github.com/containerd/containerd/discussions/6295
containerd_discard_unpacked_layers: true

containerd_base_runtime_specs:
  cri-base.json: "{{ containerd_default_base_runtime_spec | combine(containerd_default_base_runtime_spec_patch, recursive=1) }}"

containerd_grpc_max_recv_message_size: 16777216
containerd_grpc_max_send_message_size: 16777216

containerd_debug_address: ""
containerd_debug_level: "info"
containerd_debug_format: ""
containerd_debug_uid: 0
containerd_debug_gid: 0

containerd_metrics_address: ""

containerd_metrics_grpc_histogram: false

containerd_registries_mirrors:
  - prefix: docker.io
    mirrors:
      - host: https://registry-1.docker.io
        capabilities: ["pull", "resolve"]
        skip_verify: false
#        ca: ["/etc/certs/mirror.pem"]
#        client: [["/etc/certs/client.pem", ""],["/etc/certs/client.cert", "/etc/certs/client.key"]]

containerd_max_container_log_line_size: 16384

# If enabled it will allow non root users to use port numbers <1024
containerd_enable_unprivileged_ports: false
# If enabled it will allow non root users to use icmp sockets
containerd_enable_unprivileged_icmp: false

containerd_enable_selinux: false
containerd_disable_apparmor: false
containerd_tolerate_missing_hugetlb_controller: true
containerd_disable_hugetlb_controller: true
containerd_image_pull_progress_timeout: 5m

containerd_cfg_dir: /etc/containerd

# Extra config to be put in {{ containerd_cfg_dir }}/config.toml literally
containerd_extra_args: ''

# Configure registry auth (if applicable to secure/insecure registries)
containerd_registry_auth: []
#  - registry: 10.0.0.2:5000
#    username: user
#    password: pass

# Configure containerd service
containerd_limit_proc_num: "infinity"
containerd_limit_core: "infinity"
containerd_limit_open_file_num: "infinity"
containerd_limit_mem_lock: "infinity"

# OS distributions that already support containerd
containerd_supported_distributions:
  - "CentOS"
  - "OracleLinux"
  - "RedHat"
  - "Ubuntu"
  - "Debian"
  - "Fedora"
  - "AlmaLinux"
  - "Rocky"
  - "Amazon"
  - "Flatcar"
  - "Flatcar Container Linux by Kinvolk"
  - "Suse"
  - "openSUSE Leap"
  - "openSUSE Tumbleweed"
  - "Kylin Linux Advanced Server"
  - "UnionTech"
  - "UniontechOS"
  - "openEuler"

# Enable container device interface
enable_cdi: false

# For containerd tracing configuration please check out the official documentation:
# https://github.com/containerd/containerd/blob/main/docs/tracing.md
containerd_tracing_enabled: false
containerd_tracing_endpoint: "0.0.0.0:4317"
containerd_tracing_protocol: "grpc"
containerd_tracing_sampling_ratio: 1.0
containerd_tracing_service_name: "containerd"

## roles/container-engine/cri-dockerd/defaults/main.yml <==
---
# Default is "info" (like if not provided). Possible values are any log level string parseable by logrus
cri_dockerd_log_level: "info"

## roles/container-engine/cri-o/defaults/main.yml <==
---

crio_cgroup_manager: "{{ kubelet_cgroup_driver | default('systemd') }}"
crio_conmon: "{{ bin_dir }}/conmon"
crio_default_runtime: "crun"
crio_libexec_dir: "/usr/libexec/crio"
crio_enable_metrics: false
crio_log_level: "info"
crio_metrics_port: "9090"
crio_pause_image: "{{ pod_infra_image_repo }}:{{ pod_infra_version }}"

# Registries defined within cri-o.
# By default unqualified images are not allowed for security reasons
crio_registries: []
#  - prefix: docker.io
#    insecure: false
#    blocked: false
#    location: registry-1.docker.io ## REQUIRED
#    unqualified: false
#    mirrors:
#      - location: 172.20.100.52:5000
#        insecure: true
#      - location: mirror.gcr.io
#        insecure: false

crio_registry_auth: []
#  - registry: 10.0.0.2:5000
#    username: user
#    password: pass

crio_seccomp_profile: ""
crio_selinux: "{{ (preinstall_selinux_state == 'enforcing') | lower }}"
crio_signature_policy: "{% if ansible_os_family == 'ClearLinux' %}/usr/share/defaults/crio/policy.json{% endif %}"

# Override system default for storage driver
# crio_storage_driver: "overlay"

crio_stream_port: "10010"

crio_required_version: "{{ kube_version | regex_replace('^v(?P<major>\\d+).(?P<minor>\\d+).(?P<patch>\\d+)$', '\\g<major>.\\g<minor>') }}"

crio_root: "/var/lib/containers/storage"

# The crio_runtimes variable defines a list of OCI compatible runtimes.
crio_runtimes:
  - name: crun
    path: "{{ crio_runtime_bin_dir }}/crun"
    type: oci
    root: /run/crun

# Kata Containers is an OCI runtime, where containers are run inside lightweight
# VMs. Kata provides additional isolation towards the host, minimizing the host attack
# surface and mitigating the consequences of containers breakout.
kata_runtimes:
  # Kata Containers with the default configured VMM
  - name: kata-qemu
    path: /usr/local/bin/containerd-shim-kata-qemu-v2
    type: vm
    root: /run/kata-containers
    privileged_without_host_devices: true

runc_runtime:
  name: runc
  path: "{{ crio_runtime_bin_dir }}/runc"
  type: oci
  root: /run/runc

# crun is a fast and low-memory footprint OCI Container Runtime fully written in C.
crun_runtime:
  name: crun
  path: "{{ crio_runtime_bin_dir }}/crun"
  type: oci
  root: /run/crun

# youki is an implementation of the OCI runtime-spec in Rust, similar to runc.
youki_runtime:
  name: youki
  path: "{{ youki_bin_dir }}/youki"
  type: oci
  root: /run/youki

# Reserve 16M uids and gids for user namespaces (256 pods * 65536 uids/gids)
# at the end of the uid/gid space
crio_remap_enable: false
crio_remap_user: containers
crio_subuid_start: 2130706432
crio_subuid_length: 16777216
crio_subgid_start: 2130706432
crio_subgid_length: 16777216

# cri-o manual files
crio_man_files:
  5:
    - crio.conf
    - crio.conf.d
  8:
    - crio
    - crio-status

# If set to true, it will enable the CRIU support in cri-o
crio_criu_support_enabled: false

## roles/container-engine/docker/defaults/main.yml <==
---
docker_version: '26.1'
docker_cli_version: "{{ docker_version }}"

docker_package_info:
  pkgs:

# Path where to store repo key
# docker_repo_key_keyring: /etc/apt/trusted.gpg.d/docker.gpg

docker_repo_key_info:
  repo_keys:

docker_repo_info:
  repos:

docker_cgroup_driver: systemd

docker_bin_dir: "/usr/bin"

# flag to enable/disable docker cleanup
docker_orphan_clean_up: false

# old docker package names to be removed
docker_remove_packages_yum:
  - docker
  - docker-common
  - docker-engine
  - docker-selinux.noarch
  - docker-client
  - docker-client-latest
  - docker-latest
  - docker-latest-logrotate
  - docker-logrotate
  - docker-engine-selinux.noarch

# remove podman to avoid containerd.io confliction
podman_remove_packages_yum:
  - podman

docker_remove_packages_apt:
  - docker
  - docker-engine
  - docker.io

# Docker specific repos should be part of the docker role not containerd-common anymore
# Optional values for containerd apt repo
containerd_package_info:
  pkgs:

# Fedora docker-ce repo
docker_fedora_repo_base_url: 'https://download.docker.com/linux/fedora/{{ ansible_distribution_major_version }}/$basearch/stable'
docker_fedora_repo_gpgkey: 'https://download.docker.com/linux/fedora/gpg'

# CentOS/RedHat docker-ce repo
docker_rh_repo_base_url: 'https://download.docker.com/linux/centos/{{ ansible_distribution_major_version }}/$basearch/stable'
docker_rh_repo_gpgkey: 'https://download.docker.com/linux/centos/gpg'

# Ubuntu docker-ce repo
docker_ubuntu_repo_base_url: "https://download.docker.com/linux/ubuntu"
docker_ubuntu_repo_gpgkey: 'https://download.docker.com/linux/ubuntu/gpg'
docker_ubuntu_repo_repokey: '9DC858229FC7DD38854AE2D88D81803C0EBFCD88'

# Debian docker-ce repo
docker_debian_repo_base_url: "https://download.docker.com/linux/debian"
docker_debian_repo_gpgkey: 'https://download.docker.com/linux/debian/gpg'
docker_debian_repo_repokey: '9DC858229FC7DD38854AE2D88D81803C0EBFCD88'

## roles/container-engine/kata-containers/defaults/main.yml <==
---
kata_containers_dir: /opt/kata
kata_containers_config_dir: /etc/kata-containers
kata_containers_containerd_bin_dir: /usr/local/bin

kata_containers_qemu_default_memory: "{{ ansible_memtotal_mb }}"
kata_containers_qemu_debug: 'false'
kata_containers_qemu_sandbox_cgroup_only: 'true'
kata_containers_qemu_enable_mem_prealloc: 'false'
kata_containers_virtio_fs_cache: 'always'

## roles/container-engine/runc/defaults/main.yml <==
---

runc_bin_dir: "{{ bin_dir }}"

runc_package_name: runc

## roles/container-engine/youki/defaults/main.yml <==
---

youki_bin_dir: "{{ bin_dir }}"

## roles/etcd/defaults/main.yml <==
---
# Set etcd user
etcd_owner: etcd

# Set to false to only do certificate management
etcd_cluster_setup: true
etcd_events_cluster_setup: false

# Set to true to separate k8s events to a different etcd cluster
etcd_events_cluster_enabled: false

etcd_backup_prefix: "/var/backups"
etcd_data_dir: "/var/lib/etcd"

# Number of etcd backups to retain. Set to a value < 0 to retain all backups
etcd_backup_retention_count: -1

force_etcd_cert_refresh: true
etcd_config_dir: /etc/ssl/etcd
etcd_cert_dir: "{{ etcd_config_dir }}/ssl"
etcd_cert_dir_mode: "0700"
etcd_cert_group: root
# Note: This does not set up DNS entries. It simply adds the following DNS
# entries to the certificate
etcd_cert_alt_names:
  - "etcd.kube-system.svc.{{ dns_domain }}"
  - "etcd.kube-system.svc"
  - "etcd.kube-system"
  - "etcd"
etcd_cert_alt_ips: []

etcd_script_dir: "{{ bin_dir }}/etcd-scripts"

etcd_heartbeat_interval: "250"
etcd_election_timeout: "5000"

# etcd_snapshot_count: "10000"

etcd_metrics: "basic"

# Define in inventory to set a separate port for etcd to expose metrics on
# etcd_metrics_port: 2381

## A dictionary of extra environment variables to add to etcd.env, formatted like:
##  etcd_extra_vars:
##    ETCD_VAR1: "value1"
##    ETCD_VAR2: "value2"
etcd_extra_vars: {}

# Limits
# Limit memory only if <4GB memory on host. 0=unlimited
# This value is only relevant when deploying etcd with `etcd_deployment_type: docker`
etcd_memory_limit: "{% if ansible_memtotal_mb < 4096 %}512M{% else %}0{% endif %}"

# The default storage size limit is 2G.
# 8G is a suggested maximum size for normal environments and etcd warns at startup if the configured value exceeds it.
# etcd_quota_backend_bytes: "2147483648"

# Maximum client request size in bytes the server will accept.
# etcd is designed to handle small key value pairs typical for metadata.
# Larger requests will work, but may increase the latency of other requests
# etcd_max_request_bytes: "1572864"

# Uncomment to set CPU share for etcd
# etcd_cpu_limit: 300m

etcd_blkio_weight: 1000

etcd_node_cert_hosts: "{{ groups['k8s_cluster'] }}"

etcd_compaction_retention: "8"

# Force clients like etcdctl to use TLS certs (different than peer security)
etcd_secure_client: true

# Enable peer client cert authentication
etcd_peer_client_auth: true

# Maximum number of snapshot files to retain (0 is unlimited)
# etcd_max_snapshots: 5

# Maximum number of wal files to retain (0 is unlimited)
# etcd_max_wals: 5

# Number of loop retries
etcd_retries: 4

## Support tls cipher suites.
# etcd_tls_cipher_suites: {}
#   - TLS_RSA_WITH_RC4_128_SHA
#   - TLS_RSA_WITH_3DES_EDE_CBC_SHA
#   - TLS_RSA_WITH_AES_128_CBC_SHA
#   - TLS_RSA_WITH_AES_256_CBC_SHA
#   - TLS_RSA_WITH_AES_128_CBC_SHA256
#   - TLS_RSA_WITH_AES_128_GCM_SHA256
#   - TLS_RSA_WITH_AES_256_GCM_SHA384
#   - TLS_ECDHE_ECDSA_WITH_RC4_128_SHA
#   - TLS_ECDHE_ECDSA_WITH_AES_128_CBC_SHA
#   - TLS_ECDHE_ECDSA_WITH_AES_256_CBC_SHA
#   - TLS_ECDHE_RSA_WITH_RC4_128_SHA
#   - TLS_ECDHE_RSA_WITH_3DES_EDE_CBC_SHA
#   - TLS_ECDHE_RSA_WITH_AES_128_CBC_SHA
#   - TLS_ECDHE_RSA_WITH_AES_256_CBC_SHA
#   - TLS_ECDHE_ECDSA_WITH_AES_128_CBC_SHA256
#   - TLS_ECDHE_RSA_WITH_AES_128_CBC_SHA256
#   - TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256
#   - TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256
#   - TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384
#   - TLS_ECDHE_ECDSA_WITH_AES_256_GCM_SHA384
#   - TLS_ECDHE_RSA_WITH_CHACHA20_POLY1305_SHA256
#   - TLS_ECDHE_ECDSA_WITH_CHACHA20_POLY1305_SHA256

# ETCD 3.5.x issue
# https://groups.google.com/a/kubernetes.io/g/dev/c/B7gJs88XtQc/m/rSgNOzV2BwAJ?utm_medium=email&utm_source=footer
etcd_experimental_initial_corrupt_check: true

# If this is true, debug information will be displayed but
# may contain some private data, so it is recommended to set it to false
# in the production environment.
unsafe_show_logs: false

# Enable distributed tracing
# https://etcd.io/docs/v3.5/op-guide/monitoring/#distributed-tracing
etcd_experimental_enable_distributed_tracing: false
etcd_experimental_distributed_tracing_sample_rate: 100
etcd_experimental_distributed_tracing_address: "localhost:4317"
etcd_experimental_distributed_tracing_service_name: etcd

# The interval for etcd watch progress notify events
etcd_experimental_watch_progress_notify_interval: 5s

## roles/kubernetes-apps/ansible/defaults/main.yml <==
---
# Limits for coredns

# uncomment the line below to customize the DNS cpu limit value
# dns_cpu_limit: 300m
dns_memory_limit: 300Mi
dns_cpu_requests: 100m
dns_memory_requests: 70Mi
dns_min_replicas: "{{ [2, groups['k8s_cluster'] | length] | min }}"
dns_nodes_per_replica: 16
dns_cores_per_replica: 256
dns_prevent_single_point_failure: "{{ 'true' if dns_min_replicas | int > 1 else 'false' }}"
enable_coredns_reverse_dns_lookups: true
coredns_ordinal_suffix: ""
# dns_extra_tolerations: [{effect: NoSchedule, operator: "Exists"}]
coredns_deployment_nodeselector: "kubernetes.io/os: linux"
coredns_default_zone_cache_block: |
  cache 30

coredns_pod_disruption_budget: false
# value for coredns pdb
coredns_pod_disruption_budget_max_unavailable: "30%"

# coredns_additional_configs adds any extra configuration to coredns
# coredns_additional_configs: |
#   whoami
#   local

# coredns_rewrite_block: |
#   rewrite stop {
#     name regex (.*)\.my\.domain {1}.svc.cluster.local
#     answer name (.*)\.svc\.cluster\.local {1}.my.domain
#   }

# coredns_additional_error_config: |
#   consolidate 5m ".* i/o timeout$" warning

# Configure coredns and nodelocaldns to correctly answer DNS queries when you changed
# your 'dns_domain' and some workloads used it directly.
old_dns_domains: []

# dns_upstream_forward_extra_opts apply to coredns forward section as well as nodelocaldns upstream target forward section
# dns_upstream_forward_extra_opts:
#   policy: sequential

# Apply extra options to coredns kubernetes plugin
# coredns_kubernetes_extra_opts:
#   - 'fallthrough example.local'

# nodelocaldns
nodelocaldns_cpu_requests: 100m
nodelocaldns_memory_limit: 200Mi
nodelocaldns_memory_requests: 70Mi
nodelocaldns_ds_nodeselector: "kubernetes.io/os: linux"
nodelocaldns_prometheus_port: 9253
nodelocaldns_secondary_prometheus_port: 9255

# nodelocaldns_additional_configs adds any extra configuration to coredns
# nodelocaldns_additional_configs: |
#   whoami
#   local

# Limits for dns-autoscaler
dns_autoscaler_cpu_requests: 20m
dns_autoscaler_memory_requests: 10Mi
dns_autoscaler_deployment_nodeselector: "kubernetes.io/os: linux"
# dns_autoscaler_extra_tolerations: [{effect: NoSchedule, operator: "Exists"}]

# etcd metrics
# etcd_metrics_service_labels:
#   k8s-app: etcd
#   app.kubernetes.io/managed-by: Kubespray
#   app: kube-prometheus-stack-kube-etcd
#   release: prometheus-stack

# Netchecker
deploy_netchecker: false
netchecker_port: 31081
agent_report_interval: 15
netcheck_namespace: default

# Limits for netchecker apps
netchecker_agent_cpu_limit: 30m
netchecker_agent_memory_limit: 100M
netchecker_agent_cpu_requests: 15m
netchecker_agent_memory_requests: 64M
netchecker_server_cpu_limit: 100m
netchecker_server_memory_limit: 256M
netchecker_server_cpu_requests: 50m
netchecker_server_memory_requests: 64M
netchecker_etcd_cpu_limit: 200m
netchecker_etcd_memory_limit: 256M
netchecker_etcd_cpu_requests: 100m
netchecker_etcd_memory_requests: 128M

# SecurityContext (user/group)
netchecker_agent_user: 1000
netchecker_server_user: 1000
netchecker_agent_group: 1000
netchecker_server_group: 1000

# Log levels
netchecker_agent_log_level: 5
netchecker_server_log_level: 5
netchecker_etcd_log_level: info

# Dashboard
dashboard_replicas: 1

# Namespace for dashboard
dashboard_namespace: kube-system

# Limits for dashboard
dashboard_cpu_limit: 100m
dashboard_memory_limit: 256M
dashboard_cpu_requests: 50m
dashboard_memory_requests: 64M

# Set dashboard_use_custom_certs to true if overriding dashboard_certs_secret_name with a secret that
# contains dashboard_tls_key_file and dashboard_tls_cert_file instead of using the initContainer provisioned certs
dashboard_use_custom_certs: false
dashboard_certs_secret_name: kubernetes-dashboard-certs
dashboard_tls_key_file: dashboard.key
dashboard_tls_cert_file: dashboard.crt
dashboard_master_toleration: true

# Override dashboard default settings
dashboard_token_ttl: 900
dashboard_skip_login: false

# Policy Controllers
# policy_controller_extra_tolerations: [{effect: NoSchedule, operator: "Exists"}]

## roles/kubernetes-apps/argocd/defaults/main.yml <==
---
argocd_enabled: false
argocd_version: v2.11.0
argocd_namespace: argocd
# argocd_admin_password:
argocd_install_url: "https://raw.githubusercontent.com/argoproj/argo-cd/{{ argocd_version }}/manifests/install.yaml"

## roles/kubernetes-apps/container_engine_accelerator/nvidia_gpu/defaults/main.yml <==
---
nvidia_accelerator_enabled: false
nvidia_driver_version: "390.87"
nvidia_gpu_tesla_base_url: https://us.download.nvidia.com/tesla/
nvidia_gpu_gtx_base_url: http://us.download.nvidia.com/XFree86/Linux-x86_64/
nvidia_gpu_flavor: tesla
nvidia_url_end: "{{ nvidia_driver_version }}/NVIDIA-Linux-x86_64-{{ nvidia_driver_version }}.run"
nvidia_driver_install_container: false
nvidia_driver_install_centos_container: atzedevries/nvidia-centos-driver-installer:2
nvidia_driver_install_ubuntu_container: registry.k8s.io/ubuntu-nvidia-driver-installer@sha256:7df76a0f0a17294e86f691c81de6bbb7c04a1b4b3d4ea4e7e2cccdc42e1f6d63
nvidia_driver_install_supported: false
nvidia_gpu_device_plugin_container: "registry.k8s.io/nvidia-gpu-device-plugin@sha256:0842734032018be107fa2490c98156992911e3e1f2a21e059ff0105b07dd8e9e"
nvidia_gpu_nodes: []
nvidia_gpu_device_plugin_memory: 30Mi

## roles/kubernetes-apps/container_runtimes/kata_containers/defaults/main.yaml <==
---

kata_containers_qemu_overhead: true
kata_containers_qemu_overhead_fixed_cpu: 250m
kata_containers_qemu_overhead_fixed_memory: 160Mi

## roles/kubernetes-apps/csi_driver/aws_ebs/defaults/main.yml <==
---
aws_ebs_csi_enable_volume_scheduling: true
aws_ebs_csi_enable_volume_snapshot: false
aws_ebs_csi_enable_volume_resizing: false
aws_ebs_csi_controller_replicas: 1
aws_ebs_csi_plugin_image_tag: latest

# Add annotions to ebs_csi_controller. Useful if using kube2iam for role assumption
# aws_ebs_csi_annotations:
#   - key: iam.amazonaws.com/role
#     value: your-ebs-role-arn

## roles/kubernetes-apps/csi_driver/azuredisk/defaults/main.yml <==
---
azure_csi_use_instance_metadata: true
azure_csi_controller_replicas: 2
azure_csi_plugin_image_tag: latest
azure_csi_controller_affinity: {}
azure_csi_node_affinity: {}

## roles/kubernetes-apps/csi_driver/cinder/defaults/main.yml <==
---
cinder_csi_attacher_image_tag: "v4.4.2"
cinder_csi_provisioner_image_tag: "v3.6.2"
cinder_csi_snapshotter_image_tag: "v6.3.2"
cinder_csi_resizer_image_tag: "v1.9.2"
cinder_csi_livenessprobe_image_tag: "v2.11.0"

# To access Cinder, the CSI controller will need credentials to access
# openstack apis. Per default this values will be
# read from the environment.
cinder_auth_url: "{{ lookup('env', 'OS_AUTH_URL') }}"
cinder_username: "{{ lookup('env', 'OS_USERNAME') }}"
cinder_password: "{{ lookup('env', 'OS_PASSWORD') }}"
cinder_application_credential_id: "{{ lookup('env', 'OS_APPLICATION_CREDENTIAL_ID') }}"
cinder_application_credential_name: "{{ lookup('env', 'OS_APPLICATION_CREDENTIAL_NAME') }}"
cinder_application_credential_secret: "{{ lookup('env', 'OS_APPLICATION_CREDENTIAL_SECRET') }}"
cinder_region: "{{ lookup('env', 'OS_REGION_NAME') }}"
cinder_tenant_id: "{{ lookup('env', 'OS_TENANT_ID') | default(lookup('env', 'OS_PROJECT_ID'), true) }}"
cinder_tenant_name: "{{ lookup('env', 'OS_TENANT_NAME') | default(lookup('env', 'OS_PROJECT_NAME'), true) }}"
cinder_domain_name: "{{ lookup('env', 'OS_USER_DOMAIN_NAME') }}"
cinder_domain_id: "{{ lookup('env', 'OS_USER_DOMAIN_ID') }}"
cinder_cacert: "{{ lookup('env', 'OS_CACERT') }}"

# For now, only Cinder v3 is supported in Cinder CSI driver
cinder_blockstorage_version: "v3"
cinder_csi_controller_replicas: 1

# Optional. Set to true, to rescan block device and verify its size before expanding
# the filesystem.
# Not all hypervizors have a /sys/class/block/XXX/device/rescan location, therefore if
# you enable this option and your hypervizor doesn't support this, you'll get a warning
# log on resize event. It is recommended to disable this option in this case.
# Defaults to false
# cinder_csi_rescan_on_resize: true

cinder_tolerations: []

## Dictionaries of extra arguments to add to the cinder CSI plugin containers
## Format:
##  cinder_csi_attacher_extra_args:
##    arg1: "value1"
##    arg2: "value2"
cinder_csi_attacher_extra_args: {}
cinder_csi_provisioner_extra_args: {}
cinder_csi_snapshotter_extra_args: {}
cinder_csi_resizer_extra_args: {}
cinder_csi_plugin_extra_args: {}
cinder_liveness_probe_extra_args: {}

## roles/kubernetes-apps/csi_driver/gcp_pd/defaults/main.yml <==
---
gcp_pd_csi_controller_replicas: 1

## roles/kubernetes-apps/csi_driver/upcloud/defaults/main.yml <==
---
upcloud_csi_controller_replicas: 1
upcloud_csi_provisioner_image_tag: "v3.1.0"
upcloud_csi_attacher_image_tag: "v3.4.0"
upcloud_csi_resizer_image_tag: "v1.4.0"
upcloud_csi_plugin_image_tag: "v1.1.0"
upcloud_csi_node_image_tag: "v2.5.0"
upcloud_username: "{{ lookup('env', 'UPCLOUD_USERNAME') }}"
upcloud_password: "{{ lookup('env', 'UPCLOUD_PASSWORD') }}"
upcloud_tolerations: []
upcloud_csi_enable_volume_snapshot: false
upcloud_csi_snapshot_controller_replicas: 2
upcloud_csi_snapshotter_image_tag: "v4.2.1"
upcloud_csi_snapshot_controller_image_tag: "v4.2.1"
upcloud_csi_snapshot_validation_webhook_image_tag: "v4.2.1"
upcloud_cacert: "{{ lookup('env', 'OS_CACERT') }}"

## roles/kubernetes-apps/csi_driver/vsphere/defaults/main.yml <==
---
external_vsphere_vcenter_port: "443"
external_vsphere_insecure: "true"
external_vsphere_kubernetes_cluster_id: "kubernetes-cluster-id"
external_vsphere_version: "7.0u1"

vsphere_syncer_image_tag: "v3.3.1"
vsphere_csi_attacher_image_tag: "v4.3.0"
vsphere_csi_controller: "v3.3.1"
vsphere_csi_liveness_probe_image_tag: "v2.10.0"
vsphere_csi_provisioner_image_tag: "v3.5.0"
vsphere_csi_snapshotter_image_tag: "v6.2.2"
vsphere_csi_node_driver_registrar_image_tag: "v2.8.0"
vsphere_csi_driver_image_tag: "v3.3.1"
vsphere_csi_resizer_tag: "v1.8.0"

# Set to kube-system for backward compatibility, should be change to vmware-system-csi on the long run
vsphere_csi_namespace: "kube-system"

vsphere_csi_controller_replicas: 1

csi_endpoint: '{% if external_vsphere_version >= "7.0u1" %}/csi{% else %}/var/lib/csi/sockets/pluginproxy{% endif %}'

vsphere_csi_aggressive_node_drain: false
vsphere_csi_aggressive_node_unreachable_timeout: 300
vsphere_csi_aggressive_node_not_ready_timeout: 300

vsphere_csi_node_affinity: {}

# If this is true, debug information will be displayed but
# may contain some private data, so it is recommended to set it to false
# in the production environment.
unsafe_show_logs: false

# https://github.com/kubernetes-sigs/vsphere-csi-driver/blob/master/docs/book/features/volume_snapshot.md#how-to-enable-volume-snapshot--restore-feature-in-vsphere-csi-
# according to the above link , we can controler the block-volume-snapshot parameter
vsphere_csi_block_volume_snapshot: false

external_vsphere_user: "{{ lookup('env', 'VSPHERE_USER') }}"
external_vsphere_password: "{{ lookup('env', 'VSPHERE_PASSWORD') }}"

# Controller resources
vsphere_csi_snapshotter_resources: {}
vsphere_csi_provisioner_resources: {}
vsphere_syncer_resources: {}
vsphere_csi_liveness_probe_controller_resources: {}
vsphere_csi_resources: {}
vsphere_csi_resizer_resources: {}
vsphere_csi_attacher_resources: {}

# DaemonSet node resources
vsphere_csi_node_driver_registrar_resources: {}
vsphere_csi_driver_resources: {}
vsphere_csi_liveness_probe_ds_resources: {}

## roles/kubernetes-apps/defaults/main.yml <==
---
namespace: kube-system

## roles/kubernetes-apps/external_cloud_controller/hcloud/defaults/main.yml <==
---
external_hcloud_cloud:
  hcloud_api_token: ""
  token_secret_name: hcloud

  service_account_name: cloud-controller-manager

  controller_image_tag: "latest"
  ## A dictionary of extra arguments to add to the openstack cloud controller manager daemonset
  ## Format:
  ##  external_hcloud_cloud.controller_extra_args:
  ##    arg1: "value1"
  ##    arg2: "value2"
  controller_extra_args: {}

## roles/kubernetes-apps/external_cloud_controller/huaweicloud/defaults/main.yml <==
---
# The external cloud controller will need credentials to access
# openstack apis. Per default these values will be
# read from the environment.
external_huaweicloud_auth_url: "{{ lookup('env','OS_AUTH_URL')  }}"
external_huaweicloud_access_key: "{{ lookup('env','OS_ACCESS_KEY')  }}"
external_huaweicloud_secret_key: "{{ lookup('env','OS_SECRET_KEY')  }}"
external_huaweicloud_region: "{{ lookup('env','OS_REGION_NAME')  }}"
external_huaweicloud_project_id: "{{ lookup('env','OS_TENANT_ID')| default(lookup('env','OS_PROJECT_ID'),true) }}"
external_huaweicloud_cloud: "{{ lookup('env','OS_CLOUD') }}"

## A dictionary of extra arguments to add to the huawei cloud controller manager deployment
## Format:
##  external_huawei_cloud_controller_extra_args:
##    arg1: "value1"
##    arg2: "value2"
external_huawei_cloud_controller_extra_args: {}
external_huawei_cloud_controller_image_repo: "swr.ap-southeast-1.myhuaweicloud.com"
external_huawei_cloud_controller_image_tag: "v0.26.8"

## roles/kubernetes-apps/external_cloud_controller/oci/defaults/main.yml <==
---
## External Oracle Cloud Controller Manager
## https://github.com/oracle/oci-cloud-controller-manager/blob/v1.29.0/manifests/provider-config-example.yaml
external_oracle_auth_region: ""
external_oracle_auth_tenancy: ""
external_oracle_auth_user: ""
external_oracle_auth_key: ""
external_oracle_auth_passphrase: ""
external_oracle_auth_fingerprint: ""
external_oracle_auth_use_instance_principals: false

external_oracle_compartment: ""
external_oracle_vcn: ""
external_oracle_load_balancer_subnet1: ""
external_oracle_load_balancer_subnet2: ""
external_oracle_load_balancer_security_list_management_mode: All
external_oracle_load_balancer_security_lists: {}

external_oracle_ratelimiter_qps_read: 20.0
external_oracle_ratelimiter_bucket_read: 5
external_oracle_ratelimiter_qps_write: 20.0
external_oracle_ratelimiter_bucket_write: 5

external_oracle_cloud_controller_image_repo: ghcr.io/oracle/cloud-provider-oci
external_oracle_cloud_controller_image_tag: "v1.29.0"

## roles/kubernetes-apps/external_cloud_controller/openstack/defaults/main.yml <==
---
# The external cloud controller will need credentials to access
# openstack apis. Per default these values will be
# read from the environment.
external_openstack_auth_url: "{{ lookup('env', 'OS_AUTH_URL') }}"
external_openstack_username: "{{ lookup('env', 'OS_USERNAME') }}"
external_openstack_password: "{{ lookup('env', 'OS_PASSWORD') }}"
external_openstack_application_credential_id: "{{ lookup('env', 'OS_APPLICATION_CREDENTIAL_ID') }}"
external_openstack_application_credential_name: "{{ lookup('env', 'OS_APPLICATION_CREDENTIAL_NAME') }}"
external_openstack_application_credential_secret: "{{ lookup('env', 'OS_APPLICATION_CREDENTIAL_SECRET') }}"
external_openstack_region: "{{ lookup('env', 'OS_REGION_NAME') }}"
external_openstack_tenant_id: "{{ lookup('env', 'OS_TENANT_ID') | default(lookup('env', 'OS_PROJECT_ID'), true) }}"
external_openstack_tenant_name: "{{ lookup('env', 'OS_TENANT_NAME') | default(lookup('env', 'OS_PROJECT_NAME'), true) }}"
external_openstack_domain_name: "{{ lookup('env', 'OS_USER_DOMAIN_NAME') }}"
external_openstack_domain_id: "{{ lookup('env', 'OS_USER_DOMAIN_ID') }}"
external_openstack_cacert: "{{ lookup('env', 'OS_CACERT') }}"

## A dictionary of extra arguments to add to the openstack cloud controller manager daemonset
## Format:
##  external_openstack_cloud_controller_extra_args:
##    arg1: "value1"
##    arg2: "value2"
external_openstack_cloud_controller_extra_args: {}
external_openstack_cloud_controller_image_tag: "v1.30.0"
external_openstack_cloud_controller_bind_address: 127.0.0.1
external_openstack_cloud_controller_dns_policy: ClusterFirst

## roles/kubernetes-apps/external_cloud_controller/vsphere/defaults/main.yml <==
---
external_vsphere_vcenter_port: "443"
external_vsphere_insecure: "true"

## A dictionary of extra arguments to add to the vsphere cloud controller manager daemonset
## Format:
##  external_vsphere_cloud_controller_extra_args:
##    arg1: "value1"
##    arg2: "value2"
external_vsphere_cloud_controller_extra_args: {}
external_vsphere_cloud_controller_image_tag: "v1.31.0"

external_vsphere_user: "{{ lookup('env', 'VSPHERE_USER') }}"
external_vsphere_password: "{{ lookup('env', 'VSPHERE_PASSWORD') }}"

## roles/kubernetes-apps/external_provisioner/cephfs_provisioner/defaults/main.yml <==
---
cephfs_provisioner_namespace: "cephfs-provisioner"
cephfs_provisioner_cluster: ceph
cephfs_provisioner_monitors: ~
cephfs_provisioner_admin_id: admin
cephfs_provisioner_secret: secret
cephfs_provisioner_storage_class: cephfs
cephfs_provisioner_reclaim_policy: Delete
cephfs_provisioner_claim_root: /volumes
cephfs_provisioner_deterministic_names: true

## roles/kubernetes-apps/external_provisioner/local_path_provisioner/defaults/main.yml <==
---
local_path_provisioner_enabled: false
local_path_provisioner_namespace: "local-path-storage"
local_path_provisioner_storage_class: "local-path"
local_path_provisioner_reclaim_policy: Delete
local_path_provisioner_claim_root: /opt/local-path-provisioner/
local_path_provisioner_is_default_storageclass: "true"
local_path_provisioner_debug: false
local_path_provisioner_helper_image_repo: "busybox"
local_path_provisioner_helper_image_tag: "latest"

## roles/kubernetes-apps/external_provisioner/local_volume_provisioner/defaults/main.yml <==
---
local_volume_provisioner_namespace: "kube-system"
# List of node labels to be copied to the PVs created by the provisioner
local_volume_provisioner_nodelabels: []
#   - kubernetes.io/hostname
#   - topology.kubernetes.io/region
#   - topology.kubernetes.io/zone
local_volume_provisioner_tolerations: []
local_volume_provisioner_use_node_name_only: false
# Leverages Ansible's string to Python datatype casting. Otherwise the dict_key isn't substituted.
# see https://github.com/ansible/ansible/issues/17324
local_volume_provisioner_storage_classes: |
  {
    "{{ local_volume_provisioner_storage_class | default('local-storage') }}": {
      "host_dir": "{{ local_volume_provisioner_base_dir | default('/mnt/disks') }}",
      "mount_dir": "{{ local_volume_provisioner_mount_dir | default('/mnt/disks') }}",
      "volume_mode": "Filesystem",
      "fs_type": "ext4"
    }
  }
local_volume_provisioner_log_level: 2

## roles/kubernetes-apps/external_provisioner/rbd_provisioner/defaults/main.yml <==
---
rbd_provisioner_namespace: "rbd-provisioner"
rbd_provisioner_replicas: 2
rbd_provisioner_monitors: ~
rbd_provisioner_pool: kube
rbd_provisioner_admin_id: admin
rbd_provisioner_secret_name: ceph-secret-admin
rbd_provisioner_secret: ceph-key-admin
rbd_provisioner_user_id: kube
rbd_provisioner_user_secret_name: ceph-secret-user
rbd_provisioner_user_secret: ceph-key-user
rbd_provisioner_user_secret_namespace: rbd-provisioner
rbd_provisioner_fs_type: ext4
rbd_provisioner_image_format: "2"
rbd_provisioner_image_features: layering
rbd_provisioner_storage_class: rbd
rbd_provisioner_reclaim_policy: Delete

## roles/kubernetes-apps/gateway_api/defaults/main.yml <==
---
gateway_api_enabled: false
gateway_api_version: v1.1.0
gateway_api_experimental_channel: false

## roles/kubernetes-apps/helm/defaults/main.yml <==
---
helm_enabled: false

## roles/kubernetes-apps/ingress_controller/alb_ingress_controller/defaults/main.yml <==
---
alb_ingress_controller_namespace: kube-system
alb_ingress_aws_region: "us-east-1"

# Enables logging on all outbound requests sent to the AWS API.
# If logging is desired, set to true.
alb_ingress_aws_debug: "false"

## roles/kubernetes-apps/ingress_controller/cert_manager/defaults/main.yml <==
---
cert_manager_namespace: "cert-manager"
cert_manager_user: 1001
cert_manager_tolerations: []
cert_manager_affinity: {}
cert_manager_nodeselector: {}
cert_manager_dns_policy: "ClusterFirst"
cert_manager_dns_config: {}
cert_manager_controller_extra_args: []

## Allow http_proxy, https_proxy and no_proxy environment variables
## Details https://github.com/kubernetes-sigs/kubespray/blob/master/docs/proxy.md
cert_manager_http_proxy: "{{ http_proxy | default('') }}"
cert_manager_https_proxy: "{{ https_proxy | default('') }}"
cert_manager_no_proxy: "{{ no_proxy | default('') }}"

## Change leader election namespace when deploying on GKE Autopilot that forbid the changes on kube-system namespace.
## See https://github.com/jetstack/cert-manager/issues/3717
cert_manager_leader_election_namespace: kube-system

## roles/kubernetes-apps/ingress_controller/ingress_nginx/defaults/main.yml <==
---
ingress_nginx_namespace: "ingress-nginx"
ingress_nginx_host_network: false
ingress_nginx_service_type: LoadBalancer
ingress_nginx_service_nodeport_http: ""
ingress_nginx_service_nodeport_https: ""
ingress_nginx_service_annotations: {}
ingress_publish_status_address: ""
ingress_nginx_nodeselector:
  kubernetes.io/os: "linux"
ingress_nginx_tolerations: []
ingress_nginx_insecure_port: 80
ingress_nginx_secure_port: 443
ingress_nginx_metrics_port: 10254
ingress_nginx_configmap: {}
ingress_nginx_configmap_tcp_services: {}
ingress_nginx_configmap_udp_services: {}
ingress_nginx_extra_args: []
ingress_nginx_termination_grace_period_seconds: 300
ingress_nginx_class: nginx
ingress_nginx_without_class: true
ingress_nginx_default: false
ingress_nginx_webhook_enabled: false
ingress_nginx_webhook_job_ttl: 1800
ingress_nginx_opentelemetry_enabled: false

ingress_nginx_probe_initial_delay_seconds: 10

## roles/kubernetes-apps/krew/defaults/main.yml <==
---
krew_enabled: false
krew_root_dir: "/usr/local/krew"
krew_default_index_uri: https://github.com/kubernetes-sigs/krew-index.git
krew_no_upgrade_check: 0

## roles/kubernetes-apps/kubelet-csr-approver/defaults/main.yml <==
---
kubelet_csr_approver_enabled: "{{ kubelet_rotate_server_certificates }}"
kubelet_csr_approver_namespace: kube-system

kubelet_csr_approver_repository_name: kubelet-csr-approver
kubelet_csr_approver_repository_url: https://postfinance.github.io/kubelet-csr-approver
kubelet_csr_approver_chart_ref: "{{ kubelet_csr_approver_repository_name }}/kubelet-csr-approver"
kubelet_csr_approver_chart_version: 1.1.0

# Fill values override here
# See upstream https://github.com/postfinance/kubelet-csr-approver
kubelet_csr_approver_values: {}

## roles/kubernetes-apps/metallb/defaults/main.yml <==
---
metallb_enabled: false
metallb_log_level: info
metallb_port: "7472"
metallb_memberlist_port: "7946"
metallb_speaker_enabled: "{{ metallb_enabled }}"
metallb_speaker_nodeselector:
  kubernetes.io/os: "linux"
metallb_controller_nodeselector:
  kubernetes.io/os: "linux"
metallb_speaker_tolerations:
  - effect: NoSchedule
    key: node-role.kubernetes.io/control-plane
    operator: Exists
metallb_controller_tolerations: []
metallb_loadbalancer_class: ""

## roles/kubernetes-apps/metrics_server/defaults/main.yml <==
---
metrics_server_container_port: 10250
metrics_server_kubelet_insecure_tls: true
metrics_server_kubelet_preferred_address_types: "InternalIP,ExternalIP,Hostname"
metrics_server_metric_resolution: 15s
metrics_server_limits_cpu: 100m
metrics_server_limits_memory: 200Mi
metrics_server_requests_cpu: 100m
metrics_server_requests_memory: 200Mi
metrics_server_host_network: false
metrics_server_replicas: 1
metrics_server_extra_tolerations: []
metrics_server_extra_affinity: {}
metrics_server_nodeselector: {}

## roles/kubernetes-apps/node_feature_discovery/defaults/main.yml <==
---
node_feature_discovery_enabled: false
node_feature_discovery_namespace: node-feature-discovery
node_feature_discovery_enable_nodefeature_api: true
node_feature_discovery_gc_replicas: 1
node_feature_discovery_gc_interval: 1h
node_feature_discovery_gc_sa_name: node-feature-discovery-gc
node_feature_discovery_gc_sa_create: true
node_feature_discovery_master_replicas: 1
node_feature_discovery_master_crd_controller: null
node_feature_discovery_master_instance: null
node_feature_discovery_master_config: null
node_feature_discovery_worker_sa_name: node-feature-discovery-worker
node_feature_discovery_worker_sa_create: true
node_feature_discovery_worker_config: null
node_feature_discovery_worker_tolerations: null

## roles/kubernetes-apps/persistent_volumes/aws-ebs-csi/defaults/main.yml <==
---
# To restrict which AZ the volume should be provisioned in
# set this value to true and set the list of relevant AZs
# For it to work, the flag aws_ebs_csi_enable_volume_scheduling
# in AWS EBS Driver must be true
restrict_az_provisioning: false
aws_ebs_availability_zones:
  - eu-west-3c

## roles/kubernetes-apps/persistent_volumes/azuredisk-csi/defaults/main.yml <==
---
## Available values: Standard_LRS, Premium_LRS, StandardSSD_LRS, UltraSSD_LRS
storage_account_type: StandardSSD_LRS

## roles/kubernetes-apps/persistent_volumes/cinder-csi/defaults/main.yml <==
---
storage_classes:
  - name: cinder-csi
    is_default: false
    parameters:
      availability: nova
      allowVolumeExpansion: false

## roles/kubernetes-apps/persistent_volumes/gcp-pd-csi/defaults/main.yml <==
---
# Choose between pd-standard and pd-ssd
gcp_pd_csi_volume_type: pd-standard
gcp_pd_regional_replication_enabled: false
gcp_pd_restrict_zone_replication: false
gcp_pd_restricted_zones:
  - europe-west1-b
  - europe-west1-c

## roles/kubernetes-apps/persistent_volumes/upcloud-csi/defaults/main.yml <==
---
storage_classes:
  - name: standard
    is_default: true
    expand_persistent_volumes: true
    parameters:
      tier: maxiops
  - name: hdd
    is_default: false
    expand_persistent_volumes: true
    parameters:
      tier: hdd

## roles/kubernetes-apps/policy_controller/calico/defaults/main.yml <==
---
# Limits for calico apps
calico_policy_controller_cpu_limit: 1000m
calico_policy_controller_memory_limit: 256M
calico_policy_controller_cpu_requests: 30m
calico_policy_controller_memory_requests: 64M
calico_policy_controller_deployment_nodeselector: "kubernetes.io/os: linux"
calico_policy_controller_log_level: info

# SSL
calico_cert_dir: "/etc/calico/certs"

## roles/kubernetes-apps/registry/defaults/main.yml <==
---
registry_namespace: "kube-system"
registry_storage_class: ""
registry_storage_access_mode: "ReadWriteOnce"
registry_disk_size: "10Gi"
registry_port: 5000
registry_replica_count: 1

# type of service: ClusterIP, LoadBalancer or NodePort
registry_service_type: "ClusterIP"
# you can specify your cluster IP address when registry_service_type is ClusterIP
registry_service_cluster_ip: ""
# you can specify your cloud provider assigned loadBalancerIP when registry_service_type is LoadBalancer
registry_service_loadbalancer_ip: ""
# annotations for managing Cloud Load Balancers
registry_service_annotations: {}
# you can specify the node port when registry_service_type is NodePort
registry_service_nodeport: ""

# name of kubernetes secret for registry TLS certs
registry_tls_secret: ""

registry_htpasswd: ""

# registry configuration
# see: https://docs.docker.com/registry/configuration/#list-of-configuration-options
registry_config:
  version: 0.1
  log:
    fields:
      service: registry
  storage:
    cache:
      blobdescriptor: inmemory
  http:
    addr: :{{ registry_port }}
    headers:
      X-Content-Type-Options: [nosniff]
  health:
    storagedriver:
      enabled: true
      interval: 10s
      threshold: 3

registry_ingress_annotations: {}
registry_ingress_host: ""
# name of kubernetes secret for registry ingress TLS certs
registry_ingress_tls_secret: ""

## roles/kubernetes-apps/scheduler_plugins/defaults/main.yml <==
---
scheduler_plugins_enabled: false

scheduler_plugins_namespace: scheduler-plugins

scheduler_plugins_controller_replicas: 1

scheduler_plugins_scheduler_replicas: 1

# The default is determined by the number of control plane nodes.
scheduler_plugins_scheduler_leader_elect: "{{ ((groups['kube_control_plane'] | length) > 1) }}"

# Plugins to enable. See https://github.com/kubernetes-sigs/scheduler-plugins/blob/master/manifests/install/charts/as-a-second-scheduler/README.md#configuration for more info.
scheduler_plugins_enabled_plugins:
  - Coscheduling
  - CapacityScheduling
  - NodeResourceTopologyMatch
  - NodeResourcesAllocatable

# Plugins to disable. See https://github.com/kubernetes-sigs/scheduler-plugins/blob/master/manifests/install/charts/as-a-second-scheduler/README.md#configuration for more info.
scheduler_plugins_disabled_plugins:
  - PrioritySort

# Customize the enabled plugins' config.
# Refer to the "pluginConfig" section of https://github.com/kubernetes-sigs/scheduler-plugins/blob/master/manifests/<plugin>/scheduler-config.yaml.
scheduler_plugins_plugin_config:
  - name: Coscheduling
    args:
      permitWaitingTimeSeconds: 10      # default is 60

## roles/kubernetes-apps/snapshots/cinder-csi/defaults/main.yml <==
---
snapshot_classes:
  - name: cinder-csi-snapshot
    is_default: false
    force_create: true
    deletionPolicy: Delete

## roles/kubernetes-apps/snapshots/snapshot-controller/defaults/main.yml <==
---
snapshot_controller_replicas: 1
snapshot_controller_namespace: kube-system

## roles/kubernetes/client/defaults/main.yml <==
---
kubeconfig_localhost: false
kubeconfig_localhost_ansible_host: false
kubectl_localhost: false
artifacts_dir: "{{ inventory_dir }}/artifacts"

kube_config_dir: "/etc/kubernetes"
kube_apiserver_port: "6443"

## roles/kubernetes/control-plane/defaults/main/etcd.yml <==
---
# Set etcd user/group
etcd_owner: etcd

# Note: This does not set up DNS entries. It simply adds the following DNS
# entries to the certificate
etcd_cert_alt_names:
  - "etcd.kube-system.svc.{{ dns_domain }}"
  - "etcd.kube-system.svc"
  - "etcd.kube-system"
  - "etcd"
etcd_cert_alt_ips: []

etcd_heartbeat_interval: "250"
etcd_election_timeout: "5000"

# etcd_snapshot_count: "10000"

etcd_metrics: "basic"

## A dictionary of extra environment variables to add to etcd.env, formatted like:
##  etcd_extra_vars:
##    var1: "value1"
##    var2: "value2"
## Note this is different from the etcd role with ETCD_ prfexi, caps, and underscores
etcd_extra_vars: {}

# etcd_quota_backend_bytes: "2147483648"
# etcd_max_request_bytes: "1572864"

etcd_compaction_retention: "8"

## roles/kubernetes/control-plane/defaults/main/kube-proxy.yml <==
---
# bind address for kube-proxy
kube_proxy_bind_address: '0.0.0.0'

# acceptContentTypes defines the Accept header sent by clients when connecting to a server, overriding the
# default value of 'application/json'. This field will control all connections to the server used by a particular
# client.
kube_proxy_client_accept_content_types: ''

# burst allows extra queries to accumulate when a client is exceeding its rate.
kube_proxy_client_burst: 10

# contentType is the content type used when sending data to the server from this client.
kube_proxy_client_content_type: application/vnd.kubernetes.protobuf

# kubeconfig is the path to a KubeConfig file.
# Leave as empty string to generate from other fields
kube_proxy_client_kubeconfig: ''

# qps controls the number of queries per second allowed for this connection.
kube_proxy_client_qps: 5

# How often configuration from the apiserver is refreshed. Must be greater than 0.
kube_proxy_config_sync_period: 15m0s

### Conntrack
# maxPerCore is the maximum number of NAT connections to track
# per CPU core (0 to leave the limit as-is and ignore min).
kube_proxy_conntrack_max_per_core: 32768

# min is the minimum value of connect-tracking records to allocate,
# regardless of conntrackMaxPerCore (set maxPerCore=0 to leave the limit as-is).
kube_proxy_conntrack_min: 131072

# tcpCloseWaitTimeout is how long an idle conntrack entry
# in CLOSE_WAIT state will remain in the conntrack
# table. (e.g. '60s'). Must be greater than 0 to set.
kube_proxy_conntrack_tcp_close_wait_timeout: 1h0m0s

# tcpEstablishedTimeout is how long an idle TCP connection will be kept open
# (e.g. '2s').  Must be greater than 0 to set.
kube_proxy_conntrack_tcp_established_timeout: 24h0m0s

# Enables profiling via web interface on /debug/pprof handler.
# Profiling handlers will be handled by metrics server.
kube_proxy_enable_profiling: false

# bind address for kube-proxy health check
kube_proxy_healthz_bind_address: 0.0.0.0:10256

# If using the pure iptables proxy, SNAT everything. Note that it breaks any
# policy engine.
kube_proxy_masquerade_all: false

# If using the pure iptables proxy, the bit of the fwmark space to mark packets requiring SNAT with.
# Must be within the range [0, 31].
kube_proxy_masquerade_bit: 14

# The minimum interval of how often the iptables or ipvs rules can be refreshed as
# endpoints and services change (e.g. '5s', '1m', '2h22m').
kube_proxy_min_sync_period: 0s

# The maximum interval of how often iptables or ipvs rules are refreshed (e.g. '5s', '1m', '2h22m').
# Must be greater than 0.
kube_proxy_sync_period: 30s

# A comma-separated list of CIDR's which the ipvs proxier should not touch when cleaning up IPVS rules.
kube_proxy_exclude_cidrs: []

# The ipvs scheduler type when proxy mode is ipvs
# rr: round-robin
# lc: least connection
# dh: destination hashing
# sh: source hashing
# sed: shortest expected delay
# nq: never queue
kube_proxy_scheduler: rr

# configure arp_ignore and arp_announce to avoid answering ARP queries from kube-ipvs0 interface
# must be set to true for MetalLB, kube-vip(ARP enabled) to work
kube_proxy_strict_arp: false

# kube_proxy_tcp_timeout is the timeout value used for idle IPVS TCP sessions.
# The default value is 0, which preserves the current timeout value on the system.
kube_proxy_tcp_timeout: 0s

# kube_proxy_tcp_fin_timeout is the timeout value used for IPVS TCP sessions after receiving a FIN.
# The default value is 0, which preserves the current timeout value on the system.
kube_proxy_tcp_fin_timeout: 0s

# kube_proxy_udp_timeout is the timeout value used for IPVS UDP packets.
# The default value is 0, which preserves the current timeout value on the system.
kube_proxy_udp_timeout: 0s

# The IP address and port for the metrics server to serve on
# (set to 0.0.0.0 for all IPv4 interfaces and `::` for all IPv6 interfaces)
kube_proxy_metrics_bind_address: 127.0.0.1:10249

# A string slice of values which specify the addresses to use for NodePorts.
# Values may be valid IP blocks (e.g. 1.2.3.0/24, 1.2.3.4/32).
# The default empty string slice ([]) means to use all local addresses.
kube_proxy_nodeport_addresses: >-
  {%- if kube_proxy_nodeport_addresses_cidr is defined -%}
  [{{ kube_proxy_nodeport_addresses_cidr }}]
  {%- else -%}
  []
  {%- endif -%}

# oom-score-adj value for kube-proxy process. Values must be within the range [-1000, 1000]
kube_proxy_oom_score_adj: -999

# portRange is the range of host ports (beginPort-endPort, inclusive) that may be consumed
# in order to proxy service traffic. If unspecified, 0, or (0-0) then ports will be randomly chosen.
kube_proxy_port_range: ''

## roles/kubernetes/control-plane/defaults/main/kube-scheduler.yml <==
---
# Extra args passed by kubeadm
kube_kubeadm_scheduler_extra_args: {}

# Associated interface must be reachable by the rest of the cluster, and by
# CLI/web clients.
kube_scheduler_bind_address: 0.0.0.0

# ClientConnection options (e.g. Burst, QPS) except from kubeconfig.
kube_scheduler_client_conn_extra_opts: {}

# Additional KubeSchedulerConfiguration settings (e.g. metricsBindAddress).
kube_scheduler_config_extra_opts: {}

# List of scheduler extenders (dicts), each holding the values of how to
# communicate with the extender.
kube_scheduler_extenders: []

# Leader Election options (e.g. ResourceName, RetryPerion) except from
# LeaseDuration and Renew deadline which are defined in following vars.
kube_scheduler_leader_elect_extra_opts: {}

# Leader election lease duration
kube_scheduler_leader_elect_lease_duration: 15s

# Leader election lease timeout
kube_scheduler_leader_elect_renew_deadline: 10s

# Lisf of scheduling profiles (ditcs) supported by kube-scheduler
kube_scheduler_profiles: []

# Extra volume mounts
scheduler_extra_volumes: {}

## roles/kubernetes/control-plane/defaults/main/main.yml <==
---
# disable upgrade cluster
upgrade_cluster_setup: false

# By default the external API listens on all interfaces, this can be changed to
# listen on a specific address/interface.
# NOTE: If you specific address/interface and use loadbalancer_apiserver_localhost
# loadbalancer_apiserver_localhost (nginx/haproxy) will deploy on control plane nodes on 127.0.0.1:{{ loadbalancer_apiserver_port | default(kube_apiserver_port) }} too.
kube_apiserver_bind_address: 0.0.0.0

# A port range to reserve for services with NodePort visibility.
# Inclusive at both ends of the range.
kube_apiserver_node_port_range: "30000-32767"

# ETCD backend for k8s data
kube_apiserver_storage_backend: etcd3

# The interval of compaction requests. If 0, the compaction request from apiserver is disabled.
kube_apiserver_etcd_compaction_interval: "5m0s"

# CIS 1.2.26
# Validate that the service account token
# in the request is actually present in etcd.
kube_apiserver_service_account_lookup: true

kube_etcd_cacert_file: ca.pem
kube_etcd_cert_file: node-{{ inventory_hostname }}.pem
kube_etcd_key_file: node-{{ inventory_hostname }}-key.pem

# Associated interfaces must be reachable by the rest of the cluster, and by
# CLI/web clients.
kube_controller_manager_bind_address: 0.0.0.0

# Leader election lease durations and timeouts for controller-manager
kube_controller_manager_leader_elect_lease_duration: 15s
kube_controller_manager_leader_elect_renew_deadline: 10s

# discovery_timeout modifies the discovery timeout
discovery_timeout: 5m0s

# Instruct first control plane node to refresh kubeadm token
kubeadm_refresh_token: true

# Scale down coredns replicas to 0 if not using coredns dns_mode
kubeadm_scale_down_coredns_enabled: true

# audit support
kubernetes_audit: false
# path to audit log file
audit_log_path: /var/log/audit/kube-apiserver-audit.log
# num days
audit_log_maxage: 30
# the num of audit logs to retain
audit_log_maxbackups: 10
# the max size in MB to retain
audit_log_maxsize: 100
# policy file
audit_policy_file: "{{ kube_config_dir }}/audit-policy/apiserver-audit-policy.yaml"
# custom audit policy rules (to replace the default ones)
# audit_policy_custom_rules: |
#   - level: None
#     users: []
#     verbs: []
#     resources: []

# audit log hostpath
audit_log_name: audit-logs
audit_log_hostpath: /var/log/kubernetes/audit
audit_log_mountpath: "{{ audit_log_path | dirname }}"

# audit policy hostpath
audit_policy_name: audit-policy
audit_policy_hostpath: "{{ audit_policy_file | dirname }}"
audit_policy_mountpath: "{{ audit_policy_hostpath }}"

# audit webhook support
kubernetes_audit_webhook: false

# path to audit webhook config file
audit_webhook_config_file: "{{ kube_config_dir }}/audit-policy/apiserver-audit-webhook-config.yaml"
audit_webhook_server_url: "https://audit.app"
audit_webhook_server_extra_args: {}
audit_webhook_mode: batch
audit_webhook_batch_max_size: 100
audit_webhook_batch_max_wait: 1s

kube_controller_node_monitor_grace_period: 40s
kube_controller_node_monitor_period: 5s
kube_controller_terminated_pod_gc_threshold: 12500
kube_apiserver_request_timeout: "1m0s"
kube_apiserver_pod_eviction_not_ready_timeout_seconds: "300"
kube_apiserver_pod_eviction_unreachable_timeout_seconds: "300"

# 1.10+ admission plugins
kube_apiserver_enable_admission_plugins: []

# enable admission plugins configuration
kube_apiserver_admission_control_config_file: false

# data structure to configure EventRateLimit admission plugin
# this should have the following structure:
# kube_apiserver_admission_event_rate_limits:
# <limit_name>:
#   type: <limit_type>
#   qps: <qps_value>
#   burst: <burst_value>
#   cache_size: <cache_size_value>
kube_apiserver_admission_event_rate_limits: {}

## PodSecurityAdmission plugin configuration
kube_pod_security_use_default: false
kube_pod_security_default_enforce: baseline
kube_pod_security_default_enforce_version: "{{ kube_major_version }}"
kube_pod_security_default_audit: restricted
kube_pod_security_default_audit_version: "{{ kube_major_version }}"
kube_pod_security_default_warn: restricted
kube_pod_security_default_warn_version: "{{ kube_major_version }}"
kube_pod_security_exemptions_usernames: []
kube_pod_security_exemptions_runtime_class_names: []
kube_pod_security_exemptions_namespaces:
  - kube-system

## ResourceQuota plugin configuration
## Resources that ResourceQuota should limit by default if no quota exists
## Example below enforces quota on all storage classes
# kube_resource_quota_limited_resources:
# - apiGroup: ""
#   resource: persistentvolumeclaims
#   matchContains:
#   - .storageclass.storage.k8s.io/requests.storage
kube_resource_quota_limited_resources: []

# 1.10+ list of disabled admission plugins
kube_apiserver_disable_admission_plugins: []

# extra runtime config
kube_api_runtime_config: []

## Enable/Disable Kube API Server Authentication Methods
kube_token_auth: false
kube_oidc_auth: false

## Variables for webhook token auth https://kubernetes.io/docs/reference/access-authn-authz/authentication/#webhook-token-authentication
kube_webhook_token_auth: false
kube_webhook_token_auth_url_skip_tls_verify: false
# kube_webhook_token_auth_url: https://...
## base64-encoded string of the webhook's CA certificate
# kube_webhook_token_auth_ca_data: "LS0t..."

## Variables for webhook token authz https://kubernetes.io/docs/reference/access-authn-authz/webhook/
# kube_webhook_authorization_url: https://...
kube_webhook_authorization: false
kube_webhook_authorization_url_skip_tls_verify: false

# Default podnodeselector
kube_apiserver_admission_plugins_podnodeselector_default_node_selector: ""

## Variables for OpenID Connect Configuration https://kubernetes.io/docs/admin/authentication/
## To use OpenID you have to deploy additional an OpenID Provider (e.g Dex, Keycloak, ...)

# kube_oidc_url: https:// ...
# kube_oidc_client_id: kubernetes
## Optional settings for OIDC
# kube_oidc_username_claim: sub
# kube_oidc_username_prefix: 'oidc:'
# kube_oidc_groups_claim: groups
# kube_oidc_groups_prefix: 'oidc:'
# Copy oidc CA file to the following path if needed
# kube_oidc_ca_file: {{ kube_cert_dir }}/ca.pem
# Optionally include a base64-encoded oidc CA cert
# kube_oidc_ca_cert: c3RhY2thYnVzZS5jb20...

# List of the preferred NodeAddressTypes to use for kubelet connections.
kubelet_preferred_address_types: 'InternalDNS,InternalIP,Hostname,ExternalDNS,ExternalIP'

## Extra args for k8s components passing by kubeadm
kube_kubeadm_apiserver_extra_args: {}
kube_kubeadm_controller_extra_args: {}

## Extra control plane host volume mounts
## Example:
# apiserver_extra_volumes:
#  - name: name
#    hostPath: /host/path
#    mountPath: /mount/path
#    readOnly: true
apiserver_extra_volumes: {}
controller_manager_extra_volumes: {}

## Encrypting Secret Data at Rest
kube_encrypt_secret_data: false
kube_encrypt_token: "{{ lookup('password', credentials_dir + '/kube_encrypt_token.creds length=32 chars=ascii_letters,digits') }}"
# Must be either: aescbc, secretbox or aesgcm
kube_encryption_algorithm: "secretbox"
# Which kubernetes resources to encrypt
kube_encryption_resources: [secrets]

secrets_encryption_query: "resources[*].providers[0].{{ kube_encryption_algorithm }}.keys[0].secret"

## Support tls min version, Possible values: VersionTLS10, VersionTLS11, VersionTLS12, VersionTLS13.
# tls_min_version: ""

## Support tls cipher suites.
# tls_cipher_suites:
#   - TLS_ECDHE_ECDSA_WITH_AES_128_CBC_SHA
#   - TLS_ECDHE_ECDSA_WITH_AES_128_CBC_SHA256
#   - TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256
#   - TLS_ECDHE_ECDSA_WITH_AES_256_CBC_SHA
#   - TLS_ECDHE_ECDSA_WITH_AES_256_GCM_SHA384
#   - TLS_ECDHE_ECDSA_WITH_CHACHA20_POLY1305_SHA256
#   - TLS_ECDHE_ECDSA_WITH_RC4_128_SHA
#   - TLS_ECDHE_RSA_WITH_3DES_EDE_CBC_SHA
#   - TLS_ECDHE_RSA_WITH_AES_128_CBC_SHA
#   - TLS_ECDHE_RSA_WITH_AES_128_CBC_SHA256
#   - TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256
#   - TLS_ECDHE_RSA_WITH_AES_256_CBC_SHA
#   - TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384
#   - TLS_ECDHE_RSA_WITH_CHACHA20_POLY1305_SHA256
#   - TLS_ECDHE_RSA_WITH_RC4_128_SHA
#   - TLS_RSA_WITH_3DES_EDE_CBC_SHA
#   - TLS_RSA_WITH_AES_128_CBC_SHA
#   - TLS_RSA_WITH_AES_128_CBC_SHA256
#   - TLS_RSA_WITH_AES_128_GCM_SHA256
#   - TLS_RSA_WITH_AES_256_CBC_SHA
#   - TLS_RSA_WITH_AES_256_GCM_SHA384
#   - TLS_RSA_WITH_RC4_128_SHA

## Amount of time to retain events. (default 1h0m0s)
event_ttl_duration: "1h0m0s"

## Automatically renew K8S control plane certificates on first Monday of each month
auto_renew_certificates: false
# First Monday of each month
auto_renew_certificates_systemd_calendar: "Mon *-*-1,2,3,4,5,6,7 03:00:00"
# kubeadm renews all the certificates during control plane upgrade.
# If we have requirement like without renewing certs upgrade the cluster,
# we can opt out from the default behavior by setting kubeadm_upgrade_auto_cert_renewal to false
kubeadm_upgrade_auto_cert_renewal: true

# Bash alias of kubectl to interact with Kubernetes cluster much easier
# kubectl_alias: k

## Enable distributed tracing for kube-apiserver
kube_apiserver_tracing: false
kube_apiserver_tracing_endpoint: 0.0.0.0:4317
kube_apiserver_tracing_sampling_rate_per_million: 100

# Enable kubeadm file discovery if anonymous access has been removed
kubeadm_use_file_discovery: "{{ remove_anonymous_access }}"

# Supported asymmetric encryption algorithm types for the cluster's keys and certificates.
# can be one of RSA-2048(default), RSA-3072, RSA-4096, ECDSA-P256
# ref: https://kubernetes.io/docs/reference/config-api/kubeadm-config.v1beta4/#kubeadm-k8s-io-v1beta4-ClusterConfiguration
kube_asymmetric_encryption_algorithm: "RSA-2048"

## roles/kubernetes/kubeadm/defaults/main.yml <==
---
# discovery_timeout modifies the discovery timeout
# This value must be smaller than kubeadm_join_timeout
discovery_timeout: 60s
kubeadm_join_timeout: 120s

# Enable kubeadm file discovery if anonymous access has been removed
kubeadm_use_file_discovery: "{{ remove_anonymous_access }}"

## roles/kubernetes/kubeadm_common/defaults/main.yml <==
---
kubeadm_patches_dir: "{{ kube_config_dir }}/patches"
kubeadm_patches: []
# See https://kubernetes.io/docs/setup/production-environment/tools/kubeadm/control-plane-flags/#patches
# Correspondance with this link
# patchtype = type
# target = target
# suffix -> managed automatically
# extension -> always "yaml"
# kubeadm_patches:
# - target: kube-apiserver|kube-controller-manager|kube-scheduler|etcd|kubeletconfiguration
#   type: strategic(default)|json|merge
#   patch:
#    metadata:
#      annotations:
#        example.com/test: "true"
#      labels:
#        example.com/prod_level: "{{ prod_level }}"
# - ...
# Patches are applied in the order they are specified.

# List of errors to ignore during kubeadm preflight checks
kubeadm_ignore_preflight_errors: []

## roles/kubernetes/node/defaults/main.yml <==
---
# advertised host IP for kubelet. This affects network plugin config. Take caution
kubelet_address: "{{ ip | default(fallback_ip) }}{{ (',' + ip6) if enable_dual_stack_networks and ip6 is defined else '' }}"

# bind address for kubelet. Set to 0.0.0.0 to listen on all interfaces
kubelet_bind_address: "{{ ip | default('0.0.0.0') }}"

# resolv.conf to base dns config
kube_resolv_conf: "/etc/resolv.conf"

# Set to empty to avoid cgroup creation
kubelet_enforce_node_allocatable: "\"\""

# Set runtime and kubelet cgroups when using systemd as cgroup driver (default)
kube_service_cgroups: "{% if kube_reserved %}{{ kube_reserved_cgroups_for_service_slice }}{% else %}system.slice{% endif %}"
kubelet_runtime_cgroups: "/{{ kube_service_cgroups }}/{{ container_manager }}.service"
kubelet_kubelet_cgroups: "/{{ kube_service_cgroups }}/kubelet.service"

# Set runtime and kubelet cgroups when using cgroupfs as cgroup driver
kubelet_runtime_cgroups_cgroupfs: "/system.slice/{{ container_manager }}.service"
kubelet_kubelet_cgroups_cgroupfs: "/system.slice/kubelet.service"

# Set systemd service hardening features
kubelet_systemd_hardening: false

# Kubelet service dependencies other than container runtime
kubelet_systemd_wants_dependencies: []

# List of secure IPs for kubelet
kube_node_addresses: >-
  {%- for host in (groups['k8s_cluster'] | union(groups['etcd'])) -%}
    {{ hostvars[host]['ip'] | default(hostvars[host]['fallback_ip']) }}{{ ' ' if not loop.last else '' }}
  {%- endfor -%}
kubelet_secure_addresses: "localhost link-local {{ kube_pods_subnet }} {{ kube_node_addresses }}"

# Reserve this space for kube resources
# Whether to run kubelet and container-engine daemons in a dedicated cgroup. (Not required for resource reservations).
kube_reserved: false
kube_reserved_cgroups: "/{{ kube_reserved_cgroups_for_service_slice }}"
kube_memory_reserved: "256Mi"
kube_cpu_reserved: "100m"
kube_ephemeral_storage_reserved: "500Mi"
kube_pid_reserved: "1000"

# Set to true to reserve resources for system daemons
system_reserved: false
system_reserved_cgroups_for_service_slice: system.slice
system_reserved_cgroups: "/{{ system_reserved_cgroups_for_service_slice }}"
system_memory_reserved: "512Mi"
system_cpu_reserved: "500m"
system_ephemeral_storage_reserved: "500Mi"
system_pid_reserved: 1000

## Eviction Thresholds to avoid system OOMs
# https://kubernetes.io/docs/tasks/administer-cluster/reserve-compute-resources/#eviction-thresholds
eviction_hard: {}
eviction_hard_control_plane: {}

kubelet_status_update_frequency: 10s

# kube-vip
kube_vip_version: v0.8.0

kube_vip_arp_enabled: false
kube_vip_interface:
kube_vip_services_interface:
kube_vip_cidr: 32
kube_vip_dns_mode: first
kube_vip_controlplane_enabled: false
kube_vip_ddns_enabled: false
kube_vip_cp_detect: false
kube_vip_services_enabled: false
kube_vip_leader_election_enabled: "{{ kube_vip_arp_enabled }}"
kube_vip_bgp_enabled: false
kube_vip_bgp_routerid:
kube_vip_local_as: 65000
kube_vip_bgp_peeraddress:
kube_vip_bgp_peerpass:
kube_vip_bgp_peeras: 65000
kube_vip_bgppeers:
kube_vip_address:
kube_vip_enableServicesElection: false
kube_vip_lb_enable: false
kube_vip_lb_fwdmethod: local
kube_vip_leasename: plndr-cp-lock
kube_vip_svc_leasename: plndr-svcs-lock
kube_vip_leaseduration: 5
kube_vip_renewdeadline: 3
kube_vip_retryperiod: 1
kube_vip_enable_node_labeling: false

# Requests for load balancer app
loadbalancer_apiserver_memory_requests: 32M
loadbalancer_apiserver_cpu_requests: 25m

loadbalancer_apiserver_keepalive_timeout: 5m
loadbalancer_apiserver_pod_name: "{% if loadbalancer_apiserver_type == 'nginx' %}nginx-proxy{% else %}haproxy{% endif %}"

# Uncomment if you need to enable deprecated runtimes
# kube_api_runtime_config:
#   - apps/v1beta1=true
#   - apps/v1beta2=true
#   - extensions/v1beta1/daemonsets=true
#   - extensions/v1beta1/deployments=true
#   - extensions/v1beta1/replicasets=true
#   - extensions/v1beta1/networkpolicies=true

# A port range to reserve for services with NodePort visibility.
# Inclusive at both ends of the range.
kube_apiserver_node_port_range: "30000-32767"

# Configure the amount of pods able to run on single node
# default is equal to application default
kubelet_max_pods: 110

# Sets the maximum number of processes running per Pod
# Default value -1 = unlimited
kubelet_pod_pids_limit: -1

## Support parameters to be passed to kubelet via kubelet-config.yaml
kubelet_config_extra_args: {}

## Parameters to be passed to kubelet via kubelet-config.yaml when cgroupfs is used as cgroup driver
kubelet_config_extra_args_cgroupfs:
  systemCgroups: /system.slice
  cgroupRoot: /

# Maximum number of container log files that can be present for a container.
kubelet_logfiles_max_nr: 5

# Maximum size of the container log file before it is rotated
kubelet_logfiles_max_size: 10Mi

## Support custom flags to be passed to kubelet
kubelet_custom_flags: []

# The read-only port for the Kubelet to serve on with no authentication/authorization.
kube_read_only_port: 0

# Port for healthz for Kubelet
kubelet_healthz_port: 10248

# Bind address for healthz for Kubelet
kubelet_healthz_bind_address: 127.0.0.1

# sysctl_file_path to add sysctl conf to
sysctl_file_path: "/etc/sysctl.d/99-sysctl.conf"

## Support tls min version, Possible values: VersionTLS10, VersionTLS11, VersionTLS12, VersionTLS13.
# tls_min_version: ""

## Support tls cipher suites.
# tls_cipher_suites:
#   - TLS_ECDHE_ECDSA_WITH_AES_128_CBC_SHA
#   - TLS_ECDHE_ECDSA_WITH_AES_128_CBC_SHA256
#   - TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256
#   - TLS_ECDHE_ECDSA_WITH_AES_256_CBC_SHA
#   - TLS_ECDHE_ECDSA_WITH_AES_256_GCM_SHA384
#   - TLS_ECDHE_ECDSA_WITH_CHACHA20_POLY1305_SHA256
#   - TLS_ECDHE_ECDSA_WITH_RC4_128_SHA
#   - TLS_ECDHE_RSA_WITH_3DES_EDE_CBC_SHA
#   - TLS_ECDHE_RSA_WITH_AES_128_CBC_SHA
#   - TLS_ECDHE_RSA_WITH_AES_128_CBC_SHA256
#   - TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256
#   - TLS_ECDHE_RSA_WITH_AES_256_CBC_SHA
#   - TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384
#   - TLS_ECDHE_RSA_WITH_CHACHA20_POLY1305_SHA256
#   - TLS_ECDHE_RSA_WITH_RC4_128_SHA
#   - TLS_RSA_WITH_3DES_EDE_CBC_SHA
#   - TLS_RSA_WITH_AES_128_CBC_SHA
#   - TLS_RSA_WITH_AES_128_CBC_SHA256
#   - TLS_RSA_WITH_AES_128_GCM_SHA256
#   - TLS_RSA_WITH_AES_256_CBC_SHA
#   - TLS_RSA_WITH_AES_256_GCM_SHA384
#   - TLS_RSA_WITH_RC4_128_SHA

kube_proxy_ipvs_modules:
  - ip_vs
  - ip_vs_rr
  - ip_vs_wrr
  - ip_vs_sh
  - ip_vs_wlc
  - ip_vs_lc

# Kubespray will use the first module of this list which it can successfully modprobe
conntrack_modules:
  - nf_conntrack
  - nf_conntrack_ipv4


## Enable distributed tracing for kubelet
kubelet_tracing: false
kubelet_tracing_endpoint: 0.0.0.0:4317
kubelet_tracing_sampling_rate_per_million: 100

# The maximum number of image pulls in parallel. Set it to a integer great than 1 to enable image pulling in parallel.
kubelet_max_parallel_image_pulls: 1

## roles/kubernetes/preinstall/defaults/main.yml <==
---
# Set to true to allow pre-checks to fail and continue deployment
ignore_assert_errors: false

nameservers: []
cloud_resolver: []
disable_host_nameservers: false
epel_enabled: false
# Kubespray sets this to true after clusterDNS is running to apply changes to the host resolv.conf
dns_late: false

# Set to true if your network does not support IPv6
# This may be necessary for pulling Docker images from
# GCE docker repository
disable_ipv6_dns: false

# Remove default cluster search domains (``default.svc.{{ dns_domain }}, svc.{{ dns_domain }}``).
remove_default_searchdomains: false

kube_owner: kube
kube_cert_group: kube-cert
kube_config_dir: /etc/kubernetes
kube_cert_dir: "{{ kube_config_dir }}/ssl"
kube_cert_compat_dir: /etc/kubernetes/pki
kubelet_flexvolumes_plugins_dir: /usr/libexec/kubernetes/kubelet-plugins/volume/exec

# Flatcar Container Linux by Kinvolk cloud init config file to define /etc/resolv.conf content
# for hostnet pods and infra needs
resolveconf_cloud_init_conf: /etc/resolveconf_cloud_init.conf

# All inventory hostnames will be written into each /etc/hosts file.
populate_inventory_to_hosts_file: true
# K8S Api FQDN will be written into /etc/hosts file.
populate_loadbalancer_apiserver_to_hosts_file: true
# etc_hosts_localhost_entries will be written into /etc/hosts file.
populate_localhost_entries_to_hosts_file: true

sysctl_file_path: "/etc/sysctl.d/99-sysctl.conf"

etc_hosts_localhost_entries:
  127.0.0.1:
    expected:
      - localhost
      - localhost.localdomain
  ::1:
    expected:
      - localhost6
      - localhost6.localdomain
    unexpected:
      - localhost
      - localhost.localdomain

# Minimal memory requirement in MB for safety checks
minimal_node_memory_mb: 1024
minimal_master_memory_mb: 1500

yum_repo_dir: /etc/yum.repos.d

# number of times package install task should be retried
pkg_install_retries: 4

# Check if access_ip responds to ping. Set false if your firewall blocks ICMP.
ping_access_ip: true

## NTP Settings
# Start the ntpd or chrony service and enable it at system boot.
ntp_enabled: false
# The package to install which provides NTP functionality.
# The default is ntp for most platforms, or chrony on RHEL/CentOS 7 and later.
# The ntp_package can be one of ['ntp', 'ntpsec', 'chrony']
ntp_package: >-
      {% if ansible_os_family == "RedHat" -%}
      chrony
      {%- else -%}
      ntp
      {%- endif -%}

# Manage the NTP configuration file.
ntp_manage_config: false
# Specify the NTP servers
# Only takes effect when ntp_manage_config is true.
ntp_servers:
  - "0.pool.ntp.org iburst"
  - "1.pool.ntp.org iburst"
  - "2.pool.ntp.org iburst"
  - "3.pool.ntp.org iburst"
# Restrict NTP access to these hosts.
# Only takes effect when ntp_manage_config is true.
ntp_restrict:
  - "127.0.0.1"
  - "::1"
# Specify whether to filter interfaces
ntp_filter_interface: false
# Specify the interfaces
# Only takes effect when ntp_filter_interface is true
# ntp_interfaces:
#   - ignore wildcard
#   - listen xxx
# The NTP driftfile path
# Only takes effect when ntp_manage_config is true.
# Default value is `/var/lib/ntp/ntp.drift`, for ntpsec use '/var/lib/ntpsec/ntp.drift'
ntp_driftfile: >-
      {% if ntp_package == "ntpsec" -%}
      /var/lib/ntpsec/ntp.drift
      {%- else -%}
      /var/lib/ntp/ntp.drift
      {%- endif -%}
# Only takes effect when ntp_manage_config is true.
ntp_tinker_panic: false

# Force sync time immediately after the ntp installed, which is useful in a newly installed system.
ntp_force_sync_immediately: false

# Set the timezone for your server.  eg: "Etc/UTC","Etc/GMT-8". If not set, the timezone will not change.
ntp_timezone: ""

# Currently known os distributions
supported_os_distributions:
  - 'RedHat'
  - 'CentOS'
  - 'Fedora'
  - 'Ubuntu'
  - 'Debian'
  - 'Flatcar'
  - 'Flatcar Container Linux by Kinvolk'
  - 'Suse'
  - 'openSUSE Leap'
  - 'openSUSE Tumbleweed'
  - 'ClearLinux'
  - 'OracleLinux'
  - 'AlmaLinux'
  - 'Rocky'
  - 'Amazon'
  - 'Kylin Linux Advanced Server'
  - 'UnionTech'
  - 'UniontechOS'
  - 'openEuler'

# Extending some distributions into the redhat os family
redhat_os_family_extensions:
  - "UnionTech"
  - "UniontechOS"

# Sets DNSStubListener=no, useful if you get "0.0.0.0:53: bind: address already in use"
systemd_resolved_disable_stub_listener: "{{ ansible_os_family in ['Flatcar', 'Flatcar Container Linux by Kinvolk'] }}"

# Used to disable File Access Policy Daemon service.
# If service is enabled, the CNI plugin installation will fail
disable_fapolicyd: true

## roles/kubespray-defaults/defaults/main/checksums.yml <==
---
crictl_checksums:
  arm:
    v1.32.0: 0
    v1.31.1: 0
    v1.31.0: 0
    v1.30.1: 0
    v1.30.0: 0
  arm64:
    v1.32.0: f2f4e20658b72d00897f41e4b57093c8080e2d800ee894a5f4351f31d1833e30
    v1.31.1: cd70f9b2f75c9619f40450d4b6e2c74aaab619917da517eff6787b442f8b0e56
    v1.31.0: f9879541e92fd302db00b9d28ef617744bb8b8b62520bd4c0479819d7d4ae869
    v1.30.1: 61da7c11926fd29b27e191c3c25d64f2cb51d39dff72a7c90c1fbbc8d5c70f85
    v1.30.0: 3769043fc6018a9e1697fcb768bb89ecd429176bd71e849058916f79a46a07a8
  amd64:
    v1.32.0: f050b71d3a73a91a4e0990b90143ed04dcd100cc66f953736fcb6a2730e283c4
    v1.31.1: 0a03ba6b1e4c253d63627f8d210b2ea07675a8712587e697657b236d06d7d231
    v1.31.0: 9daa32308090aedee5a7f2ab1f1428fef6f669a64e993f0b5b98db8ef6edd71b
    v1.30.1: 71873cdeeeb6c9ee0f79c27b45db38066da81f0c30dcda909b4eedc3aff63f59
    v1.30.0: 3dd03954565808eaeb3a7ffc0e8cb7886a64a9aa94b2bfdfbdc6e2ed94842e49
  ppc64le:
    v1.32.0: 4ffaf29bbda8df42ed2dda4f1ad33cc785987701dc8d1e0043c17cfea9af43e0
    v1.31.1: 8a9f39335601ae3a749d90287a3f0980de01366748b83c0b067c0bf05228ad7d
    v1.31.0: ed545379a61deff415172ea3ca6b847166c5d116c7a1271866286cd0242c09a2
    v1.30.1: bafdeb709f714619c1f91579d485f46b44f1bbce2dc94227a3db761fbeb58664
    v1.30.0: ada550cecb5647014f16dd3ff6c59d7ef7d942ca8cb6c51c15ed019622f39ee9
crio_archive_checksums:
  arm:
    v1.32.0: 0
    v1.31.3: 0
    v1.31.2: 0
    v1.31.1: 0
    v1.31.0: 0
    v1.30.3: 0
    v1.30.2: 0
    v1.30.1: 0
    v1.30.0: 0
  arm64:
    v1.32.0: b092eddabedac98a0f8449dc535acfec0e14c21f59cabe8f9703043d995a1a41
    v1.31.3: 150e828420848d7dc4d190c13b313c7033f9a255a6e656e32b98f27ac574daa0
    v1.31.2: ba0e71699aa7a0e995ac2563b8aee2f2a3358ac120edb8b951e151824f16d5a4
    v1.31.1: 760d00cecaf1b6bf5a3bfae39daa5e46a74408f7a6869cbb41716a5610a7a18f
    v1.31.0: d54afe0140afde0bed09136bd923d8fb415c9016189e7f1b719565ec84edf737
    v1.30.3: 2e47b4b307788b15263256e0e423574c60eec80e17576704df736a7ccc13d7bd
    v1.30.2: 6c0ed1a8a38c65fda45d8b725b8742d247e9f658d8cd6c56baa05bd749b9ccbe
    v1.30.1: 371a6da24dfc7c9e01f29191b36a0629474a37cd8300fa8a36483647a7859b72
    v1.30.0: 7e7c934cebff6433594e4cdc440e1ceb5602741a35d74b2342dac6fb585c3549
  amd64:
    v1.32.0: 8f483f1429d2d9cd6bfa6db2e3a4263151701dd4f05f2b1c06cf8e67c44ea67e
    v1.31.3: 9241c5676934b1cba216abcd573361b72b5a88fe0696ada0ff338db7cee77b4b
    v1.31.2: d035a728c0c3e05e734d69d4a488d7509ac281fa12ae0c228dee257e9da41237
    v1.31.1: ea51b7db06ca97ecf7a76d0341ca168dca102a21fb14f97b1fc139c8e7fb1d47
    v1.31.0: 3cc88ce3c19b2f9bbdfaa1bd42eea64bd7d5ffac6e714a83abbdea40df9ef8c2
    v1.30.3: 622809ec7e21350a3ff7897c7d2cabdf4367b1a5904d346514adc485de3c7172
    v1.30.2: 10be07d2626a093b58a29110e84256029d4c46aeb06a6b41e8bddc30bcfcaa4b
    v1.30.1: 7293f51295d89106e59fe0f83af9599e71fe4f446e1b13c40687ef63ecc1b194
    v1.30.0: c2b189febc9f9cb51f84eecad0da955182e31b98a9f456314546bb83ee2a901a
  ppc64le:
    v1.32.0: e0544544c91f603afaf54ed814c8519883212bcb149f53a8be9bb0c749e9ec86
    v1.31.3: 0ce44aab3645256ac68840e54aa9720ac559c4b877e1566829b4c4b193999b75
    v1.31.2: 57596bb63aef508e86f3b41672816f02a6dee3b1a71ce472756d2c7aed836407
    v1.31.1: 94b3b1b8cebd3a3b3483cbefd11826fadaa240302c4b61f98c29bd2bf3dd72ee
    v1.31.0: 46d901644f86d25dd62f12c16bd88cf26a0b9c400405f571fc5b68abdfefad95
    v1.30.3: 44ed039a1c0c492b14212bbe59c63fe804e3cc525102f47475a5bc0ffd08f4e8
    v1.30.2: 19169b1ef3324c749a0b0105b47288c0ef4949964b340c85229d00234e6148a1
    v1.30.1: e6fb05de749a06316d046e46f8ff4345a413264e63f63dc9e3f1db2cb8a7c962
    v1.30.0: e6fe5c39fa7b7cf8167bb59b94dc9028f8def0c4fec4c1c9028ec4b84da6c53a
# Checksum
# Kubernetes versions above Kubespray's current target version are untested and should be used with caution.
kubelet_checksums:
  arm:
    v1.32.0: 0
    v1.31.4: 0
    v1.31.3: 0
    v1.31.2: 0
    v1.31.1: 0
    v1.31.0: 0
    v1.30.6: 0
    v1.30.5: 0
    v1.30.4: 0
    v1.30.3: 0
    v1.30.2: 0
    v1.30.1: 0
    v1.30.0: 0
  arm64:
    v1.32.0: bda9b2324c96693b38c41ecea051bab4c7c434be5683050b5e19025b50dbc0bf
    v1.31.4: fb6f02f3324a72307acc11998eb5b1c3778167ae165c98f9d49bd011498e72f8
    v1.31.3: 0ec590052f2d1cee158a789d705ca931cbc2556ceed364c4ad754fd36c61be28
    v1.31.2: 118e1b0e85357a81557f9264521c083708f295d7c5f954a4113500fd1afca8f8
    v1.31.1: fbd98311e96b9dcdd73d1688760d410cc70aefce26272ff2f20eef51a7c0d1da
    v1.31.0: b310da449a9d2f8b928cab5ca12a6772617ba421023894e061ca2647e6d9f1c3
    v1.30.8: fdda0047c8c6a59956db72c781705eb705018d00ba594afffdb15ef630f81e28
    v1.30.7: cb9d916c3c3332a400b42271be342728d5660a4b78dfaaf7819db8a58cb4caa4
    v1.30.6: a35e5ab0701b84c03c5cffb142e5de78dc3a5a4af9ba503a6eb3bf8944ded26d
    v1.30.5: 6d11af618f410a186a681b95865539a75146cb908522211520df584f3c09d5cc
    v1.30.4: d3df7a4acff9aba5518930b9c417e8e0ca8cf5e105b7fee6504891fa8f3e962a
    v1.30.3: 41d1926cd7b9c7c250c45f11c8fa9d1946cae98aec2eefc61a2cb4933612bcce
    v1.30.2: 72ceb082311b42032827a936f80cd2437b8eee03053d05dbe36ba48585febfb8
    v1.30.1: c45049b829af876588ec1a30def3884ce77c2c175cd77485d49c78d2064a38fb
    v1.30.0: fa887647422d34f3c7cc5b30fefcf97084d2c3277eff237c5808685ba8e4b15a
  amd64:
    v1.32.0: 5ad4965598773d56a37a8e8429c3dc3d86b4c5c26d8417ab333ae345c053dae2
    v1.31.4: 9062fbb2b6054ecab07b9e841b0a49ab4acc224860b01c218d01ba95017c5e49
    v1.31.3: a5c9e871541251db15436fc307d945217e160d12920730070417ba8037e090df
    v1.31.2: b0de6290267bbb4f6bcd9c4d50bb331e335f8dc47653644ae278844bb04c1fb6
    v1.31.1: 50619fff95bdd7e690c049cc083f495ae0e7c66d0cdf6a8bcad298af5fe28438
    v1.31.0: 39e7f1c61c8389ea7680690f8bd5dd733672fa16875ae598df0fd8c205df57a9
    v1.30.8: 7b5191dfed6a27faadefebdc4a3b602b9a76adfc58fd04c50307f1377eabc590
    v1.30.7: 4b2fb90661e2b7be8b34b5bd405652590f6351a9f55194430fa16d547a7c9d16
    v1.30.6: 9d5585448bc34d37f70171c282febaa10d32687bfee4f8e4467c1bf149674d50
    v1.30.5: 9b4b8f8b33c988372cc9c67791418028ca2cef4a4b4b8d98ab67d6f21275a11a
    v1.30.4: 0c02c0f997b3e9769eae7ca051856054411fca947b3d5409d991ce1964dd0e69
    v1.30.3: 9a37ddd5ea026639b7d85e98fa742e392df7aa5ec917bed0711a451613de3c1c
    v1.30.2: 6923abe67ef069afca61c71c585023840426e802b198298055af3a82e11a4e52
    v1.30.1: 87bd6e5de9c0769c605da5fedb77a35c8b764e3bda1632447883c935dcf219d3
    v1.30.0: 32a32ec3d7e7f8b2648c9dd503ce9ef63b4af1d1677f5b5aed7846fb02d66f18
  ppc64le:
    v1.32.0: 99d409a8023224d84c361e29cdf21ac0458a5449f03e12550288aa654539e3a1
    v1.31.4: 184154c5aa25539cf0547bbcde6d8bee7b8e05984f28da8c996a513787eef8ed
    v1.31.3: 46bd2fcd44ce9ec2a77009ae8248a3fd652305e9866c562b01524a99b18cda7a
    v1.31.2: b7eb859eaa5494273c587b0dcbb75a5a27251df5e140087de542cb7e358d79b1
    v1.31.1: 5b9e8de02f797991670c3f16fa7e46edc7e862644bfa376573c2fca2eaf01519
    v1.31.0: b347b96dd79d3ac09e490669b38c5c2a49b5d73cf82cb619a1c54c6e0a165dbb
    v1.30.8: ef3bc0239b9adbbe33ba024c93a1496a1359faa745b0dd16f7e1b8e42a015c2e
    v1.30.7: 76c7b73c15baf9b07df36ff39e15ec8e144258900d78bbd9501c6239dacf0d33
    v1.30.6: a4641d919d28f4a46e6049862a1de5449b009cfa8ee84066451b94374442ba29
    v1.30.5: ac97aa6ddb6e367ff027c13de8dbd9624a5fe21b6b35546a8603af0ffc608858
    v1.30.4: 50ea965747f3f8c69288aa9268e5c2cc1eb6c3f0b3efa7eba862258bd225d98d
    v1.30.3: c48df46a72ff9764fd1bc54e99b6154772031b1e66c36b0ac5764a5801eadfc0
    v1.30.2: 268dfbb7ee3abcb8ff9fd0a88f81204e40dd33d177f7878941c9ff6b7cca0474
    v1.30.1: 1ac58eae0aa02fefad47d2318bfa5846ae0d7d11a5b691850cd86b2b614ceffe
    v1.30.0: 8d4aa6b10bcddae9a7c754492743cfea88c1c6a4628cab98cdd29bb18d505d03
kubectl_checksums:
  arm:
    v1.32.0: 6b33ea8c80f785fb07be4d021301199ae9ee4f8d7ea037a8ae544d5a7514684e
    v1.31.4: 055d1672f63fda86c6dfa5a2354d627f908f68bde6bf8394fdc9a99cadc4de19
    v1.31.3: e0d00fbac98e67b774ff1ed9a0e6fc5be5c1f08cc69b0c8b483904ed15ad8c50
    v1.31.2: f2a638bdaa4764e82259ed1548ce2c86056e33a3d09147f7f0c2d4ee5b5e300c
    v1.31.1: 51b178c9362a4fbe35644399f113d7f904d306261953a51c5c0a57676e209fa6
    v1.31.0: a4d6292c88c199688a03ea211bea08c8ae29f1794f5deeeef46862088d124baa
    v1.30.8: ef0985c6915c2c23407a2a15dbfe5af71c397178a66afdc8e0e60c5b892c4e99
    v1.30.7: 4e3df1c0cd7e1895467525483a213e8f0f37a778c0cbf485e7a62eeb76c73d0e
    v1.30.6: 20ca85ccceb5f6539a3075d6faaec8bfc6f6351984e59cbe14f00c1b96c57bab
    v1.30.5: ee26c528357330bd1bb036064d7083d6cc66434acc7ddc003c865ddc10e0d17e
    v1.30.4: a31676f522cc745f241b1fd5755b9965558e4f1f5db5149319439a15f49806d1
    v1.30.3: f9147ca81cbcb7b1cf41b75d95a0fd3597defb7c0e6db8c54e6ca7f493929c71
    v1.30.2: 2dab982920d87bc9a17c539bfa4f94b758afc454bb044029dee06144e8dbee08
    v1.30.1: b05c4c4b1c440e8797445b8b15e9f4a00010f1365533a2420b9e68428da19d89
    v1.30.0: ff54e96c73f4b87d740768f77edada7df8f2003f278d3c79bbbaa047b1fc708d
  arm64:
    v1.32.0: ba4004f98f3d3a7b7d2954ff0a424caa2c2b06b78c17b1dccf2acc76a311a896
    v1.31.4: b97e93c20e3be4b8c8fa1235a41b4d77d4f2022ed3d899230dbbbbd43d26f872
    v1.31.3: a3953ad2b32eca0b429249a5fbdf4f8ef7d57223c45cc0401fd80fd12c7b9071
    v1.31.2: bb9fd6e5a92c2e2378954a2f1a8b4ccb2e8ba5a3635f870c3f306a53b359f971
    v1.31.1: 3af2451191e27ecd4ac46bb7f945f76b71e934d54604ca3ffc7fe6f5dd123edb
    v1.31.0: f42832db7d77897514639c6df38214a6d8ae1262ee34943364ec1ffaee6c009c
    v1.30.8: e51d6a76fade0871a9143b64dc62a5ff44f369aa6cb4b04967d93798bf39d15b
    v1.30.7: 5e856defeac209ff82dd473ce46f91a3118df82b863de0d2ed59bdf3558cffca
    v1.30.6: 0b448581f05f46d80219d1a73bd1966de09066c313f64e67e7b75b35e07191cd
    v1.30.5: efc594857f9255fc33bcda9409b8862a3b47ce5f4e09d51c3427b85dd769b9b9
    v1.30.4: 1d8b4e6443c7df8e92a065d88d146142a202fea5ec694135b83d9668529ea3b1
    v1.30.3: c6f9568f930b16101089f1036677bb15a3185e9ed9b8dbce2f518fb5a52b6787
    v1.30.2: 56becf07105fbacd2b70f87f3f696cfbed226cb48d6d89ed7f65ba4acae3f2f8
    v1.30.1: d90446719b815e3abfe7b2c46ddf8b3fda17599f03ab370d6e47b1580c0e869e
    v1.30.0: 669af0cf520757298ea60a8b6eb6b719ba443a9c7d35f36d3fb2fd7513e8c7d2
  amd64:
    v1.32.0: 646d58f6d98ee670a71d9cdffbf6625aeea2849d567f214bc43a35f8ccb7bf70
    v1.31.4: 298e19e9c6c17199011404278f0ff8168a7eca4217edad9097af577023a5620f
    v1.31.3: 981f6b49577068bc174275184d8ee7105d8e54f40733792c519cd85023984c0f
    v1.31.2: 399e9d1995da80b64d2ef3606c1a239018660d8b35209fba3f7b0bc11c631c68
    v1.31.1: 57b514a7facce4ee62c93b8dc21fda8cf62ef3fed22e44ffc9d167eab843b2ae
    v1.31.0: 7c27adc64a84d1c0cc3dcf7bf4b6e916cc00f3f576a2dbac51b318d926032437
    v1.30.8: 7f39bdcf768ce4b8c1428894c70c49c8b4d2eee52f3606eb02f5f7d10f66d692
    v1.30.7: 3950ec7b81b9aa5a3856dd6155e42e1ad12a2fa8b050502f5a9652050f94a8ee
    v1.30.6: 7a3adf80ca74b1b2afdfc7f4570f0005ca03c2812367ffb6ee2f731d66e45e61
    v1.30.5: b8aa921a580c3d8ba473236815de5ce5173d6fbfa2ccff453fa5eef46cc5ee7a
    v1.30.4: 2ffd023712bbc1a9390dbd8c0c15201c165a69d394787ef03eda3eccb4b9ac06
    v1.30.3: abd83816bd236b266c3643e6c852b446f068fe260f3296af1a25b550854ec7e5
    v1.30.2: c6e9c45ce3f82c90663e3c30db3b27c167e8b19d83ed4048b61c1013f6a7c66e
    v1.30.1: 5b86f0b06e1a5ba6f8f00e2b01e8ed39407729c4990aeda961f83a586f975e8a
    v1.30.0: 7c3807c0f5c1b30110a2ff1e55da1d112a6d0096201f1beb81b269f582b5d1c5
  ppc64le:
    v1.32.0: 9f3f239e2601ce53ec4e70b80b7684f9c89817cc9938ed0bb14f125a3c4f8c8f
    v1.31.4: 5089625fc8f4dc7082c6e0186a839c8d4e791ad15bcbbc586d4839f25f12a3df
    v1.31.3: a5855c5fb02cc40c68eee603f08a5c5bcf86d85e6c9e757f450d4fd6138e89d4
    v1.31.2: 3a9405b1f8f606f282abb03bf3f926d160be454c21b3867505f15ad2123d4139
    v1.31.1: 635275e4b207902bc6dda29de898e5152229271c46cb9613340e36c3abc2cb67
    v1.31.0: 92393bc295423429522fa8c49724f95f31fa9bf20062d2c123e928d08886c95d
    v1.30.8: 76b7ecd7212c939271493204c726e8e7ea56ac748005c901bec3f6598ee479e0
    v1.30.7: 7992f401b75399ea8a1ded372badf75da643835f0fe4645f0668c3720006a3cd
    v1.30.6: 54ae05b59c52edea26e1d4009b5e469be96d582ddbe388f33d3b07a66caf7ac8
    v1.30.5: 1289eec1144607b5b11bb4f1bdbba6ee92880f4703c9349c83b47ae6d66d9614
    v1.30.4: a913b4b8573d356483d5c7f14d2cecb290b41ab3b58812567b54ce09e763aad9
    v1.30.3: 3f2ba2216e43b833251a570b1218cba61d43ef2734c0a7751d281656066ab30b
    v1.30.2: 738bc1bad45df79fc4313d167a68ed5a1cf747f1f94e4434f0733e3126989f2e
    v1.30.1: ef01ae21e91600469db3df01172144fac6c61083e7d3282bef72ce732d76d0d8
    v1.30.0: f8a9eac6e12bc8ab7debe6c197d6536f5b3a9f199e8837afd8e4405291351811
kubeadm_checksums:
  arm:
    v1.32.0: 0
    v1.31.4: 0
    v1.31.3: 0
    v1.31.2: 0
    v1.31.1: 0
    v1.31.0: 0
    v1.30.6: 0
    v1.30.5: 0
    v1.30.4: 0
    v1.30.3: 0
    v1.30.2: 0
    v1.30.1: 0
    v1.30.0: 0
  arm64:
    v1.32.0: 5da9746a449a3b8a8312b6dd8c48dcb861036cf394306cfbc66a298ba1e8fbde
    v1.31.4: 4598c2f0c69e60feb47a070376da358f16efe0e1403c6aca97fa8f7ab1d0e7c0
    v1.31.3: 8113900524bd1c8b3ce0b3ece0d37f96291cbf359946afae58a596319a5575c8
    v1.31.2: 0f9d231569b3195504f8458415e9b3080e23fb6a749fe7752abfc7a2884efadf
    v1.31.1: 66195cd53cda3c73c9ae5e49a1352c710c0ea9ce244bbdeb68b917d809f0ea78
    v1.31.0: dbeb84862d844d58f67ad6be64021681a314cda162a04e6047f376f2a9ad0226
    v1.30.8: 7bca884b54e2c3988e81250f8eba6a49d718994dd7fe67d14905cb65dcec8b56
    v1.30.7: 3684d219d3398964038d87bf609266149cd898d810a52d21a4a6534f8a187ba8
    v1.30.6: 6206938156e079d1c3031ba9a291e720c9f04031492753759b93bc3b67b3390b
    v1.30.5: 08b8d17ac39a49b3ebb88a756599496c71e63b756884e88127654bc5c51128e5
    v1.30.4: 609afad8590afb39b500cc5175c64b17690f7bf0b0eebcf1d347656d262e5c8c
    v1.30.3: 6590f2447c87346aac29e2ab42fe4f29873f9bf154ee878f00da4c81bfdb8ea2
    v1.30.2: 7268762b7afd44bf07619985dd52c376b63e47d73b8f9a3b08cc49624a8fbd55
    v1.30.1: bda423cb4b9d056f99a2ef116bdf227fadbc1c3309fa3d76da571427a7f41478
    v1.30.0: c36afd28921303e6db8e58274de16c60a80a1e75030fc3c4e9c4ed6249b6b696
  amd64:
    v1.32.0: 8a10abe691a693d6deeeb1c992bc75da9d8c76718a22327688f7eb1d7c15f0d6
    v1.31.4: 6c8e2fd2fa2cab51debf215fcb9149b94e7046f69ff558290066875200975cf6
    v1.31.3: dcfcc6eb79e94994d5f1b04a7746239214030ce8a2e8b0e21a4772938f911d12
    v1.31.2: e3d3f1051d9f7e431aabaf433f121c76fcf6d8401b7ea51f4c7af65af44f1e54
    v1.31.1: b3f92d19d482359116dd9ee9c0a10cb86e32a2a2aef79b853d5f07d6a093b0df
    v1.31.0: cf3b1a44b11ab226e40610e63d99fae7588a82940bb77da471a6dec624c819c2
    v1.30.8: ffe1a2b6345fae55e059afe7eed90ae9f46f0a755fde5fc17b9113134ab8b79e
    v1.30.7: 3635901a3a6e5b0124547151de700a1dbd4571531327a32edbec43bb155b877b
    v1.30.6: 216b7728c6eca12a6a21a7e4199d898d4b88cf8f489a63c2779e2e525302cca7
    v1.30.5: b91e32e527d3941369cee016fccb6cb12cd214a120a81d8c5f84c7cbc9e120b2
    v1.30.4: 6c6053fb8b31030ef7fffe146eb29489f7bf53d7a5ca10e0b10c907bf4b7e281
    v1.30.3: bb78c2a27027278ee644d523f583ed7fdba48b4fbf31e3cfb0e309b6457dda69
    v1.30.2: 672b0cae2accce5eac10a1fe4ea6b166e5b518c79ccf71a2fbe7b53c2ca74062
    v1.30.1: 651faa3bbbfb368ed00460e4d11732614310b690b767c51810a7b638cc0961a2
    v1.30.0: 29f4232c50e6524abba3443ff3b9948d386964d79eb8dfefb409e1f8a8434c14
  ppc64le:
    v1.32.0: d79fe8cbd1d98bcbe56b8c0c3a64716603581cecf274951af49aa07748bf175a
    v1.31.4: 9d0a6abf9595f79660f29625ed649df4f64369e1552aa68eb7ad49b45455ab04
    v1.31.3: 646130bbb60949bdc9b7a449298537369b0eff0ff39b9f7f4222a4760ab824be
    v1.31.2: 57771542703fbb18916728b3701298fda62f28a1d9f144ae3712846d2bb50f8a
    v1.31.1: 76667e109e2dfcb332820c35f598b6f588b6f18c8b59acfb956fb9b4995dda4e
    v1.31.0: 002307ea116a5aa5f78d3d9fb00e9981593711fb79fdfc9be0a9857c370bdcf3
    v1.30.8: 48b8eefb82a9b5646286bb0479dea8c690da62b1bf9b8d5515cd854316837ad5
    v1.30.7: 62d1cd87f541b5eb179b968577e26d72e23b053f3eee4946bbc1a61dc9b6a03d
    v1.30.6: 8febc55f1a984b23deb3ecca2dfe7073180f462636512dbfdfb69537c0783ec2
    v1.30.5: 996a353e6a443a1d88fa2aff93beb9f6b3073c53d0565dcccc2886642ce79c05
    v1.30.4: df0a42a57e69f3080871736d0953f1f287f63def0ed514324aca2469463efd7a
    v1.30.3: 76a58a7389365295fb4ea1163c2644c3700f066a8e8cb1b7897ad83576e43ce2
    v1.30.2: 8aee71554003411470a5933cdff7896736ae1182055c0de6bb3782d0a7581c71
    v1.30.1: dc529fae8227422a23a8d4f70e28161fa207a4da7cb24d340aae0592dd729ea5
    v1.30.0: a77badcaff292862df8324e17f74ab7ce3c6ea9f390647878f1838a3a832f413
etcd_binary_checksums:
  arm:
    v3.5.16: 0
    v3.5.15: 0
    v3.5.14: 0
    v3.5.13: 0
    v3.5.12: 0
    v3.5.11: 0
    v3.5.10: 0
    v3.5.9: 0
    v3.5.8: 0
    v3.5.7: 0
    v3.5.6: 0
  arm64:
    v3.5.16: 8e68c55e6d72b791a9e98591c755af36f6f55aa9eca63767822cd8a3817fdb23
    v3.5.15: 5aa28b435edb1f22bf6455f754e16a13e3e4eb1ad8fc7c22ad47aa8e722febf2
    v3.5.14: 90510c79c4aae3c3313691f5770fc53b3ac883338fc0254bf8d22460acd3c19d
    v3.5.13: 2854993bf622764ccdeb7a146fae2965cb0fcba93c5c8f391e0d5f153c8a7a02
    v3.5.12: 31f30c01918771ece28d6e553e0f33be9483ced989896ecf6bbe1edb07786141
    v3.5.11: 6edf0cddc8fa2d7674129abe2e44d5a37cc3a6e3b500c13c6cbc2ed2ecf08bf4
    v3.5.10: ff74a6018d9b2a1320bff30e5a11b4f2f5c2a3d147df8a8bad53c01b9f800ee1
    v3.5.9: bb201c106a61bbab59e2d9f37f4bdff99d50201f513c66b4578741eab581fb28
    v3.5.8: 3f4441b293a2d0d4d2f8b2cd9504376e15818f7b865ef4b436e8e6f865f895ff
    v3.5.7: 1a35314900da7db006b198dd917e923459b462128101736c63a3cda57ecdbf51
    v3.5.6: 888e25c9c94702ac1254c7655709b44bb3711ebaabd3cb05439f3dd1f2b51a87
  amd64:
    v3.5.16: b414b27a5ad05f7cb01395c447c85d3227e3fb1c176e51757a283b817f645ccc
    v3.5.15: 3f6b48d8c2844699f2b19c1880508ecf63e1489769ed37ebb97495d5cd848a89
    v3.5.14: b0b34298f53f6830f08e7ddc57fc74dc45563216a66e94d9e6b0b9e0b0281b34
    v3.5.13: 31e6fcbee0e8c3df27cf1ba69b522e338377f5ed6447f5d05700aee367f3b7e7
    v3.5.12: f2ff0cb43ce119f55a85012255609b61c64263baea83aa7c8e6846c0938adca5
    v3.5.11: e256885e753dc99001335e099d3c2eb8cf21a865a087ee4d7e3665752ae5929a
    v3.5.10: 26e90d024fa2310bc52bb40e7f2132e81640b55f8fc446c00ae07e30af2a44fd
    v3.5.9: d59017044eb776597eca480432081c5bb26f318ad292967029af1f62b588b042
    v3.5.8: d4c1b8d90ad53658f12ffc293afc5694b7bc6cb093af609188649a799e1cc8dc
    v3.5.7: a43119af79c592a874e8f59c4f23832297849d0c479338f9df36e196b86bc396
    v3.5.6: 4db32e3bc06dd0999e2171f76a87c1cffed8369475ec7aa7abee9023635670fb
  ppc64le:
    v3.5.16: 33322806f4a2aa3d4947a4d42ec6a120296535e7f00e2f9d74e515e9386333e0
    v3.5.15: 6512f7308a0d0af7c9bb46bca1c4f4e816304304d838d1045ae21d9772c5490e
    v3.5.14: 01681d4d33bba5130c9cffca42c35b0f68e0d991b0b4ee65dab6fd36568d4fee
    v3.5.13: f372b524e2c118dbb0dbe1097474a072fc93bc30da65efa92999137303bcd9a7
    v3.5.12: ebd8060508d572678d8d1e4f90f87863e3a6cfcba856ceca32379b03251c0597
    v3.5.11: a2e70b291811fa8ccc34cc7d297bf7d31e3af790bc31e54cad034a49e9db2eb7
    v3.5.10: 10cd8e4ecf6718b9712bf2edfac2e4924d7f21dbe58d368e6e10578c85bd8c01
    v3.5.9: 551539ebb344ebdc77f170ea51512a6cda35877ffdcbd8b3316b2495a8b2bd87
    v3.5.8: 20e28302c1424b1a3daf7d817f2662e4c64e395a82765d1696cb53cb6bc37a4e
    v3.5.7: e861aa6acd4d326ec01bfa06fffb80d33f3f8c26e0eb8b73e4424578d149bd04
    v3.5.6: e235cb885996b8aac133975e0077eaf0a2f8dc7062ad052fa7395668a365906b
cni_binary_checksums:
  arm:
    v1.4.0: 6cddc5804fff93b914f3314d62fa03f24d69f59c03940e0bbe85a370371b5bb8
    v1.3.0: 86c4c866a01a8073ad14f6feec74de1fd63669786850c7be47521433f9570902
    v1.2.0: fde5bf2da73995196d248177ee8deeafa8005f33cbe1ab33bd2d75c17ca5a99a
    v1.1.1: 84f97baf80f9670a8cd0308dedcc8405d2bbc65166d670b48795e0d1262b4248
    v1.1.0: 91e03a9287dcf8d0249159c90357b0f871ecf7ef0ca5014b2e143f2b30ae9c6d
    v1.0.1: d35e3e9fd71687fc7e165f7dc7b1e35654b8012995bbfd937946b0681926d62d
    v1.0.0: 910c2ba8b6f50b1081b219d6db04459b555940973249fcf39a792932a91f6d39
  arm64:
    v1.4.0: 304d4389d5b732b7a73513d002c4895f731d030682d40653f411e10e39114194
    v1.3.0: de7a666fd6ad83a228086bd55756db62ef335a193d1b143d910b69f079e30598
    v1.2.0: 525e2b62ba92a1b6f3dc9612449a84aa61652e680f7ebf4eff579795fe464b57
    v1.1.1: 16484966a46b4692028ba32d16afd994e079dc2cc63fbc2191d7bfaf5e11f3dd
    v1.1.0: 33fc7b8d9d5be2d7f95e69e6a9e2af206879942f1e6b7615c04017dce5067f1a
    v1.0.1: 2d4528c45bdd0a8875f849a75082bc4eafe95cb61f9bcc10a6db38a031f67226
    v1.0.0: 736335bc5923a37cfb6cc2305489ce6206bcc565004f525b5f7c3604f092aa3a
  amd64:
    v1.4.0: c2485ddb3ffc176578ae30ae58137f0b88e50f7c7f2af7d53a569276b2949a33
    v1.3.0: 754a71ed60a4bd08726c3af705a7d55ee3df03122b12e389fdba4bea35d7dd7e
    v1.2.0: f3a841324845ca6bf0d4091b4fc7f97e18a623172158b72fc3fdcdb9d42d2d37
    v1.1.1: b275772da4026d2161bf8a8b41ed4786754c8a93ebfb6564006d5da7f23831e5
    v1.1.0: 05d46ac19d01669d424ee57401c0deba101763ac494858064b4ea4ffdcc37c5d
    v1.0.1: 5238fbb2767cbf6aae736ad97a7aa29167525dcd405196dfbc064672a730d3cf
    v1.0.0: 5894883eebe3e38f4474810d334b00dc5ec59bd01332d1f92ca4eb142a67d2e8
  ppc64le:
    v1.4.0: c87a36a75ad1692933e3218cae734ba809ae2190c725a050ac9033fc96d2ed26
    v1.3.0: 8ceff026f4eccf33c261b4153af6911e10784ac169d08c1d86cf6887b9f4e99b
    v1.2.0: 4960283b88d53b8c45ff7a938a6b398724005313e0388e0a36bd6d0b2bb5acdc
    v1.1.1: 1551259fbfe861d942846bee028d5a85f492393e04bcd6609ac8aaa7a3d71431
    v1.1.0: 98239a57452e93c0a27ba9f87bcbb80c7f982f225246f3fe4f3f5ac9b6b1becb
    v1.0.1: f078e33067e6daaef3a3a5010d6440f2464b7973dec3ca0b5d5be22fdcb1fd96
    v1.0.0: 1a055924b1b859c54a97dc14894ecaa9b81d6d949530b9544f0af4173f5a8f2a
calicoctl_binary_checksums:
  arm:
    v3.29.1: 0
    v3.29.0: 0
    v3.28.2: 0
    v3.28.1: 0
    v3.28.0: 0
    v3.27.5: 0
    v3.27.4: 0
    v3.27.3: 0
    v3.27.2: 0
    v3.27.1: 0
    v3.27.0: 0
  arm64:
    v3.29.1: 6f662d316a267854dc5487242ca7ec8ca70c35b52bed258aafb76c2d113643c2
    v3.29.0: ab23afb283fcdffcf0e1156cdced68d05b6c2b70fd4ea2cbc3189d0ecd43bdfd
    v3.28.2: 8ebe965424ac94084499182b2853de62e5d18cdc346a3b8974e991d8b7a9592d
    v3.28.1: c062d13534498a427c793a4a9190be4df3cf796a3feb29e4a501e1d6f48daa7c
    v3.28.0: c4ca8563d2a920729116a3a30171c481580c8c447938ce974ce14d7ce25a31bf
    v3.27.5: 1c929538565c9f885debb45cc38b3efb4e58d362400163a2eff2b56fad838334
    v3.27.4: 8544b601a67e0594009dafef6d3237fcf6f32fb64726c09abc1f2ce9d6819496
    v3.27.3: 1fc5f58a18d8b1c487b4663fc5cbe23b45bd9d31617debd309f6dfac7c11a8ef
    v3.27.2: 0fd1f65a511338cf9940835987d420c94ab95b5386288ba9673b736a4d347463
    v3.27.1: 0
    v3.27.0: b4b8c71f9658165e45336b9b5e4fad865529feeffe4294247eb5b4c4310dcaf9
  amd64:
    v3.29.1: 2ac849181cb1fb40c61c06d075711025cdb909d80562d078cc548d50a0edcd3d
    v3.29.0: df5048549d72a1f7ea4f61c655699d3b16d8a45873f28c3855c39597b73e8a3d
    v3.28.2: d7f30447f0f59262051b95bdc656407442c4f71066dc37ddd3b676108fab569d
    v3.28.1: 22ec5727c38dbe19001792b4ca64ac760a6e2985d5c1a231d919dbebe5bca171
    v3.28.0: 4ea270699e67ca29e5533ddb0a68d370cb0005475796c7e841f83047da6297b6
    v3.27.5: 0a63022166b353ebea49a2f250793019edf531dd5cdb0655da746e7c243aacba
    v3.27.4: 84f2bd29ef7b06e85a2caf0b6c6e0d3da5ab5264d46b360e6baaf49bbc3b957d
    v3.27.3: e22b8bb41684f8ffb5143b50bf3b2ab76985604d774d397cfb6fb11d8a19f326
    v3.27.2: 692f69dc656e41cd35e23e24f56c98c4aeeb723fed129985b46f71e6eb5e1594
    v3.27.1: 0
    v3.27.0: 46e79ae146b3dd90998f56511cf5d6db64deb97cb784235caf1f99e0672d66e4
  ppc64le:
    v3.29.1: ef6064f2ec1a09b5eb8c43ab0c64bd42785c24f5b22b950583fb5074f472c2b7
    v3.29.0: c9c2a29a349c6f681aa79b5f5d6aee738305d95aa7f158b6217f487808758e53
    v3.28.2: 9889a2f9c26ae82a501b33440b3a0772f552a4ece128cd57a21e395452b4238f
    v3.28.1: 985caad36fed7b883a2cd4cf91e556974bcca95fe4e6b7ff4cb64d8d8fbe9223
    v3.28.0: 0789cb0d1478ec3f0a44db265b19042be9dfc18bc1776343c7ea8d246561d12b
    v3.27.5: 7b8c8936e55e319b94d1fb71dacbef7617661f76241a4ed16289b5a2165fa62d
    v3.27.4: 1d44e119d9836eb4715f42a915a849377f7d6a6881b73ce66d0c95092e29d4f2
    v3.27.3: 5f2ac510c0ec31ec4c02ff2660f2502b68b655616d5b766a51bd99d2e3604fbc
    v3.27.2: f918bb88de1d01de3d143e1e75d0ee1256f247c5cbabec7d665aaf8d1fd3cc6c
    v3.27.1: 0
    v3.27.0: 3de46d8bc30c6f9d9387d484ed62a5655c1f204b1b831b5a90f0a0d1c1ffd752
ciliumcli_binary_checksums:
  arm:
    v0.16.0: 0
    v0.15.23: 0
    v0.15.22: 0
    v0.15.21: 0
    v0.15.20: 0
    v0.15.19: 0
    v0.15.18: 0
    v0.15.17: 0
    v0.15.16: 0
    v0.15.15: 0
  arm64:
    v0.16.0: fe16bcd447fc6fe764ca75712f5832d7504845e9f782684ff09c9f52548237fe
    v0.15.23: 9aa37d99a15e72bbcb555d7ed5b88c2ae3a7e6fbc478f9ee402a835ba6b41175
    v0.15.22: 23caf44dade82b5a986e9799db333724845750bebe32e571a356ab9116406f6d
    v0.15.21: 346bf2d0d60e11e02c676bcd7cb379cbedd88830188dbf811ad7099f5907da9d
    v0.15.20: 4b05fb1661b699edd89f37124d5cd0aa4f5dcfc197cef6a0bc7a6faa3dc119d4
    v0.15.19: a32521b2add0203c1945f71c6d8a50739946b4f7e35c2636529a5063959072d4
    v0.15.18: fa1aecaf1c69663bdece17608c6e85f0a5a2c8ee8fe2cbbadf25cbe887b7ae15
    v0.15.17: 4df6f634512a0e426258fbb83d43c0defabe9d91c81480c040af08fa05b4a989
    v0.15.16: 86ed6a2e796c39dd00072e7c141fc35b68d63392d1ac5e183a7ce9d7263e23a0
    v0.15.15: 5c1693ea163b094a92ebc6997b6e678cc8c24a52040c22433b58b419de74b28f
  amd64:
    v0.16.0: da98675f961833d4ffd68b1046d907b228a7d394ded2abd70a50b20eaca171c4
    v0.15.23: cda3f1c40ae2191a250a7cea9e2c3987eaa81cb657dda54cd8ce25f856c384da
    v0.15.22: c9bdf99362c16bb63ea44a214e39319d8ac1d196345792caae9665f36fe274a3
    v0.15.21: 89190bb3fdcde892d7a8d3a9718e5ffacd312d2535eee54d93ccc81c2d430cb7
    v0.15.20: a1a09f3f0176e118b1b00be4fcd7f9f32f27c9587c64b5579d2747d751e72e23
    v0.15.19: 9632fa506d7d0e0298dc5b80b9e05239ceb01d60b124dde2132417a96ba4d07b
    v0.15.18: b10359784d4c194d43bbd1de5d7000f9697e451049008ade5a0754e3c4f7958e
    v0.15.17: ed8edbce96ac7921ee75b2fbe42409fbe381e2f8f896c10d13f864cc52e07a43
    v0.15.16: f30095e1a0b926d2114b7a419141bea76e950b643182e97e666950ca05a205d9
    v0.15.15: 492279c1f960c79747290a5d1e1b21084a04a93f9e13ab4ae7df4c76fe808aff
  ppc64le:
    v0.16.0: 0
    v0.15.23: 0
    v0.15.22: 0
    v0.15.21: 0
    v0.15.20: 0
    v0.15.19: 0
    v0.15.18: 0
    v0.15.17: 0
    v0.15.16: 0
    v0.15.15: 0
calico_crds_archive_checksums:
  v3.29.1: 17894ed9f7487f1418e599fdeff5db9047374dee12d560114e25ff9147a455c3
  v3.29.0: 403a6b8616c4e97b081d7be27e9024f2f66b2d73a0ea037420a29689205b2064
  v3.28.2: f02a0e99e060850bd9050d4c94d37df899911a5e357e1d26e1b5b79a923bb389
  v3.28.1: c56f1530e7ded9d5b4afb9d83a7a24da6d2959ef7ad38521813f1c2bf138182d
  v3.28.0: ee721337db0cd847e91aae1cdfd420596896ebcb865575fd913c2f12ac2cdb76
  v3.27.5: f9cca65b96ab05732ed1902afd0f3086be54d6bb6b47c86a289ecf4ea5cdc25d
  v3.27.4: 5f6ac510bd6bd8c14542afe91f7dbcf2a846dba02ae3152a3b07a1bfdea96078
  v3.27.3: d11a32919bff389f642af5df8180ad3cec586030decd35adb2a7d4a8aa3b298e
  v3.27.2: 8154bb4aad887f2a5500b505fe203a918f72c4e602b04c688c4b94f76a26e925
  v3.27.1: 76abb0db222af279e3514cfae02be9259097b565bbb2ffcb776ca00566480edb
  v3.27.0: 2a4b5132035dfd6ac4abc8d545f33de139350eca523e0c5cfe4ac32e43fcb2f1
krew_archive_checksums:
  darwin:
    arm:
      v0.4.4: 0
      v0.4.3: 0
    arm64:
      v0.4.4: e6ac776140b228d6bdfda11247baf4e9b11068f42005d0975fc260c629954464
      v0.4.3: 22f29ce3c3c9c030e2eaf3939d2b00f0187dfdbbfaee37fba8ffaadc46e51372
    amd64:
      v0.4.4: 5f4d2f34868a87cf1188212cf7cb598e76a32f389054089aad1fa46e6daf1e1b
      v0.4.3: 6f6a774f03ad4190a709d7d4dcbb4af956ca0eb308cb0d0a44abc90777b0b21a
    ppc64le:
      v0.4.4: 0
      v0.4.3: 0
  linux:
    arm:
      v0.4.4: 4f3d550227e014f3ba7c72031108ffda0654cb755f70eb96be413a5102d23333
      v0.4.3: 68eb9e9f5bba29c7c19fb52bfc43a31300f92282a4e81f0c51ad26ed2c73eb03
    arm64:
      v0.4.4: f8f0cdbf698ed3e8cb46e7bd213754701341a10e11ccb69c90d4863e0cf5a16a
      v0.4.3: 0994923848882ad0d4825d5af1dc227687a10a02688f785709b03549dd34d71d
    amd64:
      v0.4.4: e471396b0ed4f2be092b4854cc030dfcbb12b86197972e7bef0cb89ad9c72477
      v0.4.3: 5df32eaa0e888a2566439c4ccb2ef3a3e6e89522f2f2126030171e2585585e4f
    ppc64le:
      v0.4.4: 0
      v0.4.3: 0
  windows:
    arm:
      v0.4.4: 0
      v0.4.3: 0
    arm64:
      v0.4.4: 0
      v0.4.3: 0
    amd64:
      v0.4.4: da0dfeb2a598f11fb9ce871ee7f3b1a69beb371a45f531ee65a71b2201511d28
      v0.4.3: d1343a366a867e9de60b23cc3d8ee935ee185af25ff8f717a5e696ba3cae7c85
    ppc64le:
      v0.4.4: 0
      v0.4.3: 0
helm_archive_checksums:
  arm:
    v3.16.4: 432e774d1087d3773737888d384c62477b399227662b42cbf0c32e95e6e72556
    v3.16.3: 02ba2f3b1524113f49be6df25a0b4b3190010d6e218c8e2b2fde4578a8439a9c
    v3.16.2: f0f606d0806a518b749bd82e8dbfe6a803aa33340215590ef3977c60e366ba82
    v3.16.1: a15a8ddfc373628b13cd2a987206756004091a1f6a91c3b9ee8de6f0b1e2ce90
    v3.16.0: 73efcd63d1b7f1d9db6afc2e039e03a638fe43d3633735363184692ebc8eef02
    v3.15.4: aa3fb3014d147e5dcf8bfe4f6d5fe8677029ed720d4a4bcc64e54cb745a72206
    v3.15.3: 77a9c9699c836dd34fca3d9e783f9e70e0ddbe1a4b44aa13fac82f6193da452f
    v3.15.2: 2b28fda1d8c6f087011bc7ec820051a13409dadce8385529f306476632e24e85
    v3.15.1: fa7a8b472c8f311ac618a231218511efeafad306781d11ad68976e0461074b0e
    v3.15.0: 614d53ab1192667facce7e8d4e884ff067e5684199a7e5223e8808abc43e927f
    v3.14.4: 962297c944c06e1f275111a6e3d80e37c9e9e8fed967d4abec8efcf7fc9fb260
    v3.14.3: d4ff88f02d6731ec5dbde86a67bf391e673d0d9e87901727fbf62372aff106ec
    v3.14.2: b70fb6fa2cdf0a5c782320c9d7e7b155fcaec260169218c98316bb3cf0d431d9
    v3.14.1: f50c00c262b74435530e677bcec07637aaeda1ed92ef809b49581a4e6182cbbe
    v3.14.0: cf38dfdead7266ae56662743bda0c78655814f0adeca382d1b07a812bb1a599a
  arm64:
    v3.16.4: d3f8f15b3d9ec8c8678fbf3280c3e5902efabe5912e2f9fcf29107efbc8ead69
    v3.16.3: 5bd34ed774df6914b323ff84a0a156ea6ff2ba1eaf0113962fa773f3f9def798
    v3.16.2: 1888301aeb7d08a03b6d9f4d2b73dcd09b89c41577e80e3455c113629fc657a4
    v3.16.1: 780b5b86f0db5546769b3e9f0204713bbdd2f6696dfdaac122fbe7f2f31541d2
    v3.16.0: fc121590b532d7f2037ae5cdd39d2b56dec96069d8bc613a08965f29a156e84f
    v3.15.4: fa419ecb139442e8a594c242343fafb7a46af3af34041c4eac1efcc49d74e626
    v3.15.3: bd57697305ba46fef3299b50168a34faa777dd2cf5b43b50df92cca7ed118cce
    v3.15.2: adcf07b08484b52508e5cbc8b5f4b0b0db50342f7bc487ecd88b8948b680e6a7
    v3.15.1: b4c5519b18f01dd2441f5e09497913dc1da1a1eec209033ae792a8d45b9e0e86
    v3.15.0: c3b0281fca4c030548211dd6e9b032ee0a9fc53eab614f6acbaff631682ce808
    v3.14.4: 113ccc53b7c57c2aba0cd0aa560b5500841b18b5210d78641acfddc53dac8ab2
    v3.14.3: 85e1573e76fa60af14ba7e9ec75db2129b6884203be866893fa0b3f7e41ccd5e
    v3.14.2: c65d6a9557bb359abc2c0d26670de850b52327dc3976ad6f9e14c298ea3e1b61
    v3.14.1: f865b8ad4228fd0990bbc5b50615eb6cb9eb31c9a9ca7238401ed897bbbe9033
    v3.14.0: b29e61674731b15f6ad3d1a3118a99d3cc2ab25a911aad1b8ac8c72d5a9d2952
  amd64:
    v3.16.4: fc307327959aa38ed8f9f7e66d45492bb022a66c3e5da6063958254b9767d179
    v3.16.3: f5355c79190951eed23c5432a3b920e071f4c00a64f75e077de0dd4cb7b294ea
    v3.16.2: 9318379b847e333460d33d291d4c088156299a26cd93d570a7f5d0c36e50b5bb
    v3.16.1: e57e826410269d72be3113333dbfaac0d8dfdd1b0cc4e9cb08bdf97722731ca9
    v3.16.0: 327cfbc7ddc5a3eb644039ceb0cff66394628654c4f5a76bf715ed15b893983b
    v3.15.4: 11400fecfc07fd6f034863e4e0c4c4445594673fd2a129e701fe41f31170cfa9
    v3.15.3: ad871aecb0c9fd96aa6702f6b79e87556c8998c2e714a4959bf71ee31282ac9c
    v3.15.2: 2694b91c3e501cff57caf650e639604a274645f61af2ea4d601677b746b44fe2
    v3.15.1: 7b20e7791c04ea71e7fe0cbe11f1a8be4a55a692898b57d9db28f3b0c1d52f11
    v3.15.0: a74747ac40777b86d3ff6f1be201504bba65ca46cd68b5fe25d3c394d0dcf745
    v3.14.4: a5844ef2c38ef6ddf3b5a8f7d91e7e0e8ebc39a38bb3fc8013d629c1ef29c259
    v3.14.3: 3c90f24e180f8c207b8a18e5ec82cb0fa49858a7a0a86e4ed52a98398681e00b
    v3.14.2: 0885a501d586c1e949e9b113bf3fb3290b0bbf74db9444a1d8c2723a143006a5
    v3.14.1: 75496ea824f92305ff7d28af37f4af57536bf5138399c824dff997b9d239dd42
    v3.14.0: f43e1c3387de24547506ab05d24e5309c0ce0b228c23bd8aa64e9ec4b8206651
  ppc64le:
    v3.16.4: 0ba4375a6dcf6117a8e7729fbed36d9220f8ad98dbc7aabc16186f22917caead
    v3.16.3: 266f7698c56a724fddd3a2f2b862ad496c4338dce79f0282fdbc6e23e1738608
    v3.16.2: 32a1b6073064a4a86d2a684180b6662ea202d1294b09ca52a6ba9d4cf071fec7
    v3.16.1: 9f0178957c94516eff9a3897778edb93d78fab1f76751bd282883f584ea81c23
    v3.16.0: d13a4b87b31a5b50c8d93dd9988dfb312a61e56504102f466a4004e5a3ab8e9e
    v3.15.4: e4efce93723f52dd858e9046ea836c9c75f346facce1b87b8cf78c817b97e6ac
    v3.15.3: fac86a8a0515e1f4593d6288426c99f2b3edac946b7f118fcfe03e4a09523f25
    v3.15.2: 9d95528fb797f6429f7f9b6dee0cf87bf8c71f6470e1db4a51e844c169c285a3
    v3.15.1: 0bfe2ff8b29c1f26b0484261c0fe0d041188b2e1aa5da8e461e44083bbf655a3
    v3.15.0: bcec19cdad95cae99edce046ccd8090f275e63381ccb6accb4304819fc26e004
    v3.14.4: d0d625b43f6650ad376428520b2238baa2400bfedb43b2e0f24ad7247f0f59b5
    v3.14.3: aab121ca470e2a502cda849a9b3e92eeb9a32e213b0f0a79a95a04e375d26ce7
    v3.14.2: f3bc8582ff151e619cd285d9cdf9fef1c5733ee5522d8bed2ef680ef07f87223
    v3.14.1: 4d853ab8fe3462287c7272fbadd5f73531ecdd6fa0db37d31630e41ae1ae21de
    v3.14.0: f1f9d3561724863edd4c06d89acb2e2fd8ae0f1b72058ceb891fa1c346ce5dbc
cri_dockerd_archive_checksums:
  arm:
    0.3.11: 0
    0.3.10: 0
    0.3.9: 0
    0.3.8: 0
    0.3.7: 0
    0.3.6: 0
    0.3.5: 0
  arm64:
    0.3.11: 877f635a7005b393f7aab24ca4b1cd7bdfb3b967d055e858408240c86e3cab9a
    0.3.10: 24d2d9cdbb4ed4bda4b0838edb52104ac7a4e2212a0ee05b177de0ae5b6a4a9a
    0.3.9: f5051002b4f95b0e8fe7fbd5f8de4493350e010834d2a8b647f2b26c45c6c203
    0.3.8: 64286af171785f0facb72cf364867600b4db19f43a01db49b8b364f5d04aadae
    0.3.7: 8da54563ee7ddee36b1adf1f96b3b7b97ec2bc0ec23559b89d9af8eae5e62d9e
    0.3.6: 793b8f57cecf734c47bface10387a8e90994c570b516cb755900f21ebd0a663b
    0.3.5: c20014dc5a71e6991a3bd7e1667c744e3807b5675b1724b26bb7c70093582cfe
  amd64:
    0.3.11: b2475988f3b86d85c7835269121171e35c92454ad5f4cd6252183b0fccd74d63
    0.3.10: 3e19ef525e02d2d1dfd42e8d661ee45b4bc8a49a6dcafd8baa578bdb3a23aeb6
    0.3.9: a6d9b4b796e9eff830311a2349d259507302cb3955dd07b78296b91e40e8b433
    0.3.8: e12ea6df8228b7d0794c930d32117c4e5a3dcf25a56c3facdf7006289ec6383c
    0.3.7: 518c5d5345085f36d311f274208705d7fdb79337a80c256871ce941d5a7d47a1
    0.3.6: cf271d65abee88c0c0a6d9dacb151913bf37d25d45913a7e04b09efe408eae18
    0.3.5: 30d47bd89998526d51a8518f9e8ef10baed408ab273879ee0e30350702092938
  ppc64le:
    0.3.11: 0
    0.3.10: 0
    0.3.9: 0
    0.3.8: 0
    0.3.7: 0
    0.3.6: 0
    0.3.5: 0
runc_checksums:
  arm:
    v1.2.3: 0
    v1.2.2: 0
    v1.2.1: 0
    v1.2.0: 0
    v1.1.15: 0
    v1.1.14: 0
    v1.1.13: 0
    v1.1.12: 0
    v1.1.11: 0
    v1.1.10: 0
    v1.1.9: 0
    v1.1.8: 0
  arm64:
    v1.2.3: 4ef19ab21ce1ae5a01e1d3fa5b005e45cdf59f5d3ab32541c9e262cb2b2d3451
    v1.2.2: bfd3e6c58bd6060eaa725520c31cbc8f6386ac7606e65bfa7fe9084100aa1789
    v1.2.1: 8c0d81c80ffdaab986629a9c787d8468ab41851e7aab8f9617a4c3674e192aaa
    v1.2.0: 3d4f66dc1d91f1b2a46713d185a506a604f1fe9f2f2b89c281eb1c5c13677ff0
    v1.1.15: c680f8c470ffb228944ca80e1a4dbb6768b3ad97057350852e128847f9dd10bc
    v1.1.14: 050ee97c266bf7d31e1474568ffcbb2a3ff2208087aaa238c8bbe7e398414126
    v1.1.13: 4b93701752f5338ed51592b38e039aef8c1a59856d1225df21eba84c2830743c
    v1.1.12: 879f910a05c95c10c64ad8eb7d5e3aa8e4b30e65587b3d68e009a3565aed5bb8
    v1.1.11: 9f1ee53f06b78cc4a115ca6ae4eec10567999539ce828a22c5351edba043ed12
    v1.1.10: 4830afd426bdeacbdf9cb8729524aa2ed51790b8c4b28786995925593708f1c8
    v1.1.9: b43e9f561e85906f469eef5a7b7992fc586f750f44a0e011da4467e7008c33a0
    v1.1.8: 7c22cb618116d1d5216d79e076349f93a672253d564b19928a099c20e4acd658
  amd64:
    v1.2.3: e6e8c8049b1910fce58fa68c057aaa5f42cee2a73834df5e59e5da7612d2739d
    v1.2.2: a34f5ab4fc1df1f456293c3d797a76f2d41cf3cd970bb49fc53ba94bbc8a5cf6
    v1.2.1: b106d49c60e688022f5909432a77bd3260f29687199d47213ed87269588af781
    v1.2.0: 3bbb68e49bc89dd2607f11d2ff0fa699963ebada39c32ad8a6aab0d40435c1ed
    v1.1.15: d218e1f8be4dcb1f288dea754faee342375a36f695eac5ab37fc8b7270a78763
    v1.1.14: a83c0804ebc16826829e7925626c4793da89a9b225bbcc468f2b338ea9f8e8a8
    v1.1.13: bcfc299c1ab255e9d045ffaf2e324c0abaf58f599831a7c2c4a80b33f795de94
    v1.1.12: aadeef400b8f05645768c1476d1023f7875b78f52c7ff1967a6dbce236b8cbd8
    v1.1.11: 77ae134de014613c44d25e6310a57a219a7a91155cd47d069a0f22a2cad5caea
    v1.1.10: 81f73a59be3d122ab484d7dfe9ddc81030f595cc59968f61c113a9a38a2c113a
    v1.1.9: b9bfdd4cb27cddbb6172a442df165a80bfc0538a676fbca1a6a6c8f4c6933b43
    v1.1.8: 1d05ed79854efc707841dfc7afbf3b86546fc1d0b3a204435ca921c14af8385b
  ppc64le:
    v1.2.3: 6d1b771096000a14faae660465faf9626a76afe994cbe60581ec4eac1718f12d
    v1.2.2: 9af46fe0bdc654c72593a937806ca034ffbbf4f62f25c1de7a40b5b0f4374de7
    v1.2.1: 652920e145b461151b7e87b28b339594e62129cfc87370b03651a37c39bbc0df
    v1.2.0: 0bd876309958ec00a0e86df3f549f025ad7ae32d981536c1a2932465b479be70
    v1.1.15: b4c8dbbd4973b1cc69fcade012db690e26e0b354d5fcdf04a12ffe972d5ab098
    v1.1.14: 31630474455c4208594623f1337a06556c7fe42d3983000ca800ad3bef6d8164
    v1.1.13: 4675d51dc0b08ad8e17d3065f2e4ce47760728945f33d3092385e792357e6519
    v1.1.12: 4069d1d57724126e116ad6dbd84409082d1b0afee1ee960b17558f146a742bb6
    v1.1.11: e3d1da41f97db1bb7e9a8d96c9092747c14ee53bc9f160048828e63f3a2d0896
    v1.1.10: 94a091c06c363e4af7be398dc31fa6e02576d5ecda6de1cbf3a08fe8662bf678
    v1.1.9: 065cf4f84b5acc0acdb017af2955743dfb5f5e1f49a493eea3e8206f33bf6fe6
    v1.1.8: a816cd654e804249c4f757cc6bf2aa2c128e4b8e6a993067d44c63c891c081ab
crun_checksums:
  arm:
    1.17: 0
    1.16.1: 0
    1.16: 0
    1.15: 0
    1.14.4: 0
    1.14.3: 0
    1.14.2: 0
    1.14.1: 0
    1.11.2: 0
    1.11.1: 0
    1.9.2: 0
  arm64:
    1.17: 3049017b99208f5ecd15c1366f47a77dace87f42dccf317ad40a07f1a867518c
    1.16.1: 973817340e6da12c90c751b011c797396940cca965cefa74557bd1c0939f4042
    1.16: 4595ff16487b16d2158fa8c3452bc0e1ecdc177ab2ace40fc02cd6e49838ff67
    1.15: 2ed5fe6def4c1d57f219747bac5e71cb22312ef026fe63ed8e3246a4dcfebe13
    1.14.4: 308f8719055de178897f66cbb72d6a02567050ac645dd5eca52f48de347dda6c
    1.14.3: 0486629e1599c3bccded279f6555ff22691958cde56203ceca099af6f2407263
    1.14.2: 409ebdcb4935b004ce0efa8ada4aaf8d4dd63b77cde1d0acdf55664c168acbd9
    1.14.1: 25f85c85b9ae15de589ac02d2b766178967d29122325f9479ab068534b7a9658
    1.11.2: 9e1aeb86bce609eccff46a8b976ed06994bca27d639e564fd45756786c4d0123
    1.11.1: c8b0d243f6ac4fb02665c157b5404e5184bdc9240dbdcdde0ccef2db352ce97a
    1.9.2: 1ad8bd3c1aa693f59133c480aa13bbdf6d81e4528e72ce955612c6bae8cb1720
  amd64:
    1.17: e9512a3e034e781b2396d068fd24eafcd5788e410403da886df9dc8871d504a5
    1.16.1: 7b6f1791fb9b2c49ec959b9384b3c4e2ec8c69945fd5292a179d23eb62422eb3
    1.16: 7f53bffd6b0e216f8f6d6472bb73dc4c6c4ea2c2e7342c52d4bee2972798ce68
    1.15: f02c66dcc38b9d06f19a92dfb5ac831aba9c33ae48dbf4ab92d7680ca1140172
    1.14.4: 4f170aaa10d2ef02560cfb60b67ddfa1a83b1b4f7018227e9cb23a6af3955ec1
    1.14.3: 80c5ab9422d4672f650f2bad3da933568349b64117d055486abc3534517be2af
    1.14.2: 4d3a64961ea9e6a1313ab807f86a17bc6ebcecad2df84a120322fddebff00bcf
    1.14.1: a30afd16bbf7eed9d9ce662062f64ef9fbb5d7c76963668c33e90a5693941fbd
    1.11.2: acb62839ab8615f0e2485e8d71272b5659cbe35182eb24c5e96bd213240567fe
    1.11.1: ca8c9cef23f4a3f7a635ee58a3d9fa35e768581fda89dc3b6baed219cc407a02
    1.9.2: 2bb60bcd5652cb17e44f66f0b8ae48195434bd1d66593db97fba85c7778eac53
  ppc64le:
    1.17: ca8ee0fabcac57b61b80f6c234ae20b3b9821433fdf1a6306be5defeac11930e
    1.16.1: 9590ce79697c5509731f8e58d1733b7051c36f92104925221ca8bda800afee41
    1.16: fc7199a2faac1ca0e3e58dee4dd369b9065aa0d95f3257d8803e521213f1bd9b
    1.15: dd0aad6140175ef83792e601c8e89cf66813486e9070aac7f39cac040283d4fd
    1.14.4: aa7263d3c54e478158ed5a70a435208096e434e58ccbc2a334ecbbbc384eff09
    1.14.3: b3304ce1a983e4e1abd4b2bc59eedaa188299be838bdcd8b376f1f8d489bdc94
    1.14.2: 1cf8f3296d1f6ab4189da565d2ac3552059e8e455cc665b913f4b5f3e484bdd7
    1.14.1: a1935fd9a76f0d68a3393927f45cf5627c20915046a254d4fd27531865617b91
    1.11.2: 467f2c1e95f3dc4161d0c0dd1d76601ab3de6d84460d17e1a6647474e948f264
    1.11.1: 723528913c24fac8fc7c4418b9780090eba74ac2d82435c673dedc3af39d5abe
    1.9.2: 42813b5bea2137bf9abcd1bcaa098a7d61fbbffd2a35d9c9f0f1ba79fb74eb5b
youki_checksums:
  arm:
    0.4.1: 0
    0.4.0: 0
    0.3.2: 0
    0.3.1: 0
    0.3.0: 0
    0.2.0: 0
    0.1.0: 0
  arm64:
    0.4.1: 0
    0.4.0: 0
    0.3.2: 0
    0.3.1: 0
    0.3.0: 0
    0.2.0: 0
    0.1.0: 0
  amd64:
    0.4.1: 6504a43c28710d2cb3dd6535ae9222c0570e954a799a787ccf5e5d611996bf11
    0.4.0: a9fb31c7388ed786a2a1b6361cf4aaa7c3e3b62be4c3d36dc15331416a3d6290
    0.3.2: fe80475ad6e727a50f7c0b89e26e4632dd55e477c99bbca192ad1d5fee065377
    0.3.1: 8a92304312982246d5ad9c00da367868dcc4d331fd992ca89dada8eff9cbdeaf
    0.3.0: 741ba3cd85d768bebba02598cedcf3b15a2160e4d6ce33a3d5c4e1b3080f9c1c
    0.2.0: b268689a91db07feebfd41d5806b10c7d051fbcbf7efb15076e2228763ac0762
    0.1.0: f00677e9674215b44f140f0c0f4b79b0001c72c073d2c5bb514b7a9dcb13bdbc
  ppc64le:
    0.4.1: 0
    0.4.0: 0
    0.3.2: 0
    0.3.1: 0
    0.3.0: 0
    0.2.0: 0
    0.1.0: 0
kata_containers_binary_checksums:
  arm:
    3.2.0: 0
    3.1.3: 0
    3.1.2: 0
    3.1.1: 0
    3.1.0: 0
    3.0.2: 0
    3.0.1: 0
  arm64:
    3.2.0: 0
    3.1.3: 0
    3.1.2: 0
    3.1.1: 0
    3.1.0: 0
    3.0.2: 0
    3.0.1: 0
  amd64:
    3.2.0: 21bb8484a060450d6522f29bed7d88d773c28520774eaa2c522b6f47fd12c4a1
    3.1.3: 266c906222c85b67867dea3c9bdb58c6da0b656be3a29f9e0bed227c939f3f26
    3.1.2: 11a2921242cdacf08a72bbce85418fc21c2772615cec6f3de7fd371e04188388
    3.1.1: 999bab0b362cdf856be6448d1ac4c79fa8d33e79a7dfd1cadaafa544f22ade83
    3.1.0: 452cc850e021539c14359d016aba18ddba128f59aa9ab637738296d9b5cd78a0
    3.0.2: a32dc555ffae23f3caab3bc57b03d5ed7792f651221f6cb95cdfe906e18c4bd1
    3.0.1: e2505482f68cc1b1417b8011f2755bf87171a8dd6daaace28531746118fbddaa
  ppc64le:
    3.2.0: 0
    3.1.3: 0
    3.1.2: 0
    3.1.1: 0
    3.1.0: 0
    3.0.2: 0
    3.0.1: 0
gvisor_runsc_binary_checksums:
  arm:
    20240305: 0
    20240212: 0
    20240206: 0
    20240129: 0
    20240122: 0
    20240115: 0
    20240109: 0
    20231218: 0
  arm64:
    20240305: b8b54b45fed2dd1fa14decefecc68c8da605b8abaaee97a0550deeee4afc427f
    20240212: a03fb515df9cabf1c618193e9ed7400543c0410ab7107d1ce291ebc9212521cf
    20240206: 50b637dcb7c1b2fb1c1ce189a48ca6732d4b5a5c17ac08d5dd22d33b06fd31c8
    20240129: d2ecc989f27d40a0e7cd53f0712fa91405b1eef2cb466deccffa41a7f607bacd
    20240122: ae9507f4ff950dc315e7dea2c4b0086dce66b88b8c8bac2008d8e754bac7af7a
    20240115: 7b2ce18408212542477c31cc1bd0ddddf6fbf7439d57e56f6884091f62c81cd8
    20240109: 51a1b299997834b902192806def688b1e23ff6b14f28a9ed3397f3f6572a189a
    20231218: 86262a78946deacc309c0f08883659ee3298c288048dc30955945e71993c81a8
  amd64:
    20240305: 3b949f7fab2c7d3d75df09fe5f170b46951e62b8833dcc4abad0a4d6c12f41f3
    20240212: da5390680d18c3f98f1e88cd7363f97de42ed63a767e61d476b1740b0918b93c
    20240206: 996a8e855c1d54a7dcf688d52ee698fd714f0fd143c42ee793707e7f4f18124d
    20240129: b7765ea92c0100fcd1d03c7b23073c9be9486350cf38ffcbb72eb7915fe26605
    20240122: d184712583d543b8f56a28e8583a1fa55c7256e77934123fe21c621e0d9b975c
    20240115: 9ae176da972b288880e69b1a438052eea2c502b6292aea8a1a33fbcf65e135dd
    20240109: f32810820c81a4dfe570080c06c5dabfc1be74ec0d5da659f93ae5cc1fc5c098
    20231218: c353d36a134dfc2fab8509f72a34abf6a761603975eb00a39e4077c41aeaf31b
  ppc64le:
    20240305: 0
    20240212: 0
    20240206: 0
    20240129: 0
    20240122: 0
    20240115: 0
    20240109: 0
    20231218: 0
gvisor_containerd_shim_binary_checksums:
  arm:
    20240305: 0
    20240212: 0
    20240206: 0
    20240129: 0
    20240122: 0
    20240115: 0
    20240109: 0
    20231218: 0
  arm64:
    20240305: 466c51e4f4bf592da0edf8c70c70ba74f026bb48f980bb28ffb582a93c88c049
    20240212: 4b122fd5684c068d5d73189a30a8130cc5280aefadda0b8532321446c9c79c90
    20240206: 34ded13729aeea0bee6c6d4cbc57ac19a9f4a532631b307ae975cbeb2a09a4ff
    20240129: 41c033549c24c13c776db42d212a416a2df20a6cff57cc26f70df8cdff738441
    20240122: e5f3dbcd7f1b1fb9f46e1432656a8b07dda63a5c65fdbe639062761439df23c0
    20240115: eae0a657656c4153db44dd51ca285b423b44c4eaad872ea56c18b6a430cdfda5
    20240109: 40eb0a4f5f0013afb221e228fd6e71887127c4b09c7f2eb36705a0cd5c746d57
    20231218: 5f66938de981221359a64f05a5c770b228090db3a2697d91ad622c18dd19f4b2
  amd64:
    20240305: 11a1b482e0ed6c72ea6ca72692e1cb2d0794214d142be5389e30517a96b157dc
    20240212: 48333e9b6158f8d4192a35e1d1f74319b6a083d6cbc3779c847548de6a5faf5f
    20240206: 9c88e82b71dc07f689c74f61143ea00fa8621a6d5c31c5fadb9714ad3be8465a
    20240129: 840b4b9d47bd04f3dfed6cf8fbee7c2c4a697e17461c22afb873d67499d4d9b9
    20240122: cd7d9e4bb4cb0ac8242d15fc03580880f53eb36ebd9fb8d686e2811e86ad698e
    20240115: b95d05f667f1040cb07f262f27396d1deb23573ce4c4a31ea3568e6ca3b70c24
    20240109: d677683326cfd42c7913636651f74ffd1a6866066877903d8a58c644422c2e18
    20231218: a0578a357feb9320298730bf5ba683880ba35c476dc74dc82c79f0b5acc42656
  ppc64le:
    20240305: 0
    20240212: 0
    20240206: 0
    20240129: 0
    20240122: 0
    20240115: 0
    20240109: 0
    20231218: 0
nerdctl_archive_checksums:
  arm:
    1.7.7: 26582565426152dc426fd47d8090547128e415314f36710bc58ab475160ab0a4
    1.7.6: 4c48463659b09636aa23b50825f85cdc38901b6c42e321f69a589d89f6e1d0d5
    1.7.5: 2d258a7d67e9fa808424ad42f9299a0feb318cafd2758f0287748acedeee4c0d
    1.7.4: 91d3a8bcc2247dd80f8f5769419e6f344dea412937de4c318f65d8e9bf01355b
    1.7.3: 44369f34a98e5955eb02e41779b1a470332194e4c2bef136fe471943eaf8057a
    1.7.2: d952c1cbe3d25478bbed5f4ee7af4bb52fa4ed47e43802dc5eb2888a4c8da704
    1.7.1: 799d35de7a182da35d850308c7f1787cd7321404348ff2d5ba64ad43b06b395a
    1.7.0: 8b9e7cccbcc0a472685d1bc285f591f41005f8699e7265ea5438a3e06aefdcfd
  arm64:
    1.7.7: 230ad8f4f88100774d123213a427d3d43071e0dcf9f70efbea50ab9efff1cd4c
    1.7.6: 4fa0a6e936c7a9cb9bb81e784fddaa593cb00afb48b08842e3f0503748c21348
    1.7.5: a53d87fc7d1f4ffeec55e5e08d2397b02ada0d334874c3cece306ad36f828a6c
    1.7.4: d8df47708ca57b9cd7f498055126ba7dcfc811d9ba43aae1830c93a09e70e22d
    1.7.3: e4f16b78d884768f6997558130146ba9bd7846828b19fa2ca8e8eda988953fd7
    1.7.2: de68d5380d65604cd26c164988547cf46b698f7819a5d51d98e3a0f031f5594d
    1.7.1: 46affa0564bb74f595a817e7d5060140099d9cfd9e00e1272b4dbe8b0b85c655
    1.7.0: 1255eea5bc2dbac9339d0a9acfb0651dda117504d52cd52b38cf3c2251db4f39
  amd64:
    1.7.7: 298bb95aee485b24d566115ef7e4e90951dd232447b05de5646a652a23db70a9
    1.7.6: 0326d6a42dbec5c104ed9d7aa8cbc62727433dbe000cf21cc29d06b22507e0f0
    1.7.5: 775f8bddd5e93acc4162c568dd6b84d5925549180991b83cfd4b7e33d4844921
    1.7.4: 71aee9d987b7fad0ff2ade50b038ad7e2356324edc02c54045960a3521b3e6a7
    1.7.3: ee93ffe6f90e50bde153a9a0dd779594e0bc13a26949053965958b91b6dffdd0
    1.7.2: aed7d33d645bfb97c8df978d952a1e1f7e02b0b3ed2c0089ee4285af7f8f971b
    1.7.1: 5fc0a6e8c3a71cbba95fbdb6833fb8a7cd8e78f53de10988362d4029c14b905a
    1.7.0: 844c47b175a3d6bc8eaad0c51f23624a5ef10c09e55607803ec2bc846fb04df9
  ppc64le:
    1.7.7: 8236524c4cc6c91007c794160065716516a4f7b63270dc00b796df11776b4f19
    1.7.6: 89906f9bcdf8d5bd866646c43e14c0ae15a83ba3ebed44b06c3629a11517e242
    1.7.5: 8e0891f608144d8d751070edea5cd98d2a76a053ad7fa6b9d4aae94a700aaea2
    1.7.4: 97c99ab6030ffac1fb780fe012de06a36512b17b13de5c99445468b5a5fe5a62
    1.7.3: e63ae0a8f5ccd12877ff944b609d0a4c55c97ba79808ab16c7dc7e99fd8f3dd6
    1.7.2: e5c01702d3cec0763d28bd3cf6ea9c3efc58662a93cb4e15669a839782af10d7
    1.7.1: 09fd0cbef25c98e08c5cc2d1e39da279cbf66c430fdf6c8738e56ce8f949dad9
    1.7.0: e421ae655ff68461bad04b4a1a0ffe40c6f0fcfb0847d5730d66cd95a7fd10cd
containerd_archive_checksums:
  arm:
    1.7.23: 0
    1.7.22: 0
    1.7.21: 0
    1.7.20: 0
    1.7.19: 0
    1.7.18: 0
    1.7.17: 0
    1.7.16: 0
    1.7.15: 0
    1.7.14: 0
    1.7.13: 0
    1.7.12: 0
    1.7.11: 0
    1.7.10: 0
    1.7.9: 0
    1.7.8: 0
    1.7.7: 0
    1.7.6: 0
    1.7.5: 0
    1.7.4: 0
    1.7.3: 0
    1.7.2: 0
    1.7.1: 0
    1.7.0: 0
    1.6.36: 0
    1.6.35: 0
    1.6.34: 0
    1.6.33: 0
    1.6.32: 0
    1.6.31: 0
    1.6.30: 0
    1.6.29: 0
    1.6.28: 0
    1.6.27: 0
    1.6.26: 0
    1.6.25: 0
    1.6.24: 0
    1.6.23: 0
    1.6.22: 0
    1.6.21: 0
    1.6.20: 0
    1.6.19: 0
    1.6.18: 0
    1.6.17: 0
    1.6.16: 0
    1.6.15: 0
    1.6.14: 0
  arm64:
    1.7.24: 420406d2b34ebb422ab3755fbeede59bf3bfcfccf5cfa584b558c93769d99064
    1.7.23: 6a66b5e63a5e88ff7eeb478ccaca9083d44e51e1d7261ae183fe5951a6226ccd
    1.7.22: 48d0a8461ae829b12b07c3663b14b70287d0607a0792719c51b4e4dd700b02ce
    1.7.21: 7b6b67d998eb86856d23df5d57269c054539072bbb27677975cf78269b2c5c10
    1.7.20: cf80cd305f7d1c23aaf0c57bc1c1e37089cad9130d533db6fe968cdebd16c759
    1.7.19: 1839e6f7cd7c62d9df3ef3deac3f404cdd5cd47bbdf8acfeb0b0f3776eb20002
    1.7.18: e80ce87b469af03b3bdcf68b95f0f4a303787ae247581bcd42f04acf1ad4c24d
    1.7.17: 8d9749985796a208e860afe331ec77cb485566104e5cc7c0b5e9e82ec7681969
    1.7.16: 2d4373de40a6f58cd0f29377c0257b35697a987248e6268520586996771d7a75
    1.7.15: 5cc8bd8f3d9803ef0ef701596e89d62ad6850a2544e722842f4533642df36d87
    1.7.14: 44df66d0a0332465e7d15e90b974cd4f08d059dfa26652218ed9485390f47f9e
    1.7.13: 118759e398f35337109592b4d237538872dc12a207d38832b9d04515d0acbc4d
    1.7.12: 8a1b35a521d071a8828f63fe007a51e5b7ac863a1195f5dee32543b1a9d5f2b6
    1.7.11: 5eae27cce38a14be5390d4035127aa11416bc5ae592a9ff25b11870872ce1159
    1.7.10: 0667b12a04a896a61cf508a4a77190c280f4a1fa35f38c8a4ba63f605b5ec375
    1.7.9: 09ca326dee14e00c439137071747c15cc280480e2c26c1e82698c992dd1889c6
    1.7.8: 3fc551e8f51150804d80cc1958a271bd2252b6334f0355244d0faa5da7fa55d1
    1.7.7: 0a104f487193665d2681fcb5ed83f2baa5f97849fe2661188da835c9d4eaf9e3
    1.7.6: d844a1c8b993e7e9647f73b9814567004dce1287c0529ce55c50519490eafcce
    1.7.5: 98fc6990820d52d45b56ea2cda808157d4e61bb30ded96887634644c03025fa9
    1.7.4: ea5a04379bd4252fc1e0b7b37f69cd516350c5269054483535d6eab7a0c79d2e
    1.7.3: 85d2eaedabff57ac1d7cd3884bf232155c4c46491f6b071982e4f7b684b74445
    1.7.2: d75a4ca53d9addd0b2c50172d168b12957e18b2d8b802db2658f2767f15889a6
    1.7.1: 1f828dc063e3c24b0840b284c5635b5a11b1197d564c97f9e873b220bab2b41b
    1.7.0: e7e5be2d9c92e076f1e2e15c9f0a6e0609ddb75f7616999b843cba92d01e4da2
    1.6.36: 48aaf746ad4adc6e5c3b077875ddbd15a8f5b660a5f7dcb533f0205aeeff3785
    1.6.35: 0e0066aeffbd4360bfcf16bd08b6a9e40da7f437aa7b292991ce8d08083bee40
    1.6.34: 9e898686ff003cec2d80c30cf5ad342c1ac88373568dae792f93cd088e66d038
    1.6.33: 432cf17fbc01ba4fc59b949210baa96865185b8eb3b3292eb7a00e2f6bde9fe9
    1.6.32: a9cb16bafbf1eb8cea11b4803d76f78cf7bef311b951dd1ae49c238bb41ec649
    1.6.31: 91a74cc602c7724668537f754006692114af70cfb6ef840b288f922fa68f7ed7
    1.6.30: 0bbf1eed508d6ebc240b900648c76f12a07c0c6125aa8c22d46c9ce24252f9e3
    1.6.29: 0
    1.6.28: 96a231f875ddf9cc7682b881d408ae993f2bd5d0a40402a74ec4fda672047427
    1.6.27: 433b0e8113adfd726374e04fc2f61dafad65c53db5665569f2715a7a916a1813
    1.6.26: 177bed65b6425255bacbe48d99ea7aa5209d381576962c0962dc8615ef16c5c5
    1.6.25: 4948677cfc5f98a1d5d46cec90d6d6f84f6b27cd6d28fd87f7f5936d61580ceb
    1.6.24: 1d741e9e2d907f02a8b2a46034a28ff9aacdba88c485cef2f4bad18be9ea23ba
    1.6.23: ea7afb82dc5789307e684ef9b4a55ce1ee9a05dc02c2118df640b01207208c45
    1.6.22: 7882d6e7f4e97dcba041c37592c4cb9e7a5b4d972380c74d959e388b12d57d01
    1.6.21: d713d8fbec491705ffe8c33ecc9051a904f6eedc92574928e1d33616f291c583
    1.6.20: c3e6a054b18b20fce06c7c3ed53f0989bb4b255c849bede446ebca955f07a9ce
    1.6.19: 25a0dd6cce4e1058824d6dc277fc01dc45da92539ccb39bb6c8a481c24d2476e
    1.6.18: 56b83a0bc955edc5ebaa3bd0f788e654b63395be00fcb1bd03ff4bdfe4b5e1e7
    1.6.17: 7e110faa738bff2f5f0ffd54c4ec2c17c05fd2af6de4877c839794ca3dadd61c
    1.6.16: c2bf51fde02ec9cf8b9c18721bc4f53bd1f19fb2bb3251f41ece61af7347e082
    1.6.15: d63e4d27c51e33cd10f8b5621c559f09ece8a65fec66d80551b36cac9e61a07d
    1.6.14: 3ccb61218e60cbba0e1bbe1e5e2bf809ac1ead8eafbbff36c3195d3edd0e4809
  amd64:
    1.7.24: 1a94f15139f37633f39e24f08a4071f4533b285df3cbee6478972d26147bcaef
    1.7.23: 8a0de43d9313aef2ebdccc0ffa49461a4a28139a2c0ef104c3c847f6f37c8119
    1.7.22: f8b2d935d1f86003f4e0c1af3b9f0d2820bacabe6dc9f562785b74af24c5e468
    1.7.21: 3d1fcdfd0b141f4dc4916b7aee7f9a7773dc344baffc8954e1ca66b1adc5c120
    1.7.20: e09410787b6f392748959177a84e024424f75d7aff33ea1c5b783f2260edce67
    1.7.19: 97f75e60f0ad19d335b1d23385835df721cad4492740d50576997f2717dc3f94
    1.7.18: a24b05b341c155a0ec367d3d0fd1d437c09a0261dffdecc0e44e9abbf2d02aca
    1.7.17: 04cf937349f82d29fe98553ff45a7e9ea2ed6b81fe6514e3679cf263b50409ff
    1.7.16: 4f4f2c3c7d14fd59a404961a3a3341303c2fdeeba0e78808c209f606e828f99c
    1.7.15: ea27e6454954bd9cb62a70b0a40eb085ae9c96cb8c075a74910102b33586e07d
    1.7.14: 48e0d9747cd51cb90e0b278d100397653d9f2e765effca194427e4796395b240
    1.7.13: c2371c009dd8b7738663333d91e5ab50d204f8bcae24201f45d59060d12c3a23
    1.7.12: 6a24d8b996533fa1b0d7348fe9813a78cd01fa16cff865a961ad0d556f5cd665
    1.7.11: d66161d54546fad502fd50a13fcb79efff033fcd895adc9c44762680dcde4e69
    1.7.10: eacb0296bff2ae5225a18492dcb32fb28ad4a1fe0a39ea9073367c7e43dc5838
    1.7.9: ccd5b434393666f6ebbc90eea959ffd3e61958a1e3e1cc830a678f040142d4b0
    1.7.8: 5f1d017a5a7359514d6187d6656e88fb2a592d107e6298db7963dbddb9a111d9
    1.7.7: 371de359d6102c51f6ee2361d08297948d134ce7379e01cb965ceeffa4365fba
    1.7.6: 58408cfa025003e671b0af72183b963363d519543d0d0ba186037e9c57489ffe
    1.7.5: 33609ae2d5838bc5798306a1ac30d7f2c6a8cff785ca6253d2be8a8b3ccbab25
    1.7.4: fc070fabfe3539d46ae5db160d18381270928b3f912e2e800947e9fbd43f510c
    1.7.3: de7f61aacba88ee647a7dcde1ca77672ec44ab9fb3e58ae90c0efc9b2d8f3068
    1.7.2: 2755c70152ab40856510b4549c2dd530e15f5355eb7bf82868e813c9380e22a7
    1.7.1: 9504771bcb816d3b27fab37a6cf76928ee5e95a31eb41510a7d10ae726e01e85
    1.7.0: b068b05d58025dc9f2fc336674cac0e377a478930f29b48e068f97c783a423f0
    1.6.36: e9a53f5f7549afbe9208578609eddecd238b7166663ab273f2954fab77602b3f
    1.6.35: 50f05b2986a8635827e3f015f10d8d1c342e9a9d6886c7392160b5c27ac77c83
    1.6.34: 18969d667cd6b9993d168f6d30f9ad978f0aca72cf984c1f522fc5277780885b
    1.6.33: a0c7daa50386dc3ca19cbeb83d6987d43bdd92c0bb0429d08be7f9be4f9c307a
    1.6.32: 7acab4dda6edb7e8e0a6cfc3abd9f323db05a3d92a8a1842de8f6c9e28af501d
    1.6.31: 52080601f414b7e63a5b8e0cb8c1d641c9e070447ac96da9b1aeb00480744ba5
    1.6.30: 1f1b65190b626883394e6f2ecbe5141afc6c45fc1ca035ef052e66bb2c479a5f
    1.6.29: 0
    1.6.28: b2f15c722d1cc8b74ed643068e043b92bd031fc23d53488d1e837cf4b2777391
    1.6.27: 8c0b04a8b39127c084d490cca905d565c94929dd15e168b0f8663076fdcf5539
    1.6.26: fa806d3e945a8ad25aa1f8123a98524768ead83af2ed1ab3d922d2dd5fe6b14c
    1.6.25: 878b331b5fa65df3d33c68ee355724de0044c25071486086409b374a9c62d145
    1.6.24: a56fac5ba03c3d6f74ceae14abdc9fafabcba900105e9890c0ac895cc00164ad
    1.6.23: bcf16bb63a295721a2603e9a56602c5d18e5443df04a9f2c1ca5328f41556fcc
    1.6.22: 5671eb4eba97f0ec98223c84401c9aeb21d0ef16ac3ece3eb8fadd46174d7eab
    1.6.21: 04dcc1b99368492caee758583e531392683268197e58156888a3cea2941117b6
    1.6.20: bb9a9ccd6517e2a54da748a9f60dc9aa9d79d19d4724663f2386812f083968e2
    1.6.19: 3262454d9b3581f4d4da0948f77dde1be51cfc42347a1548bc9ab6870b055815
    1.6.18: c4e516376a2392520a87abea94baf2045cc3a67e9e0c90c75fb6ed038170561e
    1.6.17: 5f0584d000769d0cf08fc0e25135614ef5bf52971a6069175c78437699f3b8d4
    1.6.16: 2415b431a900275c14942f87f751e1e13d513c1c2f062322b5ca5a9a2190f22a
    1.6.15: 191bb4f6e4afc237efc5c85b5866b6fdfed731bde12cceaa6017a9c7f8aeda02
    1.6.14: 7da626d46c4edcae1eefe6d48dc6521db3e594a402715afcddc6ac9e67e1bfcd
  ppc64le:
    1.7.24: 2ca4d527dac68132a2a6b3971d82ddfd18edc7fa838b7cfcfe6eb11efd017871
    1.7.23: 00dd8a1145d7392ffe1e2b74da147b896e4387afb5e73ed6e5cd3744add32826
    1.7.22: 6747b7291ffbfde2c0bf0031978985df92ac74414f09bf190afda0fc9e797146
    1.7.21: 5ce0c1125e8d9ca04e2b524a2bac8b1eb97876c073023d5e083f7da64fcd8207
    1.7.20: dc611df0baa90509dda35e0be993da52f42b067514329fcf538d000b110364e8
    1.7.19: f41c2f28ee933a9ca24ff02cca159099fbcf798850e56cf0b7a6047ebe21fa86
    1.7.18: d6cfb3bc8fbdead7d435d5f3f6b1913b5896f7f97102c1bbad206f9123c2a5d3
    1.7.17: 873b76a507d362eec73887f61fa1400f3a892c7dbed1759f5dad2b654095b534
    1.7.16: d0add7a55a5d4411cafb276469d2b78bc3ada11cb4b444b9e35f9ef60c00960d
    1.7.15: b38641d9bd18139495cf9839999039b19941f53d36a6d72efe4577c489dfda0c
    1.7.14: b84b523909b9dd0c0b2bc40bd2b9af543ec9f1186df69c220ae3749e34623dbb
    1.7.13: 89605ed2365d5eb779477d11947101236eb44e5244f1e58bb162a9e68d242798
    1.7.12: 80f16891b387d86712026234de7d4d0365a38106dbe5e51b65b1200b24822721
    1.7.11: 6f91c5dabdccd1fc75aae8687381bb185b9eb4200beb29d0993dea8175f5fa61
    1.7.10: 15a5191bf7c555956a8565d8786399d51b13f2718d59b1a5b2bd380fc420bf8a
    1.7.9: 174b8af2d878ad8410205b9ba44fa8d2a9683a521abf13f168f67b7f7375d5b3
    1.7.8: 2b563df9e1bddc96a99a023963c99b5faf3066d3fcbc23ff44ba24229e939444
    1.7.7: 0335e7447ed84757489337686a709e95ffa379a8780f238725abb10facaeaa7f
    1.7.6: 956fadb01b35c3214f2b6f82abc0dda3e1b754cb223cd24e818334b08cb09fb2
    1.7.5: 2496e24a95fa74750363a8a7e2ac36acf8d41ee2e4b67a452154ad4c8efbc4bc
    1.7.4: c3397f67fb5756e6336ff76eeb34dfad7ad66235877a4186d82044c7a4caf482
    1.7.3: d1977922e74147782dd5bb488f260ee14d758d29a7651cd97bc2e6c7cc1a3cce
    1.7.2: cbe7ec913cb603ca218bd8867efdce4bee3b0e0115e467e51c910467daf8184e
    1.7.1: 17d97ef55c6ce7af9778dbafb5e73f577d1b34220043a91cccde49dbcc610342
    1.7.0: 051e897d3ee5b8c8097f65be447fea2d29226b583ca5d9ed78e9aebcf4e69889
    1.6.36: 8978cd8bcd4d5a2640bad26d8ea522a46847b6e4a62da1b07bfa482c8906e5ce
    1.6.35: 99095ab778f6fd532eb01d11771e7f8de8383ef20a00ec536c0cf9c018895115
    1.6.34: 14a4392ba4e533e313fe6d3ed1a68cfdce038b87ad4693be6e71ff31568e2173
    1.6.33: 0a77fba37290a40a7853dbd7e5a297288d3657f7e92cd7864bc7187189a0a370
    1.6.32: d733e4b66ca2bc8191ae5e8770e4806ebd4094fdc657258045b925930ad9bfc5
    1.6.31: 4458a2398f27241b6e674ea9ba1f56dc4d9ab9dacc5a07469602776c3e428110
    1.6.30: ba3d790f504a845b060e2faae3cc0603afd125ebdddb3bdb513b8d70a4337d87
    1.6.29: 0
    1.6.28: 35411f9d1bafc9cae91c2e30d46a59d01bffc7e18ac7f0942dca9d1d5907ab38
    1.6.27: 8106915bc62c51383baa77925748505e79229fded7efcd7e74cb352ad10d0ce9
    1.6.26: 75fb01a4bd3bcd16263c2f833b8e7081356e2e390dd7eb0710232cb04dac5a01
    1.6.25: 3ddcc1739ffeb3e1df786d45518a01d93a5cef243eb6dee61cbdd4cd110bc723
    1.6.24: abff9e7ec4cc21d19150d2bc55fc89cf53dc03c002cdaf5016ee82aedead9b03
    1.6.23: 1099fce4a4dfc78712cc1c19be6d9f80e9321f513834dba0b2418bd5c78ad398
    1.6.22: 0f8647aedd96174704a63a17b1a7cf4c4c5c2fc066606b1a419b2a860b754bfb
    1.6.21: 196d91799070a5ff2f5f3b6efe8516c5377f299d38012b6c0cf4ae77fc8c22c5
    1.6.20: f3ee666fdd31031f07cbb7bad24f0181fad1094ba36273dc61f8fa5a570b5311
    1.6.19: 18cf11b6dfc980aca8792a2cd3ea7afed6379c2988ca6fe9e53a19a0bece5a2d
    1.6.18: b7083473061a61200d04f500ad4a96813d1b09f71b2d427019076836c2a49836
    1.6.17: 2f689ff36ba41c3c86ce926f55b0101118a40dd7b741946386062fddaa287db0
    1.6.16: 9cfd5dade6a1c2671f5c76496395afe0aa0ce902c13672b306d8d09fdbb99492
    1.6.15: 502f3e4c8ea2018aaa285fe4f704bfd560fdf93193bb829dd9302d013bc38370
    1.6.14: 73025da0666079fc3bbd48cf185da320955d323c7dc42d8a4ade0e7926d62bb0
skopeo_binary_checksums:
  arm:
    v1.16.1: 0
    v1.16.0: 0
    v1.15.2: 0
    v1.15.1: 0
    v1.15.0: 0
    v1.14.2: 0
    v1.14.1: 0
    v1.13.3: 0
    v1.13.2: 0
    v1.13.1: 0
    v1.13.0: 0
  arm64:
    v1.16.1: 3272f15f469af843d325134ff8a77a069d647c5f247766715c098b8f0622b627
    v1.16.0: 331b09b3b6e6550c178ea1c2fb2bdc5bdbd90c6f6e8d86a974f1117d6ab2fabe
    v1.15.2: f81487af3104e37537ff21f1b2527b294f5cc4e7988941a1655ded97c027ac1d
    v1.15.1: e20e34f96b5545bacd469b0d85ccce811ffbe2809db36248a3becb4638276959
    v1.15.0: bde8cc7e764d246281430d5da07ca906ee0838803199e3a6136a58802b2e0207
    v1.14.5: 23e157de988c6020f1300b5d73d84d2fed2823ed61dbc6828de3552e9c77a6db
    v1.14.4: d825f93b28cf7502569fe75c46aa78187bb63b6bc06036621de7b63290b51058
    v1.14.3: e93a82b88e9bff46cbe4e68f96e265d934026a845b76ce51672c7cce26fba164
    v1.14.2: 364c46085de31edf4b312f13587442f4eade1f181bc5a9ea2ab2ffab5b575916
    v1.14.1: fd4fc0adae14f27788fd52cf0d23be2cfd1963e184c4af689de30185455e29a6
    v1.13.3: 1f7726b020ff9bc931ce16caa13c29999738a231f1414028282cd8f8661eb747
    v1.13.2: 520cc31c15796405b82d01c78629d5b581eced3512ca0b6b184ed82f5e18dc86
    v1.13.1: 3b7db2b827fea432aa8a861b5caa250271c05da70bd240aa4045f692eba52e24
    v1.13.0: d23e43323c0a441d1825f9da483b07c7f265f2bd0a4728f7daac4239460600a3
  amd64:
    v1.16.1: 8813fb7fcd7a723196ac287683dd929d280f6fe7f0782eace452fe1e3ff2b7eb
    v1.16.0: 7bc31ed810d1366304d2e975c2910cea5e22cbd68f8316f14cacf44f6c0bd1d2
    v1.15.2: 6b84d1158f29610f692f24c82459a865c2a21911647cc0cdf44027e7a59f73ba
    v1.15.1: d45a93dab851f072fe5d3f0419f5c8bb3ee48069b588c211cccebd023fd5ae3a
    v1.15.0: 3cdbcde0163abb4c942f62d0302479d5aa4d31c5970d712841cf5d5f76edc594
    v1.14.5: 180c2d7e8bc00685ba291572db6ddd90acadf03af7595521da17ae1f2c28f4b1
    v1.14.4: 4c6f8f7c6e5f01675adff8c5bbb542d8d02b9bbdecf0d2abac1e99b8a34a9768
    v1.14.3: 2db7e036e99ad3b808aaffbafc5267391bd3ba2f45ff03dd0090686eb3eb0f1e
    v1.14.2: 51218f93a2b079e36a36f7fbe2d2d86778be0a6947653031b4f9e254e2469224
    v1.14.1: 6b7776bcdf0c92af5d3f3c91a959d091011b42d839025b90f12b7201a083f308
    v1.13.3: 65707992885b1a4a446af6342874749478a1af7e17ab3f4df8fb89509e8b1966
    v1.13.2: 2f00be6ee1c4cbfa7f2452be90a1a2ce88fd92a6d0f6a2e9d901bd2087bd9092
    v1.13.1: 8c15c56a6caffeb863c17d73a6361218c04c7763e020fffc8d5d6745cacfa901
    v1.13.0: 8cb477ee25010497fc9df53a6205dbd9fe264dd8a5ea4e934b9ec24d5bdc126c
  ppc64le:
    v1.16.1: 248f8f601e4c40dd6d603b66ac26246f96d18451cc3642718c59afb6c2403cf7
    v1.16.0: 24f1266d6146c27143b5002387c5b68086f1355de7db5c9bfe820928e3b8e298
    v1.15.2: 5b123d38c34024e8b62b3bc94abfeea3007291743260bf7f62b2a1d935f1c3f9
    v1.15.1: 39a4a6d77daca09a93a0b490285f48cd9040da1ba9c05b1f9709483e4f65c318
    v1.15.0: fb7f390f52f4b81f85d9bdce8715af5e27ee3969eff236b5f3c0f3a0b5a182e1
    v1.14.5: 4ed476c46fabb3b320aac9b88ddc1b7a2665cb151a93482db7cb98e5768a768f
    v1.14.4: f1b37ad1b83bd43bada6e49518165cf41d727d0662351dc5fcc9a46f0c3b4482
    v1.14.3: 9028b7c4aafe235f1ba4efd57435b97ace341e544d3a6807440ac3b0f32d7d73
    v1.14.2: 0
    v1.14.1: 0
    v1.13.3: 0
    v1.13.2: 0
    v1.13.1: 0
    v1.13.0: 0
yq_checksums:
  arm:
    v4.42.1: 4e3fe0c37793d28e96d465d9958fbf679d8c616e1857d0faf7980ad087f32aee
    v4.41.1: ccd50344652c02574ca7dd123c7d66a06b391838e8ca6088b688e6edf2e25d0c
    v4.40.7: fb922bb1e3974fbd15957feafb5e9bbabe43f4192999cf9b3e0e470815f2e0da
    v4.40.6: 0
    v4.40.5: c587b2411e43d3fbcdd24c233fb558a362b5111a8446b23f9ce9a4a5665a7041
    v4.40.4: 2ff3f17483f2172a20130b16328114bfe6abd7d3068d66d8194a5093079e8529
    v4.40.3: 6a97856e8b4ef992ce08dcfdf97fec517cf612b1a89078406f401673f126c21c
  arm64:
    v4.42.1: 16a57531a594b66c3e0981cd93f9e9cd4b684a347b86eaf5e3f409074ad67eb8
    v4.41.1: 066aa930d74e39a25447b1900d8cbb3e1c7df72cd75bc203bc6ae5ee577a5b4a
    v4.40.7: a84f2c8f105b70cd348c3bf14048aeb1665c2e7314cbe9aaff15479f268b8412
    v4.40.6: 0
    v4.40.5: 9431f0fa39a0af03a152d7fe19a86e42e9ff28d503ed4a70598f9261ec944a97
    v4.40.4: 79c61a1ebfedb165ec8c4678777775b52e2c581801f5d4cd80f97300852fe0f0
    v4.40.3: 44a5cca10d33019b8a46212882197be4f961dfe7deddde0af497065aa980a6a4
  amd64:
    v4.42.1: 1a95960dddd426321354d58d2beac457717f7c49a9ec0806749a5a9e400eb45e
    v4.41.1: ce0d5a61c256a463fd32f67f133e0c2948bc2cf77d44c42ff335a40e6bef34bf
    v4.40.7: 4f13ee9303a49f7e8f61e7d9c87402e07cc920ae8dfaaa8c10d7ea1b8f9f48ed
    v4.40.6: 0
    v4.40.5: 0d6aaf1cf44a8d18fbc7ed0ef14f735a8df8d2e314c4cc0f0242d35c0a440c95
    v4.40.4: f9163412d9aa2aa55e888fdcaf2b4053ada20074be35f701424caa7163100704
    v4.40.3: 6e9a5ed9591dbf1d13aaec4efaaf0ecdaf4945ea393b9ce01f4c3dea22311470
  ppc64le:
    v4.42.1: d0d1cdbd2c4a7e6995433baf879cadaa47f6f12290e1661ea11933ed90baccb6
    v4.41.1: eed2af79d0ad787878b2d5c7c592e43ac152208d9ed432b42a43663167e276e8
    v4.40.7: ac0e8d06a7ed9afc108b4e2e9d6900312b01757f61b75fcecb809f15c39b10e7
    v4.40.6: 0
    v4.40.5: a1df9d2b872fbb30583526bf4f37f737dc1913b28606dfc1dafeaf56a8862b3d
    v4.40.4: c67379085a44558825a60a8af3b59b400852b168356070829bc0f45c70553f45
    v4.40.3: 2fe818a0b141913a41548e0e727267479d0f755221c73f9e304788c8e9139a45

## roles/kubespray-defaults/defaults/main/download.yml <==
---
local_release_dir: /tmp/releases
download_cache_dir: /tmp/kubespray_cache

# If this is true, debug information will be displayed but
# may contain some private data, so it is recommended to set it to false
# in the production environment.
unsafe_show_logs: false

# do not delete remote cache files after using them
# NOTE: Setting this parameter to TRUE is only really useful when developing kubespray
download_keep_remote_cache: false

# Only useful when download_run_once is false: Localy cached files and images are
# uploaded to kubernetes nodes. Also, images downloaded on those nodes are copied
# back to the ansible runner's cache, if they are not yet preset.
download_force_cache: false

# Used to only evaluate vars from download role
skip_downloads: false

# Optionally skip kubeadm images download
skip_kubeadm_images: false
kubeadm_images: {}

# if this is set to true will only download files once. Doesn't work
# on Flatcar Container Linux by Kinvolk unless the download_localhost is true and localhost
# is running another OS type. Default compress level is 1 (fastest).
download_run_once: false
download_compress: 1

# if this is set to true will download container
download_container: true

# if this is set to true, uses the localhost for download_run_once mode
# (requires docker and sudo to access docker). You may want this option for
# local caching of docker images or for Flatcar Container Linux by Kinvolk cluster nodes.
# Otherwise, uses the first node in the kube_control_plane group to store images
# in the download_run_once mode.
download_localhost: false

# Always pull images if set to True. Otherwise check by the repo's tag/digest.
download_always_pull: false

# Some problems may occur when downloading files over https proxy due to ansible bug
# https://github.com/ansible/ansible/issues/32750. Set this variable to False to disable
# SSL validation of get_url module. Note that kubespray will still be performing checksum validation.
download_validate_certs: true

# Use the first kube_control_plane if download_localhost is not set
download_delegate: "{% if download_localhost %}localhost{% else %}{{ groups['kube_control_plane'][0] }}{% endif %}"

# Allow control the times of download retries for files and containers
download_retries: 4

# The docker_image_info_command might seems weird but we are using raw/endraw and `{{ `{{` }}` to manage the double jinja2 processing
docker_image_pull_command: "{{ docker_bin_dir }}/docker pull"
docker_image_info_command: "{{ docker_bin_dir }}/docker images -q | xargs -i {{ '{{' }} docker_bin_dir }}/docker inspect -f {% raw %}'{{ '{{' }} if .RepoTags }}{{ '{{' }} join .RepoTags \",\" }}{{ '{{' }} end }}{{ '{{' }} if .RepoDigests }},{{ '{{' }} join .RepoDigests \",\" }}{{ '{{' }} end }}' {% endraw %} {} | tr '\n' ','"
nerdctl_image_info_command: "{{ bin_dir }}/nerdctl -n k8s.io images --format '{% raw %}{{ .Repository }}:{{ .Tag }}{% endraw %}' 2>/dev/null | grep -v ^:$ | tr '\n' ','"
# Using the ctr instead of nerdctl to workdaround the https://github.com/kubernetes-sigs/kubespray/issues/10670
nerdctl_image_pull_command: "{{ bin_dir }}/ctr -n k8s.io images pull{% if containerd_registries_mirrors is defined %} --hosts-dir {{ containerd_cfg_dir }}/certs.d{%- endif -%}"
crictl_image_info_command: "{{ bin_dir }}/crictl images --verbose | awk -F ': ' '/RepoTags|RepoDigests/ {print $2}' | tr '\n' ','"
crictl_image_pull_command: "{{ bin_dir }}/crictl pull"

image_command_tool: "{%- if container_manager == 'containerd' -%}nerdctl{%- elif container_manager == 'crio' -%}crictl{%- else -%}{{ container_manager }}{%- endif -%}"
image_command_tool_on_localhost: "{{ image_command_tool }}"

image_pull_command: "{{ lookup('vars', image_command_tool + '_image_pull_command') }}"
image_info_command: "{{ lookup('vars', image_command_tool + '_image_info_command') }}"
image_pull_command_on_localhost: "{{ lookup('vars', image_command_tool_on_localhost + '_image_pull_command') }}"
image_info_command_on_localhost: "{{ lookup('vars', image_command_tool_on_localhost + '_image_info_command') }}"

# Arch of Docker images and needed packages
image_arch: "{{ host_architecture | default('amd64') }}"

# Versions
crun_version: 1.17
runc_version: v1.2.3
kata_containers_version: 3.1.3
youki_version: 0.4.1
gvisor_version: 20240305
containerd_version: 1.7.24
cri_dockerd_version: 0.3.11

# this is relevant when container_manager == 'docker'
docker_containerd_version: 1.6.32

# gcr and kubernetes image repo define
gcr_image_repo: "gcr.io"
kube_image_repo: "registry.k8s.io"

# docker image repo define
docker_image_repo: "docker.io"

# quay image repo define
quay_image_repo: "quay.io"

# github image repo define (ex multus only use that)
github_image_repo: "ghcr.io"

# TODO(mattymo): Move calico versions to roles/network_plugins/calico/defaults
# after migration to container download
calico_version: "v3.29.1"
calico_ctl_version: "{{ calico_version }}"
calico_cni_version: "{{ calico_version }}"
calico_policy_version: "{{ calico_version }}"
calico_typha_version: "{{ calico_version }}"
calico_apiserver_version: "{{ calico_version }}"
typha_enabled: false
calico_apiserver_enabled: false

flannel_version: "v0.22.0"
flannel_cni_version: "v1.1.2"
weave_version: 2.8.7
cni_version: "v1.4.0"

cilium_version: "v1.15.9"
cilium_cli_version: "v0.16.0"
cilium_enable_hubble: false

kube_ovn_version: "v1.12.21"
kube_ovn_dpdk_version: "19.11-{{ kube_ovn_version }}"
kube_router_version: "v2.0.0"
multus_version: "v4.1.0"
helm_version: "v3.16.4"
nerdctl_version: "1.7.7"
krew_version: "v0.4.4"
skopeo_version: "v1.16.1"

# Get kubernetes major version (i.e. 1.17.4 => 1.17)
kube_major_version: "{{ kube_version | regex_replace('^v([0-9])+\\.([0-9]+)\\.[0-9]+', 'v\\1.\\2') }}"

pod_infra_supported_versions:
  v1.32: "3.10"
  v1.31: "3.10"
  v1.30: "3.9"
pod_infra_version: "{{ pod_infra_supported_versions[kube_major_version] }}"

etcd_supported_versions:
  v1.32: "v3.5.16"
  v1.31: "v3.5.16"
  v1.30: "v3.5.16"
etcd_version: "{{ etcd_supported_versions[kube_major_version] }}"

crictl_supported_versions:
  v1.32: "v1.32.0"
  v1.31: "v1.31.1"
  v1.30: "v1.30.1"
crictl_version: "{{ crictl_supported_versions[kube_major_version] }}"

crio_supported_versions:
  v1.32: v1.32.0
  v1.31: v1.31.3
  v1.30: v1.30.3
crio_version: "{{ crio_supported_versions[kube_major_version] }}"

# Scheduler plugins doesn't build for K8s 1.29 yet
scheduler_plugins_supported_versions:
  v1.31: 0
  v1.30: 0
  v1.29: 0
scheduler_plugins_version: "{{ scheduler_plugins_supported_versions[kube_major_version] }}"

yq_version: "v4.42.1"

github_url: https://github.com
dl_k8s_io_url: https://dl.k8s.io
storage_googleapis_url: https://storage.googleapis.com
get_helm_url: https://get.helm.sh

# Download URLs
kubelet_download_url: "{{ dl_k8s_io_url }}/release/{{ kube_version }}/bin/linux/{{ image_arch }}/kubelet"
kubectl_download_url: "{{ dl_k8s_io_url }}/release/{{ kube_version }}/bin/linux/{{ image_arch }}/kubectl"
kubeadm_download_url: "{{ dl_k8s_io_url }}/release/{{ kube_version }}/bin/linux/{{ image_arch }}/kubeadm"
etcd_download_url: "{{ github_url }}/etcd-io/etcd/releases/download/{{ etcd_version }}/etcd-{{ etcd_version }}-linux-{{ image_arch }}.tar.gz"
cni_download_url: "{{ github_url }}/containernetworking/plugins/releases/download/{{ cni_version }}/cni-plugins-linux-{{ image_arch }}-{{ cni_version }}.tgz"
calicoctl_download_url: "{{ github_url }}/projectcalico/calico/releases/download/{{ calico_ctl_version }}/calicoctl-linux-{{ image_arch }}"
calico_crds_download_url: "{{ github_url }}/projectcalico/calico/archive/{{ calico_version }}.tar.gz"
ciliumcli_download_url: "{{ github_url }}/cilium/cilium-cli/releases/download/{{ cilium_cli_version }}/cilium-linux-{{ image_arch }}.tar.gz"
crictl_download_url: "{{ github_url }}/kubernetes-sigs/cri-tools/releases/download/{{ crictl_version }}/crictl-{{ crictl_version }}-{{ ansible_system | lower }}-{{ image_arch }}.tar.gz"
crio_download_url: "{{ storage_googleapis_url }}/cri-o/artifacts/cri-o.{{ image_arch }}.{{ crio_version }}.tar.gz"
helm_download_url: "{{ get_helm_url }}/helm-{{ helm_version }}-linux-{{ image_arch }}.tar.gz"
runc_download_url: "{{ github_url }}/opencontainers/runc/releases/download/{{ runc_version }}/runc.{{ image_arch }}"
crun_download_url: "{{ github_url }}/containers/crun/releases/download/{{ crun_version }}/crun-{{ crun_version }}-linux-{{ image_arch }}"
youki_download_url: "{{ github_url }}/containers/youki/releases/download/v{{ youki_version }}/youki-{{ youki_version }}-{{ ansible_architecture }}-musl.tar.gz"
kata_containers_download_url: "{{ github_url }}/kata-containers/kata-containers/releases/download/{{ kata_containers_version }}/kata-static-{{ kata_containers_version }}-{{ ansible_architecture }}.tar.xz"
# gVisor only supports amd64 and uses x86_64 to in the download link
gvisor_runsc_download_url: "{{ storage_googleapis_url }}/gvisor/releases/release/{{ gvisor_version }}/{{ ansible_architecture }}/runsc"
gvisor_containerd_shim_runsc_download_url: "{{ storage_googleapis_url }}/gvisor/releases/release/{{ gvisor_version }}/{{ ansible_architecture }}/containerd-shim-runsc-v1"
nerdctl_download_url: "{{ github_url }}/containerd/nerdctl/releases/download/v{{ nerdctl_version }}/nerdctl-{{ nerdctl_version }}-{{ ansible_system | lower }}-{{ image_arch }}.tar.gz"
krew_download_url: "{{ github_url }}/kubernetes-sigs/krew/releases/download/{{ krew_version }}/krew-{{ host_os }}_{{ image_arch }}.tar.gz"
containerd_download_url: "{{ github_url }}/containerd/containerd/releases/download/v{{ containerd_version }}/containerd-{{ containerd_version }}-linux-{{ image_arch }}.tar.gz"
cri_dockerd_download_url: "{{ github_url }}/Mirantis/cri-dockerd/releases/download/v{{ cri_dockerd_version }}/cri-dockerd-{{ cri_dockerd_version }}.{{ image_arch }}.tgz"
skopeo_download_url: "{{ github_url }}/lework/skopeo-binary/releases/download/{{ skopeo_version }}/skopeo-linux-{{ image_arch }}"
yq_download_url: "{{ github_url }}/mikefarah/yq/releases/download/{{ yq_version }}/yq_linux_{{ image_arch }}"

etcd_binary_checksum: "{{ etcd_binary_checksums[image_arch][etcd_version] }}"
cni_binary_checksum: "{{ cni_binary_checksums[image_arch][cni_version] }}"
kubelet_binary_checksum: "{{ kubelet_checksums[image_arch][kube_version] }}"
kubectl_binary_checksum: "{{ kubectl_checksums[image_arch][kube_version] }}"
kubeadm_binary_checksum: "{{ kubeadm_checksums[image_arch][kube_version] }}"
yq_binary_checksum: "{{ yq_checksums[image_arch][yq_version] }}"
calicoctl_binary_checksum: "{{ calicoctl_binary_checksums[image_arch][calico_ctl_version] }}"
calico_crds_archive_checksum: "{{ calico_crds_archive_checksums[calico_version] }}"
ciliumcli_binary_checksum: "{{ ciliumcli_binary_checksums[image_arch][cilium_cli_version] }}"
crictl_binary_checksum: "{{ crictl_checksums[image_arch][crictl_version] }}"
crio_archive_checksum: "{{ crio_archive_checksums[image_arch][crio_version] }}"
cri_dockerd_archive_checksum: "{{ cri_dockerd_archive_checksums[image_arch][cri_dockerd_version] }}"
helm_archive_checksum: "{{ helm_archive_checksums[image_arch][helm_version] }}"
runc_binary_checksum: "{{ runc_checksums[image_arch][runc_version] }}"
crun_binary_checksum: "{{ crun_checksums[image_arch][crun_version] }}"
youki_archive_checksum: "{{ youki_checksums[image_arch][youki_version] }}"
kata_containers_binary_checksum: "{{ kata_containers_binary_checksums[image_arch][kata_containers_version] }}"
gvisor_runsc_binary_checksum: "{{ gvisor_runsc_binary_checksums[image_arch][gvisor_version] }}"
gvisor_containerd_shim_binary_checksum: "{{ gvisor_containerd_shim_binary_checksums[image_arch][gvisor_version] }}"
nerdctl_archive_checksum: "{{ nerdctl_archive_checksums[image_arch][nerdctl_version] }}"
krew_archive_checksum: "{{ krew_archive_checksums[host_os][image_arch][krew_version] }}"
containerd_archive_checksum: "{{ containerd_archive_checksums[image_arch][containerd_version] }}"
skopeo_binary_checksum: "{{ skopeo_binary_checksums[image_arch][skopeo_version] }}"

# Containers
# In some cases, we need a way to set --registry-mirror or --insecure-registry for docker,
# it helps a lot for local private development or bare metal environment.
# So you need define --registry-mirror or --insecure-registry, and modify the following url address.
# example:
# You need to deploy kubernetes cluster on local private development.
# Also provide the address of your own private registry.
# And use --insecure-registry options for docker
kube_proxy_image_repo: "{{ kube_image_repo }}/kube-proxy"
etcd_image_repo: "{{ quay_image_repo }}/coreos/etcd"
etcd_image_tag: "{{ etcd_version }}"
flannel_image_repo: "{{ docker_image_repo }}/flannel/flannel"
flannel_image_tag: "{{ flannel_version }}"
flannel_init_image_repo: "{{ docker_image_repo }}/flannel/flannel-cni-plugin"
flannel_init_image_tag: "{{ flannel_cni_version }}"
calico_node_image_repo: "{{ quay_image_repo }}/calico/node"
calico_node_image_tag: "{{ calico_version }}"
calico_cni_image_repo: "{{ quay_image_repo }}/calico/cni"
calico_cni_image_tag: "{{ calico_cni_version }}"
calico_policy_image_repo: "{{ quay_image_repo }}/calico/kube-controllers"
calico_policy_image_tag: "{{ calico_policy_version }}"
calico_typha_image_repo: "{{ quay_image_repo }}/calico/typha"
calico_typha_image_tag: "{{ calico_typha_version }}"
calico_apiserver_image_repo: "{{ quay_image_repo }}/calico/apiserver"
calico_apiserver_image_tag: "{{ calico_apiserver_version }}"
pod_infra_image_repo: "{{ kube_image_repo }}/pause"
pod_infra_image_tag: "{{ pod_infra_version }}"
netcheck_version: "v1.2.2"
netcheck_agent_image_repo: "{{ docker_image_repo }}/mirantis/k8s-netchecker-agent"
netcheck_agent_image_tag: "{{ netcheck_version }}"
netcheck_server_image_repo: "{{ docker_image_repo }}/mirantis/k8s-netchecker-server"
netcheck_server_image_tag: "{{ netcheck_version }}"
netcheck_etcd_image_tag: "v3.4.17"
weave_kube_image_repo: "{{ docker_image_repo }}/rajchaudhuri/weave-kube"
weave_kube_image_tag: "{{ weave_version }}"
weave_npc_image_repo: "{{ docker_image_repo }}/rajchaudhuri/weave-npc"
weave_npc_image_tag: "{{ weave_version }}"
cilium_image_repo: "{{ quay_image_repo }}/cilium/cilium"
cilium_image_tag: "{{ cilium_version }}"
cilium_operator_image_repo: "{{ quay_image_repo }}/cilium/operator"
cilium_operator_image_tag: "{{ cilium_version }}"
cilium_hubble_relay_image_repo: "{{ quay_image_repo }}/cilium/hubble-relay"
cilium_hubble_relay_image_tag: "{{ cilium_version }}"
cilium_hubble_certgen_image_repo: "{{ quay_image_repo }}/cilium/certgen"
cilium_hubble_certgen_image_tag: "v0.1.8"
cilium_hubble_ui_image_repo: "{{ quay_image_repo }}/cilium/hubble-ui"
cilium_hubble_ui_image_tag: "v0.11.0"
cilium_hubble_ui_backend_image_repo: "{{ quay_image_repo }}/cilium/hubble-ui-backend"
cilium_hubble_ui_backend_image_tag: "v0.11.0"
cilium_hubble_envoy_image_repo: "{{ docker_image_repo }}/envoyproxy/envoy"
cilium_hubble_envoy_image_tag: "v1.22.5"
kube_ovn_container_image_repo: "{{ docker_image_repo }}/kubeovn/kube-ovn"
kube_ovn_container_image_tag: "{{ kube_ovn_version }}"
kube_ovn_vpc_container_image_repo: "{{ docker_image_repo }}/kubeovn/vpc-nat-gateway"
kube_ovn_vpc_container_image_tag: "{{ kube_ovn_version }}"
kube_ovn_dpdk_container_image_repo: "{{ docker_image_repo }}/kubeovn/kube-ovn-dpdk"
kube_ovn_dpdk_container_image_tag: "{{ kube_ovn_dpdk_version }}"
kube_router_image_repo: "{{ docker_image_repo }}/cloudnativelabs/kube-router"
kube_router_image_tag: "{{ kube_router_version }}"
multus_image_repo: "{{ github_image_repo }}/k8snetworkplumbingwg/multus-cni"
multus_image_tag: "{{ multus_version }}"
external_openstack_cloud_controller_image_repo: "{{ kube_image_repo }}/provider-os/openstack-cloud-controller-manager"
external_openstack_cloud_controller_image_tag: "v1.31.1"

kube_vip_image_repo: "{{ github_image_repo }}/kube-vip/kube-vip"
kube_vip_image_tag: v0.8.0
nginx_image_repo: "{{ docker_image_repo }}/library/nginx"
nginx_image_tag: 1.25.2-alpine
haproxy_image_repo: "{{ docker_image_repo }}/library/haproxy"
haproxy_image_tag: 2.8.2-alpine

# Coredns version should be supported by corefile-migration (or at least work with)
# bundle with kubeadm; if not 'basic' upgrade can sometimes fail

coredns_version: "{{ 'v1.11.3' if (kube_version is version('v1.30.5', '>=')) else 'v1.11.1' }}"
coredns_image_is_namespaced: "{{ (coredns_version is version('v1.7.1', '>=')) }}"

coredns_image_repo: "{{ kube_image_repo }}{{ '/coredns/coredns' if (coredns_image_is_namespaced | bool) else '/coredns' }}"
coredns_image_tag: "{{ coredns_version if (coredns_image_is_namespaced | bool) else (coredns_version | regex_replace('^v', '')) }}"

nodelocaldns_version: "1.22.28"
nodelocaldns_image_repo: "{{ kube_image_repo }}/dns/k8s-dns-node-cache"
nodelocaldns_image_tag: "{{ nodelocaldns_version }}"

dnsautoscaler_version: v1.8.8
dnsautoscaler_image_repo: "{{ kube_image_repo }}/cpa/cluster-proportional-autoscaler"
dnsautoscaler_image_tag: "{{ dnsautoscaler_version }}"

scheduler_plugins_controller_image_repo: "{{ kube_image_repo }}/scheduler-plugins/controller"
scheduler_plugins_controller_image_tag: "{{ scheduler_plugins_version }}"
scheduler_plugins_scheduler_image_repo: "{{ kube_image_repo }}/scheduler-plugins/kube-scheduler"
scheduler_plugins_scheduler_image_tag: "{{ scheduler_plugins_version }}"

registry_version: "2.8.1"
registry_image_repo: "{{ docker_image_repo }}/library/registry"
registry_image_tag: "{{ registry_version }}"
metrics_server_version: "v0.7.0"
metrics_server_image_repo: "{{ kube_image_repo }}/metrics-server/metrics-server"
metrics_server_image_tag: "{{ metrics_server_version }}"
local_volume_provisioner_version: "v2.5.0"
local_volume_provisioner_image_repo: "{{ kube_image_repo }}/sig-storage/local-volume-provisioner"
local_volume_provisioner_image_tag: "{{ local_volume_provisioner_version }}"
cephfs_provisioner_version: "v2.1.0-k8s1.11"
cephfs_provisioner_image_repo: "{{ quay_image_repo }}/external_storage/cephfs-provisioner"
cephfs_provisioner_image_tag: "{{ cephfs_provisioner_version }}"
rbd_provisioner_version: "v2.1.1-k8s1.11"
rbd_provisioner_image_repo: "{{ quay_image_repo }}/external_storage/rbd-provisioner"
rbd_provisioner_image_tag: "{{ rbd_provisioner_version }}"
local_path_provisioner_version: "v0.0.24"
local_path_provisioner_image_repo: "{{ docker_image_repo }}/rancher/local-path-provisioner"
local_path_provisioner_image_tag: "{{ local_path_provisioner_version }}"
ingress_nginx_version: "v1.12.0"
ingress_nginx_controller_image_repo: "{{ kube_image_repo }}/ingress-nginx/controller"
ingress_nginx_opentelemetry_image_repo: "{{ kube_image_repo }}/ingress-nginx/opentelemetry"
ingress_nginx_controller_image_tag: "{{ ingress_nginx_version }}"
ingress_nginx_opentelemetry_image_tag: "v20230721-3e2062ee5"
ingress_nginx_kube_webhook_certgen_image_repo: "{{ kube_image_repo }}/ingress-nginx/kube-webhook-certgen"
ingress_nginx_kube_webhook_certgen_image_tag: "v1.5.0"
alb_ingress_image_repo: "{{ docker_image_repo }}/amazon/aws-alb-ingress-controller"
alb_ingress_image_tag: "v1.1.9"
cert_manager_version: "v1.15.3"
cert_manager_controller_image_repo: "{{ quay_image_repo }}/jetstack/cert-manager-controller"
cert_manager_controller_image_tag: "{{ cert_manager_version }}"
cert_manager_cainjector_image_repo: "{{ quay_image_repo }}/jetstack/cert-manager-cainjector"
cert_manager_cainjector_image_tag: "{{ cert_manager_version }}"
cert_manager_webhook_image_repo: "{{ quay_image_repo }}/jetstack/cert-manager-webhook"
cert_manager_webhook_image_tag: "{{ cert_manager_version }}"

csi_attacher_image_repo: "{{ kube_image_repo }}/sig-storage/csi-attacher"
csi_attacher_image_tag: "v3.3.0"
csi_provisioner_image_repo: "{{ kube_image_repo }}/sig-storage/csi-provisioner"
csi_provisioner_image_tag: "v3.0.0"
csi_snapshotter_image_repo: "{{ kube_image_repo }}/sig-storage/csi-snapshotter"
csi_snapshotter_image_tag: "v5.0.0"
csi_resizer_image_repo: "{{ kube_image_repo }}/sig-storage/csi-resizer"
csi_resizer_image_tag: "v1.3.0"
csi_node_driver_registrar_image_repo: "{{ kube_image_repo }}/sig-storage/csi-node-driver-registrar"
csi_node_driver_registrar_image_tag: "v2.4.0"
csi_livenessprobe_image_repo: "{{ kube_image_repo }}/sig-storage/livenessprobe"
csi_livenessprobe_image_tag: "v2.5.0"

snapshot_controller_supported_versions:
  v1.32: "v7.0.2"
  v1.31: "v7.0.2"
  v1.30: "v7.0.2"
snapshot_controller_image_repo: "{{ kube_image_repo }}/sig-storage/snapshot-controller"
snapshot_controller_image_tag: "{{ snapshot_controller_supported_versions[kube_major_version] }}"

cinder_csi_plugin_version: "v1.30.0"
cinder_csi_plugin_image_repo: "{{ kube_image_repo }}/provider-os/cinder-csi-plugin"
cinder_csi_plugin_image_tag: "{{ cinder_csi_plugin_version }}"

aws_ebs_csi_plugin_version: "v0.5.0"
aws_ebs_csi_plugin_image_repo: "{{ docker_image_repo }}/amazon/aws-ebs-csi-driver"
aws_ebs_csi_plugin_image_tag: "{{ aws_ebs_csi_plugin_version }}"

gcp_pd_csi_plugin_version: "v1.9.2"
gcp_pd_csi_plugin_image_repo: "{{ kube_image_repo }}/cloud-provider-gcp/gcp-compute-persistent-disk-csi-driver"
gcp_pd_csi_plugin_image_tag: "{{ gcp_pd_csi_plugin_version }}"

azure_csi_image_repo: "mcr.microsoft.com/oss/kubernetes-csi"
azure_csi_provisioner_image_tag: "v2.2.2"
azure_csi_attacher_image_tag: "v3.3.0"
azure_csi_resizer_image_tag: "v1.3.0"
azure_csi_livenessprobe_image_tag: "v2.5.0"
azure_csi_node_registrar_image_tag: "v2.4.0"
azure_csi_snapshotter_image_tag: "v3.0.3"
azure_csi_plugin_version: "v1.10.0"
azure_csi_plugin_image_repo: "mcr.microsoft.com/k8s/csi"
azure_csi_plugin_image_tag: "{{ azure_csi_plugin_version }}"

gcp_pd_csi_image_repo: "gke.gcr.io"
gcp_pd_csi_driver_image_tag: "v0.7.0-gke.0"
gcp_pd_csi_provisioner_image_tag: "v1.5.0-gke.0"
gcp_pd_csi_attacher_image_tag: "v2.1.1-gke.0"
gcp_pd_csi_resizer_image_tag: "v0.4.0-gke.0"
gcp_pd_csi_registrar_image_tag: "v1.2.0-gke.0"

dashboard_image_repo: "{{ docker_image_repo }}/kubernetesui/dashboard"
dashboard_image_tag: "v2.7.0"
dashboard_metrics_scraper_repo: "{{ docker_image_repo }}/kubernetesui/metrics-scraper"
dashboard_metrics_scraper_tag: "v1.0.8"

metallb_speaker_image_repo: "{{ quay_image_repo }}/metallb/speaker"
metallb_controller_image_repo: "{{ quay_image_repo }}/metallb/controller"
metallb_version: v0.13.9

node_feature_discovery_version: v0.16.4
node_feature_discovery_image_repo: "{{ kube_image_repo }}/nfd/node-feature-discovery"
node_feature_discovery_image_tag: "{{ node_feature_discovery_version }}"

downloads:
  netcheck_server:
    enabled: "{{ deploy_netchecker }}"
    container: true
    repo: "{{ netcheck_server_image_repo }}"
    tag: "{{ netcheck_server_image_tag }}"
    sha256: "{{ netcheck_server_digest_checksum | default(None) }}"
    groups:
      - k8s_cluster

  netcheck_agent:
    enabled: "{{ deploy_netchecker }}"
    container: true
    repo: "{{ netcheck_agent_image_repo }}"
    tag: "{{ netcheck_agent_image_tag }}"
    sha256: "{{ netcheck_agent_digest_checksum | default(None) }}"
    groups:
      - k8s_cluster

  etcd:
    container: "{{ etcd_deployment_type != 'host' }}"
    file: "{{ etcd_deployment_type == 'host' }}"
    enabled: true
    version: "{{ etcd_version }}"
    dest: "{{ local_release_dir }}/etcd-{{ etcd_version }}-linux-{{ image_arch }}.tar.gz"
    repo: "{{ etcd_image_repo }}"
    tag: "{{ etcd_image_tag }}"
    sha256: >-
      {{ etcd_binary_checksum if (etcd_deployment_type == 'host')
      else etcd_digest_checksum | d(None) }}
    url: "{{ etcd_download_url }}"
    unarchive: "{{ etcd_deployment_type == 'host' }}"
    owner: "root"
    mode: "0755"
    groups:
      - etcd

  cni:
    enabled: true
    file: true
    version: "{{ cni_version }}"
    dest: "{{ local_release_dir }}/cni-plugins-linux-{{ image_arch }}-{{ cni_version }}.tgz"
    sha256: "{{ cni_binary_checksum }}"
    url: "{{ cni_download_url }}"
    unarchive: false
    owner: "root"
    mode: "0755"
    groups:
      - k8s_cluster

  kubeadm:
    enabled: true
    file: true
    version: "{{ kube_version }}"
    dest: "{{ local_release_dir }}/kubeadm-{{ kube_version }}-{{ image_arch }}"
    sha256: "{{ kubeadm_binary_checksum }}"
    url: "{{ kubeadm_download_url }}"
    unarchive: false
    owner: "root"
    mode: "0755"
    groups:
      - k8s_cluster

  kubelet:
    enabled: true
    file: true
    version: "{{ kube_version }}"
    dest: "{{ local_release_dir }}/kubelet-{{ kube_version }}-{{ image_arch }}"
    sha256: "{{ kubelet_binary_checksum }}"
    url: "{{ kubelet_download_url }}"
    unarchive: false
    owner: "root"
    mode: "0755"
    groups:
      - k8s_cluster

  kubectl:
    enabled: true
    file: true
    version: "{{ kube_version }}"
    dest: "{{ local_release_dir }}/kubectl-{{ kube_version }}-{{ image_arch }}"
    sha256: "{{ kubectl_binary_checksum }}"
    url: "{{ kubectl_download_url }}"
    unarchive: false
    owner: "root"
    mode: "0755"
    groups:
      - kube_control_plane

  crictl:
    file: true
    enabled: true
    version: "{{ crictl_version }}"
    dest: "{{ local_release_dir }}/crictl-{{ crictl_version }}-linux-{{ image_arch }}.tar.gz"
    sha256: "{{ crictl_binary_checksum }}"
    url: "{{ crictl_download_url }}"
    unarchive: true
    owner: "root"
    mode: "0755"
    groups:
      - k8s_cluster

  crio:
    file: true
    enabled: "{{ container_manager == 'crio' }}"
    version: "{{ crio_version }}"
    dest: "{{ local_release_dir }}/cri-o.{{ image_arch }}.{{ crio_version }}.tar.gz"
    sha256: "{{ crio_archive_checksum }}"
    url: "{{ crio_download_url }}"
    unarchive: true
    owner: "root"
    mode: "0755"
    groups:
      - k8s_cluster

  cri_dockerd:
    file: true
    enabled: "{{ container_manager == 'docker' }}"
    version: "{{ cri_dockerd_version }}"
    dest: "{{ local_release_dir }}/cri-dockerd-{{ cri_dockerd_version }}.{{ image_arch }}.tar.gz"
    sha256: "{{ cri_dockerd_archive_checksum }}"
    url: "{{ cri_dockerd_download_url }}"
    unarchive: true
    unarchive_extra_opts:
      - --strip=1
    owner: "root"
    mode: "0755"
    groups:
      - k8s_cluster

  crun:
    file: true
    enabled: "{{ crun_enabled }}"
    version: "{{ crun_version }}"
    dest: "{{ local_release_dir }}/crun-{{ crun_version }}-{{ image_arch }}"
    sha256: "{{ crun_binary_checksum }}"
    url: "{{ crun_download_url }}"
    unarchive: false
    owner: "root"
    mode: "0755"
    groups:
      - k8s_cluster

  youki:
    file: true
    enabled: "{{ youki_enabled }}"
    version: "{{ youki_version }}"
    dest: "{{ local_release_dir }}/youki-{{ youki_version }}-{{ ansible_architecture }}.tar.gz"
    sha256: "{{ youki_archive_checksum }}"
    url: "{{ youki_download_url }}"
    unarchive: true
    owner: "root"
    mode: "0755"
    groups:
      - k8s_cluster

  runc:
    file: true
    enabled: "{{ container_manager == 'containerd' }}"
    version: "{{ runc_version }}"
    dest: "{{ local_release_dir }}/runc-{{ runc_version }}.{{ image_arch }}"
    sha256: "{{ runc_binary_checksum }}"
    url: "{{ runc_download_url }}"
    unarchive: false
    owner: "root"
    mode: "0755"
    groups:
      - k8s_cluster

  kata_containers:
    enabled: "{{ kata_containers_enabled }}"
    file: true
    version: "{{ kata_containers_version }}"
    dest: "{{ local_release_dir }}/kata-static-{{ kata_containers_version }}-{{ image_arch }}.tar.xz"
    sha256: "{{ kata_containers_binary_checksum }}"
    url: "{{ kata_containers_download_url }}"
    unarchive: false
    owner: "root"
    mode: "0755"
    groups:
      - k8s_cluster

  containerd:
    enabled: "{{ container_manager == 'containerd' }}"
    file: true
    version: "{{ containerd_version }}"
    dest: "{{ local_release_dir }}/containerd-{{ containerd_version }}-linux-{{ image_arch }}.tar.gz"
    sha256: "{{ containerd_archive_checksum }}"
    url: "{{ containerd_download_url }}"
    unarchive: false
    owner: "root"
    mode: "0755"
    groups:
      - k8s_cluster

  gvisor_runsc:
    enabled: "{{ gvisor_enabled }}"
    file: true
    version: "{{ gvisor_version }}"
    dest: "{{ local_release_dir }}/gvisor-runsc-{{ gvisor_version }}-{{ ansible_architecture }}"
    sha256: "{{ gvisor_runsc_binary_checksum }}"
    url: "{{ gvisor_runsc_download_url }}"
    unarchive: false
    owner: "root"
    mode: 755
    groups:
      - k8s_cluster

  gvisor_containerd_shim:
    enabled: "{{ gvisor_enabled }}"
    file: true
    version: "{{ gvisor_version }}"
    dest: "{{ local_release_dir }}/gvisor-containerd-shim-runsc-v1-{{ gvisor_version }}-{{ ansible_architecture }}"
    sha256: "{{ gvisor_containerd_shim_binary_checksum }}"
    url: "{{ gvisor_containerd_shim_runsc_download_url }}"
    unarchive: false
    owner: "root"
    mode: 755
    groups:
      - k8s_cluster

  nerdctl:
    file: true
    enabled: "{{ container_manager == 'containerd' }}"
    version: "{{ nerdctl_version }}"
    dest: "{{ local_release_dir }}/nerdctl-{{ nerdctl_version }}-linux-{{ image_arch }}.tar.gz"
    sha256: "{{ nerdctl_archive_checksum }}"
    url: "{{ nerdctl_download_url }}"
    unarchive: true
    owner: "root"
    mode: "0755"
    groups:
      - k8s_cluster

  skopeo:
    file: true
    enabled: "{{ container_manager == 'crio' }}"
    version: "{{ skopeo_version }}"
    dest: "{{ local_release_dir }}/skopeo-{{ skopeo_version }}-{{ image_arch }}"
    sha256: "{{ skopeo_binary_checksum }}"
    url: "{{ skopeo_download_url }}"
    unarchive: false
    owner: "root"
    mode: "0755"
    groups:
      - kube_control_plane

  cilium:
    enabled: "{{ kube_network_plugin == 'cilium' or cilium_deploy_additionally | default(false) | bool }}"
    container: true
    repo: "{{ cilium_image_repo }}"
    tag: "{{ cilium_image_tag }}"
    sha256: "{{ cilium_digest_checksum | default(None) }}"
    groups:
      - k8s_cluster

  cilium_operator:
    enabled: "{{ kube_network_plugin == 'cilium' or cilium_deploy_additionally | default(false) | bool }}"
    container: true
    repo: "{{ cilium_operator_image_repo }}"
    tag: "{{ cilium_operator_image_tag }}"
    sha256: "{{ cilium_operator_digest_checksum | default(None) }}"
    groups:
      - k8s_cluster

  cilium_hubble_relay:
    enabled: "{{ cilium_enable_hubble }}"
    container: true
    repo: "{{ cilium_hubble_relay_image_repo }}"
    tag: "{{ cilium_hubble_relay_image_tag }}"
    sha256: "{{ cilium_hubble_relay_digest_checksum | default(None) }}"
    groups:
      - k8s_cluster

  cilium_hubble_certgen:
    enabled: "{{ cilium_enable_hubble }}"
    container: true
    repo: "{{ cilium_hubble_certgen_image_repo }}"
    tag: "{{ cilium_hubble_certgen_image_tag }}"
    sha256: "{{ cilium_hubble_certgen_digest_checksum | default(None) }}"
    groups:
      - k8s_cluster

  cilium_hubble_ui:
    enabled: "{{ cilium_enable_hubble }}"
    container: true
    repo: "{{ cilium_hubble_ui_image_repo }}"
    tag: "{{ cilium_hubble_ui_image_tag }}"
    sha256: "{{ cilium_hubble_ui_digest_checksum | default(None) }}"
    groups:
      - k8s_cluster

  cilium_hubble_ui_backend:
    enabled: "{{ cilium_enable_hubble }}"
    container: true
    repo: "{{ cilium_hubble_ui_backend_image_repo }}"
    tag: "{{ cilium_hubble_ui_backend_image_tag }}"
    sha256: "{{ cilium_hubble_ui_backend_digest_checksum | default(None) }}"
    groups:
      - k8s_cluster

  cilium_hubble_envoy:
    enabled: "{{ cilium_enable_hubble }}"
    container: true
    repo: "{{ cilium_hubble_envoy_image_repo }}"
    tag: "{{ cilium_hubble_envoy_image_tag }}"
    sha256: "{{ cilium_hubble_envoy_digest_checksum | default(None) }}"
    groups:
      - k8s_cluster

  ciliumcli:
    enabled: "{{ kube_network_plugin == 'cilium' or cilium_deploy_additionally | default(false) | bool }}"
    file: true
    version: "{{ cilium_cli_version }}"
    dest: "{{ local_release_dir }}/cilium-{{ cilium_cli_version }}-{{ image_arch }}.tar.gz"
    sha256: "{{ ciliumcli_binary_checksum }}"
    url: "{{ ciliumcli_download_url }}"
    unarchive: true
    owner: "root"
    mode: "0755"
    groups:
      - k8s_cluster

  multus:
    enabled: "{{ kube_network_plugin_multus }}"
    container: true
    repo: "{{ multus_image_repo }}"
    tag: "{{ multus_image_tag }}"
    sha256: "{{ multus_digest_checksum | default(None) }}"
    groups:
      - k8s_cluster

  flannel:
    enabled: "{{ kube_network_plugin == 'flannel' }}"
    container: true
    repo: "{{ flannel_image_repo }}"
    tag: "{{ flannel_image_tag }}"
    sha256: "{{ flannel_digest_checksum | default(None) }}"
    groups:
      - k8s_cluster

  flannel_init:
    enabled: "{{ kube_network_plugin == 'flannel' }}"
    container: true
    repo: "{{ flannel_init_image_repo }}"
    tag: "{{ flannel_init_image_tag }}"
    sha256: "{{ flannel_init_digest_checksum | default(None) }}"
    groups:
      - k8s_cluster

  calicoctl:
    enabled: "{{ kube_network_plugin == 'calico' }}"
    file: true
    version: "{{ calico_ctl_version }}"
    dest: "{{ local_release_dir }}/calicoctl-{{ calico_ctl_version }}-{{ image_arch }}"
    sha256: "{{ calicoctl_binary_checksum }}"
    url: "{{ calicoctl_download_url }}"
    unarchive: false
    owner: "root"
    mode: "0755"
    groups:
      - k8s_cluster

  calico_node:
    enabled: "{{ kube_network_plugin == 'calico' }}"
    container: true
    repo: "{{ calico_node_image_repo }}"
    tag: "{{ calico_node_image_tag }}"
    sha256: "{{ calico_node_digest_checksum | default(None) }}"
    groups:
      - k8s_cluster

  calico_cni:
    enabled: "{{ kube_network_plugin == 'calico' }}"
    container: true
    repo: "{{ calico_cni_image_repo }}"
    tag: "{{ calico_cni_image_tag }}"
    sha256: "{{ calico_cni_digest_checksum | default(None) }}"
    groups:
      - k8s_cluster

  calico_policy:
    enabled: "{{ enable_network_policy and kube_network_plugin in ['calico'] }}"
    container: true
    repo: "{{ calico_policy_image_repo }}"
    tag: "{{ calico_policy_image_tag }}"
    sha256: "{{ calico_policy_digest_checksum | default(None) }}"
    groups:
      - k8s_cluster

  calico_typha:
    enabled: "{{ typha_enabled }}"
    container: true
    repo: "{{ calico_typha_image_repo }}"
    tag: "{{ calico_typha_image_tag }}"
    sha256: "{{ calico_typha_digest_checksum | default(None) }}"
    groups:
      - k8s_cluster

  calico_apiserver:
    enabled: "{{ calico_apiserver_enabled }}"
    container: true
    repo: "{{ calico_apiserver_image_repo }}"
    tag: "{{ calico_apiserver_image_tag }}"
    sha256: "{{ calico_apiserver_digest_checksum | default(None) }}"
    groups:
      - k8s_cluster

  calico_crds:
    file: true
    enabled: "{{ kube_network_plugin == 'calico' and calico_datastore == 'kdd' }}"
    version: "{{ calico_version }}"
    dest: "{{ local_release_dir }}/calico-{{ calico_version }}-kdd-crds/{{ calico_version }}.tar.gz"
    sha256: "{{ calico_crds_archive_checksum }}"
    url: "{{ calico_crds_download_url }}"
    unarchive: true
    unarchive_extra_opts:
      - "{{ '--strip=6' if (calico_version is version('v3.22.3', '<')) else '--strip=3' }}"
      - "--wildcards"
      - "{{ '*/_includes/charts/calico/crds/kdd/' if (calico_version is version('v3.22.3', '<')) else '*/libcalico-go/config/crd/' }}"
    owner: "root"
    mode: "0755"
    groups:
      - kube_control_plane

  weave_kube:
    enabled: "{{ kube_network_plugin == 'weave' }}"
    container: true
    repo: "{{ weave_kube_image_repo }}"
    tag: "{{ weave_kube_image_tag }}"
    sha256: "{{ weave_kube_digest_checksum | default(None) }}"
    groups:
      - k8s_cluster

  weave_npc:
    enabled: "{{ kube_network_plugin == 'weave' }}"
    container: true
    repo: "{{ weave_npc_image_repo }}"
    tag: "{{ weave_npc_image_tag }}"
    sha256: "{{ weave_npc_digest_checksum | default(None) }}"
    groups:
      - k8s_cluster

  kube_ovn:
    enabled: "{{ kube_network_plugin == 'kube-ovn' }}"
    container: true
    repo: "{{ kube_ovn_container_image_repo }}"
    tag: "{{ kube_ovn_container_image_tag }}"
    sha256: "{{ kube_ovn_digest_checksum | default(None) }}"
    groups:
      - k8s_cluster

  kube_router:
    enabled: "{{ kube_network_plugin == 'kube-router' }}"
    container: true
    repo: "{{ kube_router_image_repo }}"
    tag: "{{ kube_router_image_tag }}"
    sha256: "{{ kube_router_digest_checksum | default(None) }}"
    groups:
      - k8s_cluster

  pod_infra:
    enabled: true
    container: true
    repo: "{{ pod_infra_image_repo }}"
    tag: "{{ pod_infra_image_tag }}"
    sha256: "{{ pod_infra_digest_checksum | default(None) }}"
    groups:
      - k8s_cluster

  kube-vip:
    enabled: "{{ kube_vip_enabled }}"
    container: true
    repo: "{{ kube_vip_image_repo }}"
    tag: "{{ kube_vip_image_tag }}"
    sha256: "{{ kube_vip_digest_checksum | default(None) }}"
    groups:
      - kube_control_plane

  nginx:
    enabled: "{{ loadbalancer_apiserver_localhost and loadbalancer_apiserver_type == 'nginx' }}"
    container: true
    repo: "{{ nginx_image_repo }}"
    tag: "{{ nginx_image_tag }}"
    sha256: "{{ nginx_digest_checksum | default(None) }}"
    groups:
      - kube_node

  haproxy:
    enabled: "{{ loadbalancer_apiserver_localhost and loadbalancer_apiserver_type == 'haproxy' }}"
    container: true
    repo: "{{ haproxy_image_repo }}"
    tag: "{{ haproxy_image_tag }}"
    sha256: "{{ haproxy_digest_checksum | default(None) }}"
    groups:
      - kube_node

  coredns:
    enabled: "{{ dns_mode in ['coredns', 'coredns_dual'] }}"
    container: true
    repo: "{{ coredns_image_repo }}"
    tag: "{{ coredns_image_tag }}"
    sha256: "{{ coredns_digest_checksum | default(None) }}"
    groups:
      - k8s_cluster

  nodelocaldns:
    enabled: "{{ enable_nodelocaldns }}"
    container: true
    repo: "{{ nodelocaldns_image_repo }}"
    tag: "{{ nodelocaldns_image_tag }}"
    sha256: "{{ nodelocaldns_digest_checksum | default(None) }}"
    groups:
      - k8s_cluster

  dnsautoscaler:
    enabled: "{{ dns_mode in ['coredns', 'coredns_dual'] }}"
    container: true
    repo: "{{ dnsautoscaler_image_repo }}"
    tag: "{{ dnsautoscaler_image_tag }}"
    sha256: "{{ dnsautoscaler_digest_checksum | default(None) }}"
    groups:
      - kube_control_plane

  helm:
    enabled: "{{ helm_enabled }}"
    file: true
    version: "{{ helm_version }}"
    dest: "{{ local_release_dir }}/helm-{{ helm_version }}/helm-{{ helm_version }}-linux-{{ image_arch }}.tar.gz"
    sha256: "{{ helm_archive_checksum }}"
    url: "{{ helm_download_url }}"
    unarchive: true
    owner: "root"
    mode: "0755"
    groups:
      - kube_control_plane

  krew:
    enabled: "{{ krew_enabled }}"
    file: true
    version: "{{ krew_version }}"
    dest: "{{ local_release_dir }}/krew-{{ host_os }}_{{ image_arch }}.tar.gz"
    sha256: "{{ krew_archive_checksum }}"
    url: "{{ krew_download_url }}"
    unarchive: true
    owner: "root"
    mode: "0755"
    groups:
      - kube_control_plane

  registry:
    enabled: "{{ registry_enabled }}"
    container: true
    repo: "{{ registry_image_repo }}"
    tag: "{{ registry_image_tag }}"
    sha256: "{{ registry_digest_checksum | default(None) }}"
    groups:
      - kube_node

  metrics_server:
    enabled: "{{ metrics_server_enabled }}"
    container: true
    repo: "{{ metrics_server_image_repo }}"
    tag: "{{ metrics_server_image_tag }}"
    sha256: "{{ metrics_server_digest_checksum | default(None) }}"
    groups:
      - kube_control_plane

  local_volume_provisioner:
    enabled: "{{ local_volume_provisioner_enabled }}"
    container: true
    repo: "{{ local_volume_provisioner_image_repo }}"
    tag: "{{ local_volume_provisioner_image_tag }}"
    sha256: "{{ local_volume_provisioner_digest_checksum | default(None) }}"
    groups:
      - kube_node

  cephfs_provisioner:
    enabled: "{{ cephfs_provisioner_enabled }}"
    container: true
    repo: "{{ cephfs_provisioner_image_repo }}"
    tag: "{{ cephfs_provisioner_image_tag }}"
    sha256: "{{ cephfs_provisioner_digest_checksum | default(None) }}"
    groups:
      - kube_node

  rbd_provisioner:
    enabled: "{{ rbd_provisioner_enabled }}"
    container: true
    repo: "{{ rbd_provisioner_image_repo }}"
    tag: "{{ rbd_provisioner_image_tag }}"
    sha256: "{{ rbd_provisioner_digest_checksum | default(None) }}"
    groups:
      - kube_node

  local_path_provisioner:
    enabled: "{{ local_path_provisioner_enabled }}"
    container: true
    repo: "{{ local_path_provisioner_image_repo }}"
    tag: "{{ local_path_provisioner_image_tag }}"
    sha256: "{{ local_path_provisioner_digest_checksum | default(None) }}"
    groups:
      - kube_node

  ingress_nginx_controller:
    enabled: "{{ ingress_nginx_enabled }}"
    container: true
    repo: "{{ ingress_nginx_controller_image_repo }}"
    tag: "{{ ingress_nginx_controller_image_tag }}"
    sha256: "{{ ingress_nginx_controller_digest_checksum | default(None) }}"
    groups:
      - kube_node

  ingress_alb_controller:
    enabled: "{{ ingress_alb_enabled }}"
    container: true
    repo: "{{ alb_ingress_image_repo }}"
    tag: "{{ alb_ingress_image_tag }}"
    sha256: "{{ ingress_alb_controller_digest_checksum | default(None) }}"
    groups:
      - kube_node

  cert_manager_controller:
    enabled: "{{ cert_manager_enabled }}"
    container: true
    repo: "{{ cert_manager_controller_image_repo }}"
    tag: "{{ cert_manager_controller_image_tag }}"
    sha256: "{{ cert_manager_controller_digest_checksum | default(None) }}"
    groups:
      - kube_node

  cert_manager_cainjector:
    enabled: "{{ cert_manager_enabled }}"
    container: true
    repo: "{{ cert_manager_cainjector_image_repo }}"
    tag: "{{ cert_manager_cainjector_image_tag }}"
    sha256: "{{ cert_manager_cainjector_digest_checksum | default(None) }}"
    groups:
      - kube_node

  cert_manager_webhook:
    enabled: "{{ cert_manager_enabled }}"
    container: true
    repo: "{{ cert_manager_webhook_image_repo }}"
    tag: "{{ cert_manager_webhook_image_tag }}"
    sha256: "{{ cert_manager_webhook_digest_checksum | default(None) }}"
    groups:
      - kube_node

  csi_attacher:
    enabled: "{{ cinder_csi_enabled or aws_ebs_csi_enabled }}"
    container: true
    repo: "{{ csi_attacher_image_repo }}"
    tag: "{{ csi_attacher_image_tag }}"
    sha256: "{{ csi_attacher_digest_checksum | default(None) }}"
    groups:
      - kube_node

  csi_provisioner:
    enabled: "{{ cinder_csi_enabled or aws_ebs_csi_enabled }}"
    container: true
    repo: "{{ csi_provisioner_image_repo }}"
    tag: "{{ csi_provisioner_image_tag }}"
    sha256: "{{ csi_provisioner_digest_checksum | default(None) }}"
    groups:
      - kube_node

  csi_snapshotter:
    enabled: "{{ cinder_csi_enabled or aws_ebs_csi_enabled }}"
    container: true
    repo: "{{ csi_snapshotter_image_repo }}"
    tag: "{{ csi_snapshotter_image_tag }}"
    sha256: "{{ csi_snapshotter_digest_checksum | default(None) }}"
    groups:
      - kube_node

  snapshot_controller:
    enabled: "{{ csi_snapshot_controller_enabled }}"
    container: true
    repo: "{{ snapshot_controller_image_repo }}"
    tag: "{{ snapshot_controller_image_tag }}"
    sha256: "{{ snapshot_controller_digest_checksum | default(None) }}"
    groups:
      - kube_node

  csi_resizer:
    enabled: "{{ cinder_csi_enabled or aws_ebs_csi_enabled }}"
    container: true
    repo: "{{ csi_resizer_image_repo }}"
    tag: "{{ csi_resizer_image_tag }}"
    sha256: "{{ csi_resizer_digest_checksum | default(None) }}"
    groups:
      - kube_node

  csi_node_driver_registrar:
    enabled: "{{ cinder_csi_enabled or aws_ebs_csi_enabled }}"
    container: true
    repo: "{{ csi_node_driver_registrar_image_repo }}"
    tag: "{{ csi_node_driver_registrar_image_tag }}"
    sha256: "{{ csi_node_driver_registrar_digest_checksum | default(None) }}"
    groups:
      - kube_node

  cinder_csi_plugin:
    enabled: "{{ cinder_csi_enabled }}"
    container: true
    repo: "{{ cinder_csi_plugin_image_repo }}"
    tag: "{{ cinder_csi_plugin_image_tag }}"
    sha256: "{{ cinder_csi_plugin_digest_checksum | default(None) }}"
    groups:
      - kube_node

  aws_ebs_csi_plugin:
    enabled: "{{ aws_ebs_csi_enabled }}"
    container: true
    repo: "{{ aws_ebs_csi_plugin_image_repo }}"
    tag: "{{ aws_ebs_csi_plugin_image_tag }}"
    sha256: "{{ aws_ebs_csi_plugin_digest_checksum | default(None) }}"
    groups:
      - kube_node

  dashboard:
    enabled: "{{ dashboard_enabled }}"
    container: true
    repo: "{{ dashboard_image_repo }}"
    tag: "{{ dashboard_image_tag }}"
    sha256: "{{ dashboard_digest_checksum | default(None) }}"
    groups:
      - kube_control_plane

  dashboard_metrics_scrapper:
    enabled: "{{ dashboard_enabled }}"
    container: true
    repo: "{{ dashboard_metrics_scraper_repo }}"
    tag: "{{ dashboard_metrics_scraper_tag }}"
    sha256: "{{ dashboard_digest_checksum | default(None) }}"
    groups:
      - kube_control_plane

  metallb_speaker:
    enabled: "{{ metallb_speaker_enabled }}"
    container: true
    repo: "{{ metallb_speaker_image_repo }}"
    tag: "{{ metallb_version }}"
    sha256: "{{ metallb_speaker_digest_checksum | default(None) }}"
    groups:
      - kube_control_plane

  metallb_controller:
    enabled: "{{ metallb_enabled }}"
    container: true
    repo: "{{ metallb_controller_image_repo }}"
    tag: "{{ metallb_version }}"
    sha256: "{{ metallb_controller_digest_checksum | default(None) }}"
    groups:
      - kube_control_plane

  yq:
    enabled: "{{ argocd_enabled }}"
    file: true
    version: "{{ yq_version }}"
    dest: "{{ local_release_dir }}/yq-{{ yq_version }}-{{ image_arch }}"
    sha256: "{{ yq_binary_checksum | default(None) }}"
    url: "{{ yq_download_url }}"
    unarchive: false
    owner: "root"
    mode: "0755"
    groups:
      - kube_control_plane

download_defaults:
  container: false
  file: false
  repo: None
  tag: None
  enabled: false
  dest: None
  version: None
  url: None
  unarchive: false
  owner: "{{ kube_owner }}"
  mode: None

## roles/kubespray-defaults/defaults/main/main.yml <==
---
# Use proxycommand if bastion host is in group all
# This change obseletes editing ansible.cfg file depending on bastion existence
ansible_ssh_common_args: "{% if 'bastion' in groups['all'] %} -o ProxyCommand='ssh -o UserKnownHostsFile=/dev/null -o StrictHostKeyChecking=no -W %h:%p -p {{ hostvars['bastion']['ansible_port'] | default(22) }} {{ hostvars['bastion']['ansible_user'] }}@{{ hostvars['bastion']['ansible_host'] }} {% if ansible_ssh_private_key_file is defined %}-i {{ ansible_ssh_private_key_file }}{% endif %} ' {% endif %}"

# selinux state
preinstall_selinux_state: permissive

# Setting this value to false will fail
# For details, read this comment https://github.com/kubernetes-sigs/kubespray/pull/11016#issuecomment-2004985001
kube_api_anonymous_auth: true

# Default value, but will be set to true automatically if detected
is_fedora_coreos: false

# Swap settings
kubelet_fail_swap_on: true
kubelet_swap_behavior: LimitedSwap

## Change this to use another Kubernetes version, e.g. a current beta release
kube_version: v1.32.0

## The minimum version working
kube_version_min_required: v1.30.0

## Kube Proxy mode One of ['iptables', 'ipvs']
kube_proxy_mode: ipvs

# Kubeadm config api version
# If kube_version is v1.31 or higher, it will be v1beta4, otherwise it will be v1beta3.
kubeadm_config_api_version: "{{ 'v1beta4' if kube_version is version('v1.31.0', '>=') else 'v1beta3' }}"

## The timeout for init first control-plane
kubeadm_init_timeout: 300s

# TODO: remove this
kube_reserved_cgroups_for_service_slice: kube.slice

## List of kubeadm init phases that should be skipped during control plane setup
## By default 'addon/coredns' is skipped
## 'addon/kube-proxy' gets skipped for some network plugins
kubeadm_init_phases_skip_default: [ "addon/coredns" ]
kubeadm_init_phases_skip: >-
  {%- if kube_network_plugin == 'kube-router' and (kube_router_run_service_proxy is defined and kube_router_run_service_proxy) -%}
  {{ kubeadm_init_phases_skip_default + ["addon/kube-proxy"] }}
  {%- elif kube_network_plugin == 'cilium' and (cilium_kube_proxy_replacement is defined and (cilium_kube_proxy_replacement == 'strict' or (cilium_kube_proxy_replacement | bool) or (cilium_kube_proxy_replacement | string | lower == 'true') )) -%}
  {{ kubeadm_init_phases_skip_default + ["addon/kube-proxy"] }}
  {%- elif kube_network_plugin == 'calico' and (calico_bpf_enabled is defined and calico_bpf_enabled) -%}
  {{ kubeadm_init_phases_skip_default + ["addon/kube-proxy"] }}
  {%- elif kube_proxy_remove is defined and kube_proxy_remove -%}
  {{ kubeadm_init_phases_skip_default + ["addon/kube-proxy"] }}
  {%- else -%}
  {{ kubeadm_init_phases_skip_default }}
  {%- endif -%}

# List of kubeadm phases that should be skipped when joining a new node
# You may need to set this to ['preflight'] for air-gaped deployments to avoid failing connectivity tests.
kubeadm_join_phases_skip_default: []
kubeadm_join_phases_skip: >-
 {{ kubeadm_join_phases_skip_default }}

# Set to true to remove the role binding to anonymous users created by kubeadm
remove_anonymous_access: false

# A string slice of values which specify the addresses to use for NodePorts.
# Values may be valid IP blocks (e.g. 1.2.3.0/24, 1.2.3.4/32).
# The default empty string slice ([]) means to use all local addresses.
# kube_proxy_nodeport_addresses_cidr is retained for legacy config
kube_proxy_nodeport_addresses: >-
  {%- if kube_proxy_nodeport_addresses_cidr is defined -%}
  [{{ kube_proxy_nodeport_addresses_cidr }}]
  {%- else -%}
  []
  {%- endif -%}

# Set to true to allow pre-checks to fail and continue deployment
ignore_assert_errors: false

kube_vip_enabled: false

# nginx-proxy configure
nginx_config_dir: "/etc/nginx"

# haproxy configure
haproxy_config_dir: "/etc/haproxy"

# Directory where the binaries will be installed
bin_dir: /usr/local/bin
docker_bin_dir: /usr/bin
containerd_bin_dir: "{{ bin_dir }}"
etcd_data_dir: /var/lib/etcd
# Where the binaries will be downloaded.
# Note: ensure that you've enough disk space (about 1G)
local_release_dir: "/tmp/releases"
# Random shifts for retrying failed ops like pushing/downloading
retry_stagger: 5

# Install epel repo on Centos/RHEL
epel_enabled: false

# DNS configuration.
# Kubernetes cluster name, also will be used as DNS domain
cluster_name: cluster.local
# Subdomains of DNS domain to be resolved via /etc/resolv.conf for hostnet pods
ndots: 2
# Default resolv.conf options
docker_dns_options:
- ndots:{{ ndots }}
- timeout:2
- attempts:2
# Can be coredns, coredns_dual, manual, or none
dns_mode: coredns

# Enable dns autoscaler
enable_dns_autoscaler: true

# DNS servers added after the cluster DNS
# These will also be used as upstream by Coredns for out-cluster queries
upstream_dns_servers: []

# Enable nodelocal dns cache
enable_nodelocaldns: true
enable_nodelocaldns_secondary: false
nodelocaldns_ip: 169.254.25.10
nodelocaldns_health_port: 9254
nodelocaldns_second_health_port: 9256
nodelocaldns_bind_metrics_host_ip: false
nodelocaldns_secondary_skew_seconds: 5

# Should be set to a cluster IP if using a custom cluster DNS
manual_dns_server: ""

# Can be host_resolvconf, docker_dns or none
resolvconf_mode: host_resolvconf
# Deploy netchecker app to verify DNS resolve as an HTTP service
deploy_netchecker: false
# Ip address of the kubernetes DNS service (called skydns for historical reasons)
skydns_server: "{{ kube_service_addresses | ansible.utils.ipaddr('net') | ansible.utils.ipaddr(3) | ansible.utils.ipaddr('address') }}"
skydns_server_secondary: "{{ kube_service_addresses | ansible.utils.ipaddr('net') | ansible.utils.ipaddr(4) | ansible.utils.ipaddr('address') }}"
dns_domain: "{{ cluster_name }}"
docker_dns_search_domains:
- 'default.svc.{{ dns_domain }}'
- 'svc.{{ dns_domain }}'
searchdomains: []

kube_dns_servers:
  coredns: ["{{ skydns_server }}"]
  coredns_dual: "{{ [skydns_server] + [skydns_server_secondary] }}"
  manual: ["{{ manual_dns_server }}"]

dns_servers: "{{ kube_dns_servers[dns_mode] }}"

enable_coredns_k8s_external: false
coredns_k8s_external_zone: k8s_external.local

enable_coredns_k8s_endpoint_pod_names: false

# Kubernetes configuration dirs and system namespace.
# Those are where all the additional config stuff goes
# the kubernetes normally puts in /srv/kubernetes.
# This puts them in a sane location and namespace.
# Editing those values will almost surely break something.
kube_config_dir: /etc/kubernetes
kube_script_dir: "{{ bin_dir }}/kubernetes-scripts"
kube_manifest_dir: "{{ kube_config_dir }}/manifests"

# Kubectl command
# This is for consistency when using kubectl command in roles, and ensure
kubectl: "{{ bin_dir }}/kubectl --kubeconfig {{ kube_config_dir }}/admin.conf"

# This is where all the cert scripts and certs will be located
kube_cert_dir: "{{ kube_config_dir }}/ssl"

# compatibility directory for kubeadm
kube_cert_compat_dir: "/etc/kubernetes/pki"

# This is where all of the bearer tokens will be stored
kube_token_dir: "{{ kube_config_dir }}/tokens"

# This is the user that owns the cluster installation.
kube_owner: kube

# This is the group that the cert creation scripts chgrp the
# cert files to. Not really changeable...
kube_cert_group: kube-cert

# Set to true when the CAs are managed externally.
# When true, disables all tasks manipulating certificates. Ensure before the kubespray run that:
# - Certificates and CAs are present in kube_cert_dir
# - Kubeconfig files are present in kube_config_dir
kube_external_ca_mode: false

# Cluster Loglevel configuration
kube_log_level: 2

# Choose network plugin (cilium, calico, kube-ovn, weave or flannel. Use cni for generic cni plugin)
# Can also be set to 'cloud', which lets the cloud provider setup appropriate routing
kube_network_plugin: calico
kube_network_plugin_multus: false

# Determines if calico_rr group exists
peer_with_calico_rr: "{{ 'calico_rr' in groups and groups['calico_rr'] | length > 0 }}"

# Choose data store type for calico: "etcd" or "kdd" (kubernetes datastore)
calico_datastore: "kdd"

# Kubernetes internal network for services, unused block of space.
kube_service_addresses: 10.233.0.0/18

# internal network. When used, it will assign IP
# addresses from this range to individual pods.
# This network must be unused in your network infrastructure!
kube_pods_subnet: 10.233.64.0/18

# internal network node size allocation (optional). This is the size allocated
# to each node for pod IP address allocation. Note that the number of pods per node is
# also limited by the kubelet_max_pods variable which defaults to 110.
#
# Example:
# Up to 64 nodes and up to 254 or kubelet_max_pods (the lowest of the two) pods per node:
#  - kube_pods_subnet: 10.233.64.0/18
#  - kube_network_node_prefix: 24
#  - kubelet_max_pods: 110
#
# Example:
# Up to 128 nodes and up to 126 or kubelet_max_pods (the lowest of the two) pods per node:
#  - kube_pods_subnet: 10.233.64.0/18
#  - kube_network_node_prefix: 25
#  - kubelet_max_pods: 110
kube_network_node_prefix: 24

# Configure Dual Stack networking (i.e. both IPv4 and IPv6)
enable_dual_stack_networks: false

# Kubernetes internal network for IPv6 services, unused block of space.
# This is only used if enable_dual_stack_networks is set to true
# This provides 4096 IPv6 IPs
kube_service_addresses_ipv6: fd85:ee78:d8a6:8607::1000/116

# Internal network. When used, it will assign IPv6 addresses from this range to individual pods.
# This network must not already be in your network infrastructure!
# This is only used if enable_dual_stack_networks is set to true.
# This provides room for 256 nodes with 254 pods per node.
kube_pods_subnet_ipv6: fd85:ee78:d8a6:8607::1:0000/112

# IPv6 subnet size allocated to each for pods.
# This is only used if enable_dual_stack_networks is set to true
# This provides room for 254 pods per node.
kube_network_node_prefix_ipv6: 120

# The virtual cluster IP, real host IPs and ports the API Server will be
# listening on.
# NOTE: loadbalancer_apiserver_localhost somewhat alters the final API enpdoint
# access IP value (automatically evaluated below)
kube_apiserver_ip: "{{ kube_service_addresses | ansible.utils.ipaddr('net') | ansible.utils.ipaddr(1) | ansible.utils.ipaddr('address') }}"

# NOTE: If you specific address/interface and use loadbalancer_apiserver_localhost
# loadbalancer_apiserver_localhost (nginx/haproxy) will deploy on control plane nodes on 127.0.0.1:{{ loadbalancer_apiserver_port | default(kube_apiserver_port) }} too.
kube_apiserver_bind_address: 0.0.0.0

# https
kube_apiserver_port: 6443

# If non-empty, will use this string as identification instead of the actual hostname
kube_override_hostname: "{{ inventory_hostname }}"

# define kubelet config dir for dynamic kubelet
# kubelet_config_dir:
default_kubelet_config_dir: "{{ kube_config_dir }}/dynamic_kubelet_dir"

# Aggregator
kube_api_aggregator_routing: false

# Profiling
kube_profiling: false

# Graceful Node Shutdown
kubelet_shutdown_grace_period: 60s
# kubelet_shutdown_grace_period_critical_pods should be less than kubelet_shutdown_grace_period
# to give normal pods time to be gracefully evacuated
kubelet_shutdown_grace_period_critical_pods: 20s

# Cloud Provider
# This variable can only be set to "external" or empty string, otherwise the check will fail.
cloud_provider: ""
# External Cloud Controller Manager (Formerly known as cloud provider)
# cloud_provider must be "external", otherwise this setting is invalid.
# Supported external cloud controllers are: 'openstack', 'vsphere', 'oci', 'huaweicloud', 'hcloud' and 'manual'
# 'manual' does not install the cloud controller manager used by Kubespray.
# If you fill in a value other than the above, the check will fail.
external_cloud_provider: ""

# Whether to deploy the container engine
deploy_container_engine: "{{ 'k8s_cluster' in group_names or etcd_deployment_type == 'docker' }}"

# Container for runtime
container_manager: containerd

# Enable Node Resource Interface in containerd or CRI-O. Requires crio_version >= v1.26.0
# or containerd_version >= 1.7.0.
nri_enabled: false

# Enable Kata Containers as additional container runtime
# When enabled, it requires `container_manager` different than Docker
kata_containers_enabled: false

# Enable gVisor as an additional container runtime
# gVisor is only supported with container_manager Docker or containerd
gvisor_enabled: false

# Enable runc as additional container runtime
# When enabled, it requires container_manager=crio
runc_enabled: false

# Enable crun as additional container runtime
# When enabled, it requires container_manager=crio
crun_enabled: false

# Enable youki as additional container runtime
# When enabled, it requires container_manager=crio
youki_enabled: false

# Container on localhost (download images when download_localhost is true)
container_manager_on_localhost: "{{ container_manager }}"

# CRI socket path
cri_socket: >-
  {%- if container_manager == 'crio' -%}
  unix:///var/run/crio/crio.sock
  {%- elif container_manager == 'containerd' -%}
  unix:///var/run/containerd/containerd.sock
  {%- elif container_manager == 'docker' -%}
  unix:///var/run/cri-dockerd.sock
  {%- endif -%}

crio_insecure_registries: []

## Uncomment this if you want to force overlay/overlay2 as docker storage driver
## Please note that overlay2 is only supported on newer kernels
# docker_storage_options: -s overlay2

## Only set this if you have more than 3 nameservers:
## If true Kubespray will only use the first 3, otherwise it will fail
docker_dns_servers_strict: false

# Path used to store Docker data
docker_daemon_graph: "/var/lib/docker"

## Used to set docker daemon iptables options to true
docker_iptables_enabled: "false"

# Docker log options
# Rotate container stderr/stdout logs at 50m and keep last 5
docker_log_opts: "--log-opt max-size=50m --log-opt max-file=5"

## A list of insecure docker registries (IP address or domain name), for example
## to allow insecure-registry access to self-hosted registries. Empty by default.
# docker_insecure_registries:
#   - mirror.registry.io
#   - 172.19.16.11
docker_insecure_registries: []

## A list of additional registry mirrors, for example China registry mirror. Empty by default.
# docker_registry_mirrors:
#   - https://registry.docker-cn.com
#   - https://mirror.aliyuncs.com
docker_registry_mirrors: []

## If non-empty will override default system MounFlags value.
## This option takes a mount propagation flag: shared, slave
## or private, which control whether mounts in the file system
## namespace set up for docker will receive or propagate mounts
## and unmounts. Leave empty for system default
# docker_mount_flags:

## A string of extra options to pass to the docker daemon.
# docker_options: ""

## A list of plugins to install using 'docker plugin install --grant-all-permissions'
## Empty by default so no plugins will be installed.
docker_plugins: []

# Containerd options - thse are relevant when container_manager == 'containerd'
containerd_use_systemd_cgroup: true

# Containerd conf default dir
containerd_storage_dir: "/var/lib/containerd"
containerd_state_dir: "/run/containerd"
containerd_systemd_dir: "/etc/systemd/system/containerd.service.d"
containerd_cfg_dir: "/etc/containerd"

# Settings for containerized control plane (etcd/kubelet/secrets)
# deployment type for legacy etcd mode
etcd_deployment_type: host
cert_management: script

# Make a copy of kubeconfig on the host that runs Ansible in {{ inventory_dir }}/artifacts
kubeconfig_localhost: false
# Download kubectl onto the host that runs Ansible in {{ bin_dir }}
kubectl_localhost: false

# Define credentials_dir here so it can be overridden
credentials_dir: "{{ inventory_dir }}/credentials"

# K8s image pull policy (imagePullPolicy)
k8s_image_pull_policy: IfNotPresent

# Kubernetes dashboard
# RBAC required. see docs/getting-started.md for access details.
dashboard_enabled: false

# Addons which can be enabled
helm_enabled: false
krew_enabled: false
registry_enabled: false
metrics_server_enabled: false
enable_network_policy: true
local_path_provisioner_enabled: false
local_volume_provisioner_enabled: false
local_volume_provisioner_directory_mode: "0700"
cinder_csi_enabled: false
aws_ebs_csi_enabled: false
azure_csi_enabled: false
gcp_pd_csi_enabled: false
vsphere_csi_enabled: false
upcloud_csi_enabled: false
csi_snapshot_controller_enabled: false
persistent_volumes_enabled: false
cephfs_provisioner_enabled: false
rbd_provisioner_enabled: false
ingress_nginx_enabled: false
ingress_alb_enabled: false
cert_manager_enabled: false
expand_persistent_volumes: false
metallb_enabled: false
metallb_speaker_enabled: "{{ metallb_enabled }}"
argocd_enabled: false

## When OpenStack is used, Cinder version can be explicitly specified if autodetection fails (Fixed in 1.9: https://github.com/kubernetes/kubernetes/issues/50461)
# openstack_blockstorage_version: "v1/v2/auto (default)"
openstack_blockstorage_ignore_volume_az: "{{ volume_cross_zone_attachment | default('false') }}"
# set max volumes per node (cinder-csi), default not set
# node_volume_attach_limit: 25
# Cinder CSI topology, when false volumes can be cross-mounted between availability zones
# cinder_topology: false
# Set Cinder topology zones (can be multiple zones, default not set)
# cinder_topology_zones:
#   - nova
cinder_csi_ignore_volume_az: "{{ volume_cross_zone_attachment | default('false') }}"

## When OpenStack is used, if LBaaSv2 is available you can enable it with the following 2 variables.
openstack_lbaas_enabled: false
# openstack_lbaas_subnet_id: "Neutron subnet ID (not network ID) to create LBaaS VIP"
## To enable automatic floating ip provisioning, specify a subnet.
# openstack_lbaas_floating_network_id: "Neutron network ID (not subnet ID) to get floating IP from, disabled by default"
## Override default LBaaS behavior
# openstack_lbaas_use_octavia: False
# openstack_lbaas_method: "ROUND_ROBIN"
# openstack_lbaas_provider: "haproxy"
openstack_lbaas_create_monitor: "yes"
openstack_lbaas_monitor_delay: "1m"
openstack_lbaas_monitor_timeout: "30s"
openstack_lbaas_monitor_max_retries: "3"
openstack_cacert: "{{ lookup('env', 'OS_CACERT') }}"

# Default values for the external OpenStack Cloud Controller
external_openstack_lbaas_enabled: true
external_openstack_network_ipv6_disabled: false
external_openstack_network_internal_networks: []
external_openstack_network_public_networks: []

# Default values for the external Hcloud Cloud Controller
external_hcloud_cloud:
  hcloud_api_token: ""
  token_secret_name: hcloud

  service_account_name: cloud-controller-manager

  controller_image_tag: "latest"
  ## A dictionary of extra arguments to add to the openstack cloud controller manager daemonset
  ## Format:
  ##  external_hcloud_cloud.controller_extra_args:
  ##    arg1: "value1"
  ##    arg2: "value2"
  controller_extra_args: {}

## List of authorization modes that must be configured for
## the k8s cluster. Only 'AlwaysAllow', 'AlwaysDeny', 'Node' and
## 'RBAC' modes are tested. Order is important.
authorization_modes: ['Node', 'RBAC']

## Structured authorization config
## Structured AuthorizationConfiguration is a new feature in Kubernetes v1.29+ (GA in v1.32) that configures the API server's authorization modes with a structured configuration file.
## AuthorizationConfiguration files offer features not available with the `--authorization-mode` flag, although Kubespray supports both methods and authorization-mode remains the default for now.
## Note: Because the `--authorization-config` and `--authorization-mode` flags are mutually exclusive, the `authorization_modes` ansible variable is ignored when `kube_apiserver_use_authorization_config_file` is set to true. The two features cannot be used at the same time.
## Docs: https://kubernetes.io/docs/reference/access-authn-authz/authorization/#configuring-the-api-server-using-an-authorization-config-file
## Examples: https://kubernetes.io/blog/2024/04/26/multi-webhook-and-modular-authorization-made-much-easier/
## KEP: https://github.com/kubernetes/enhancements/tree/master/keps/sig-auth/3221-structured-authorization-configuration
kube_apiserver_use_authorization_config_file: false
kube_apiserver_authorization_config_authorizers:
- type: Node
  name: node
- type: RBAC
  name: rbac
## Example for use with kube_webhook_authorization: true
# - type: Webhook
#   name: webhook
#   webhook:
#     connectionInfo:
#       type: KubeConfigFile
#       kubeConfigFile: "{{ kube_config_dir }}/webhook-authorization-config.yaml"
#     subjectAccessReviewVersion: v1beta1
#     matchConditionSubjectAccessReviewVersion: v1
#     timeout: 3s
#     failurePolicy: NoOpinion
#     matchConditions:
#     # Documentation on CEL: https://kubernetes.io/docs/reference/using-api/cel/
#     # only send resource requests to the webhook
#     - expression: has(request.resourceAttributes)
#     # Don't intercept requests from kube-system service accounts
#     - expression: "!('system:serviceaccounts:kube-system' in request.groups)"
#     ## Below expressions avoid issues with kubeadm init and other system components that should be authorized by Node and RBAC
#     # Don't process node and bootstrap token requests with the webhook
#     - expression: "!('system:nodes' in request.groups)"
#     - expression: "!('system:bootstrappers' in request.groups)"
#     - expression: "!('system:bootstrappers:kubeadm:default-node-token' in request.groups)"
#     # Don't process kubeadm requests with the webhook
#     - expression: "!('kubeadm:cluster-admins' in request.groups)"
#     - expression: "!('system:masters' in request.groups)"

## Two workarounds are required to use AuthorizationConfiguration with kubeadm v1.29.x:
## 1. Enable the StructuredAuthorizationConfiguration feature gate:
# kube_apiserver_feature_gates:
# - StructuredAuthorizationConfiguration=true
## 2. Use the following kubeadm_patches to remove defaulted authorization-mode flags (Workaround for a kubeadm defaulting bug on v1.29.x. fixed in 1.30+ via: https://github.com/kubernetes/kubernetes/pull/123654)
# kubeadm_patches:
# - target: kube-apiserver
#   type: strategic
#   patch:
#     spec:
#       containers:
#       - name: kube-apiserver
#         $deleteFromPrimitiveList/command:
#           - --authorization-mode=Node,RBAC

rbac_enabled: "{{ ('RBAC' in authorization_modes and not kube_apiserver_use_authorization_config_file) or (kube_apiserver_use_authorization_config_file and kube_apiserver_authorization_config_authorizers | selectattr('type', 'equalto', 'RBAC') | list | length > 0) }}"

# When enabled, API bearer tokens (including service account tokens) can be used to authenticate to the kubelet's HTTPS endpoint
kubelet_authentication_token_webhook: true

# When enabled, access to the kubelet API requires authorization by delegation to the API server
kubelet_authorization_mode_webhook: true

# kubelet uses certificates for authenticating to the Kubernetes API
# Automatically generate a new key and request a new certificate from the Kubernetes API as the current certificate approaches expiration
kubelet_rotate_certificates: true
# kubelet can also request a new server certificate from the Kubernetes API
kubelet_rotate_server_certificates: false

# If set to true, kubelet errors if any of kernel tunables is different than kubelet defaults
kubelet_protect_kernel_defaults: true

# Set additional sysctl variables to modify Linux kernel variables, for example:
# additional_sysctl:
#  - { name: kernel.pid_max, value: 131072 }
#
additional_sysctl: []

## List of key=value pairs that describe feature gates for
## the k8s cluster.
kube_feature_gates: []
kube_apiserver_feature_gates: []
kube_controller_feature_gates: []
kube_scheduler_feature_gates: []
kube_proxy_feature_gates: []
kubelet_feature_gates: []
kubeadm_feature_gates: []

# Local volume provisioner storage classes
# Levarages Ansibles string to Python datatype casting. Otherwise the dict_key isn't substituted
# see https://github.com/ansible/ansible/issues/17324
local_volume_provisioner_storage_classes: |
  {
    "{{ local_volume_provisioner_storage_class | default('local-storage') }}": {
      "host_dir": "{{ local_volume_provisioner_base_dir | default('/mnt/disks') }}",
      "mount_dir": "{{ local_volume_provisioner_mount_dir | default('/mnt/disks') }}",
      "volume_mode": "Filesystem",
      "fs_type": "ext4"

    }
  }

# weave's network password for encryption
# if null then no network encryption
# you can use --extra-vars to pass the password in command line
weave_password: EnterPasswordHere

ssl_ca_dirs: |-
  [
  {% if ansible_os_family in ['Flatcar', 'Flatcar Container Linux by Kinvolk'] -%}
  '/usr/share/ca-certificates',
  {% elif ansible_os_family == 'RedHat' -%}
  '/etc/pki/tls',
  '/etc/pki/ca-trust',
  {% elif ansible_os_family == 'Debian' -%}
  '/usr/share/ca-certificates',
  {% endif -%}
  ]

# Vars for pointing to kubernetes api endpoints
kube_apiserver_count: "{{ groups['kube_control_plane'] | length }}"
kube_apiserver_address: "{{ ip | default(hostvars[inventory_hostname]['fallback_ip']) }}"
kube_apiserver_access_address: "{{ access_ip | default(kube_apiserver_address) }}"
first_kube_control_plane_address: "{{ hostvars[groups['kube_control_plane'][0]]['access_ip'] | default(hostvars[groups['kube_control_plane'][0]]['ip'] | default(hostvars[groups['kube_control_plane'][0]]['fallback_ip'])) }}"
loadbalancer_apiserver_localhost: "{{ loadbalancer_apiserver is not defined }}"
loadbalancer_apiserver_type: "nginx"
# applied if only external loadbalancer_apiserver is defined, otherwise ignored
apiserver_loadbalancer_domain_name: "lb-apiserver.kubernetes.local"
kube_apiserver_global_endpoint: |-
  {% if loadbalancer_apiserver is defined -%}
      https://{{ apiserver_loadbalancer_domain_name }}:{{ loadbalancer_apiserver.port | default(kube_apiserver_port) }}
  {%- elif loadbalancer_apiserver_localhost and (loadbalancer_apiserver_port is not defined or loadbalancer_apiserver_port == kube_apiserver_port) -%}
      https://localhost:{{ kube_apiserver_port }}
  {%- else -%}
      https://{{ first_kube_control_plane_address }}:{{ kube_apiserver_port }}
  {%- endif %}
kube_apiserver_endpoint: |-
  {% if loadbalancer_apiserver is defined -%}
      https://{{ apiserver_loadbalancer_domain_name }}:{{ loadbalancer_apiserver.port | default(kube_apiserver_port) }}
  {%- elif ('kube_control_plane' not in group_names) and loadbalancer_apiserver_localhost -%}
      https://localhost:{{ loadbalancer_apiserver_port | default(kube_apiserver_port) }}
  {%- elif 'kube_control_plane' in group_names -%}
      https://{{ kube_apiserver_bind_address | regex_replace('0\.0\.0\.0', '127.0.0.1') }}:{{ kube_apiserver_port }}
  {%- else -%}
      https://{{ first_kube_control_plane_address }}:{{ kube_apiserver_port }}
  {%- endif %}
kube_apiserver_client_cert: "{{ kube_cert_dir }}/ca.crt"
kube_apiserver_client_key: "{{ kube_cert_dir }}/ca.key"

# Set to true to deploy etcd-events cluster
etcd_events_cluster_enabled: false

# etcd group can be empty when kubeadm manages etcd
etcd_hosts: "{{ groups['etcd'] | default(groups['kube_control_plane']) }}"

# Vars for pointing to etcd endpoints
etcd_address: "{{ ip | default(fallback_ip) }}"
etcd_access_address: "{{ access_ip | default(etcd_address) }}"
etcd_events_access_address: "{{ access_ip | default(etcd_address) }}"
etcd_peer_url: "https://{{ etcd_access_address }}:2380"
etcd_client_url: "https://{{ etcd_access_address }}:2379"
etcd_events_peer_url: "https://{{ etcd_events_access_address }}:2382"
etcd_events_client_url: "https://{{ etcd_events_access_address }}:2383"
etcd_access_addresses: |-
  {% for item in etcd_hosts -%}
    https://{{ hostvars[item]['etcd_access_address'] | default(hostvars[item]['ip'] | default(hostvars[item]['fallback_ip'])) }}:2379{% if not loop.last %},{% endif %}
  {%- endfor %}
etcd_events_access_addresses_list: |-
  [
  {% for item in etcd_hosts -%}
    'https://{{ hostvars[item]['etcd_events_access_address'] | default(hostvars[item]['ip'] | default(hostvars[item]['fallback_ip'])) }}:2383'{% if not loop.last %},{% endif %}
  {%- endfor %}
  ]
etcd_metrics_addresses: |-
  {% for item in etcd_hosts -%}
    https://{{ hostvars[item]['etcd_access_address'] | default(hostvars[item]['ip'] | default(hostvars[item]['fallback_ip'])) }}:{{ etcd_metrics_port | default(2381) }}{% if not loop.last %},{% endif %}
  {%- endfor %}
etcd_events_access_addresses: "{{ etcd_events_access_addresses_list | join(',') }}"
etcd_events_access_addresses_semicolon: "{{ etcd_events_access_addresses_list | join(';') }}"
# user should set etcd_member_name in inventory/mycluster/hosts.ini
etcd_member_name: |-
  {% for host in groups['etcd'] %}
  {%   if inventory_hostname == host %}{{ hostvars[host].etcd_member_name | default("etcd" + loop.index | string) }}{% endif %}
  {% endfor %}
etcd_peer_addresses: |-
  {% for item in groups['etcd'] -%}
    {{ hostvars[item].etcd_member_name | default("etcd" + loop.index | string) }}=https://{{ hostvars[item].etcd_access_address | default(hostvars[item].ip | default(hostvars[item]['fallback_ip'])) }}:2380{% if not loop.last %},{% endif %}
  {%- endfor %}
etcd_events_peer_addresses: |-
  {% for item in groups['etcd'] -%}
    {{ hostvars[item].etcd_member_name | default("etcd" + loop.index | string) }}-events=https://{{ hostvars[item].etcd_events_access_address | default(hostvars[item].ip | default(hostvars[item]['fallback_ip'])) }}:2382{% if not loop.last %},{% endif %}
  {%- endfor %}

etcd_heartbeat_interval: "250"
etcd_election_timeout: "5000"
etcd_snapshot_count: "10000"

certificates_key_size: 2048
certificates_duration: 36500

etcd_config_dir: /etc/ssl/etcd
etcd_events_data_dir: "/var/lib/etcd-events"
etcd_cert_dir: "{{ etcd_config_dir }}/ssl"

typha_enabled: false

calico_apiserver_enabled: false

_host_architecture_groups:
  x86_64: amd64
  aarch64: arm64
  armv7l: arm
host_architecture: >-
  {%- if ansible_architecture in _host_architecture_groups -%}
  {{ _host_architecture_groups[ansible_architecture] }}
  {%- else -%}
  {{ ansible_architecture }}
  {%- endif -%}

_host_os_groups:
  Linux: linux
  Darwin: darwin
  Win32NT: windows
host_os: >-
  {%- if ansible_system in _host_os_groups -%}
  {{ _host_os_groups[ansible_system] }}
  {%- else -%}
  {{ ansible_system }}
  {%- endif -%}

# Sets the eventRecordQPS parameter in kubelet-config.yaml.
# Setting it to 0 allows unlimited requests per second.
kubelet_event_record_qps: 50

proxy_env_defaults:
  http_proxy: "{{ http_proxy | default('') }}"
  HTTP_PROXY: "{{ http_proxy | default('') }}"
  https_proxy: "{{ https_proxy | default('') }}"
  HTTPS_PROXY: "{{ https_proxy | default('') }}"
  no_proxy: "{{ no_proxy | default('') }}"
  NO_PROXY: "{{ no_proxy | default('') }}"

# If we use SSL_CERT_FILE: {{ omit }} it cause in value __omit_place_holder__ and break environments
# Combine dict is avoiding the problem with omit placeholder. Maybe it can be better solution?
proxy_env: "{{ proxy_env_defaults | combine({'SSL_CERT_FILE': https_proxy_cert_file}) if https_proxy_cert_file is defined else proxy_env_defaults }}"

proxy_disable_env:
  ALL_PROXY: ''
  FTP_PROXY: ''
  HTTPS_PROXY: ''
  HTTP_PROXY: ''
  NO_PROXY: ''
  all_proxy: ''
  ftp_proxy: ''
  http_proxy: ''
  https_proxy: ''
  no_proxy: ''

# krew root dir
krew_root_dir: "/usr/local/krew"

# sysctl_file_path to add sysctl conf to
sysctl_file_path: "/etc/sysctl.d/99-sysctl.conf"

system_upgrade: false
system_upgrade_reboot: on-upgrade  # never, always

# Enables or disables the scheduler plugins.
scheduler_plugins_enabled: false

## roles/network_plugin/calico/rr/defaults/main.yml <==
---
# Global as_num (/calico/bgp/v1/global/as_num)
# should be the same as in calico role
global_as_num: "64512"
calico_baremetal_nodename: "{{ kube_override_hostname | default(inventory_hostname) }}"

## roles/network_plugin/calico_defaults/defaults/main.yml <==
---
# the default value of name
calico_cni_name: k8s-pod-network

# Enables Internet connectivity from containers
nat_outgoing: true
nat_outgoing_ipv6: false

# add default ippool name
calico_pool_name: "default-pool"
calico_ipv4pool_ipip: "Off"

# Change encapsulation mode, by default we enable vxlan which is the most mature and well tested mode
calico_ipip_mode: Never  # valid values are 'Always', 'Never' and 'CrossSubnet'
calico_vxlan_mode: Always  # valid values are 'Always', 'Never' and 'CrossSubnet'

calico_cni_pool: true
calico_cni_pool_ipv6: true

# add default ippool blockSize
calico_pool_blocksize: 26

# Calico doesn't support ipip tunneling for the IPv6.
calico_ipip_mode_ipv6: Never
calico_vxlan_mode_ipv6: Never

# add default ipv6 ippool blockSize
calico_pool_blocksize_ipv6: 122

# Calico network backend can be 'bird', 'vxlan' and 'none'
calico_network_backend: vxlan

calico_cert_dir: /etc/calico/certs

# Global as_num (/calico/bgp/v1/global/as_num)
global_as_num: "64512"

# You can set MTU value here. If left undefined or empty, it will
# not be specified in calico CNI config, so Calico will use built-in
# defaults. The value should be a number, not a string.
# calico_mtu: 1500

# Advertise Service External IPs
calico_advertise_service_external_ips: []

# Advertise Service LoadBalancer IPs
calico_advertise_service_loadbalancer_ips: []

# Calico eBPF support
calico_bpf_enabled: false
calico_bpf_log_level: ""
# Valid option for service mode: Tunnel (default), DSR=Direct Server Return
calico_bpf_service_mode: Tunnel

# Calico floatingIPs support
# Valid option for floatingIPs: Disabled (default), Enabled
calico_felix_floating_ips: Disabled

# Limits for apps
calico_node_memory_limit: 500M
calico_node_cpu_limit: 300m
calico_node_memory_requests: 64M
calico_node_cpu_requests: 150m
calico_felix_chaininsertmode: Insert

# Calico daemonset nodeselector
calico_ds_nodeselector: "kubernetes.io/os: linux"

# Virtual network ID to use for VXLAN traffic. A value of 0 means “use the kernel default”.
calico_vxlan_vni: 4096

# Port to use for VXLAN traffic. A value of 0 means “use the kernel default”.
calico_vxlan_port: 4789

# Enable Prometheus Metrics endpoint for felix
calico_felix_prometheusmetricsenabled: false
calico_felix_prometheusmetricsport: 9091
calico_felix_prometheusgometricsenabled: true
calico_felix_prometheusprocessmetricsenabled: true

# Set the agent log level. Can be debug, warning, info or fatal
calico_loglevel: info
calico_node_startup_loglevel: error

# Set log path for calico CNI plugin. Set to false to disable logging to disk.
calico_cni_log_file_path: /var/log/calico/cni/cni.log

# Enable or disable usage report to 'usage.projectcalico.org'
calico_usage_reporting: false

# Should calico ignore kernel's RPF check setting,
# see https://github.com/projectcalico/felix/blob/ab8799eaea66627e5db7717e62fca61fd9c08646/python/calico/felix/config.py#L198
calico_node_ignorelooserpf: false

# Define address on which Felix will respond to health requests
calico_healthhost: "localhost"

# Configure time in seconds that calico will wait for the iptables lock
calico_iptables_lock_timeout_secs: 10

# Choose Calico iptables backend: "Legacy", "Auto" or "NFT" (FELIX_IPTABLESBACKEND)
calico_iptables_backend: "Auto"

# Calico Wireguard support
calico_wireguard_enabled: false
calico_wireguard_packages: []
calico_wireguard_repo: https://download.copr.fedorainfracloud.org/results/jdoss/wireguard/epel-{{ ansible_distribution_major_version }}-$basearch/

# If you want to use non default IP_AUTODETECTION_METHOD, IP6_AUTODETECTION_METHOD for calico node set this option to one of:
# * can-reach=DESTINATION
# * interface=INTERFACE-REGEX
# see https://projectcalico.docs.tigera.io/reference/node/configuration#ip-autodetection-methods
# calico_ip_auto_method: "interface=eth.*"
# calico_ip6_auto_method: "interface=eth.*"

# Set FELIX_MTUIFACEPATTERN, Pattern used to discover the host’s interface for MTU auto-detection.
# see https://projectcalico.docs.tigera.io/reference/felix/configuration
# calico_felix_mtu_iface_pattern: "^((en|wl|ww|sl|ib)[opsx].*|(eth|wlan|wwan).*)"

calico_baremetal_nodename: "{{ kube_override_hostname | default(inventory_hostname) }}"

kube_etcd_cacert_file: ca.pem
kube_etcd_cert_file: node-{{ inventory_hostname }}.pem
kube_etcd_key_file: node-{{ inventory_hostname }}-key.pem

# Choose data store type for calico: "etcd" or "kdd" (kubernetes datastore)
# The default value for calico_datastore is set in role kubespray-default

# Use typha (only with kdd)
typha_enabled: false
typha_prometheusmetricsenabled: false
typha_prometheusmetricsport: 9093

# Scaling typha: 1 replica per 100 nodes is adequate
# Number of typha replicas
typha_replicas: 1

# Set max typha connections
typha_max_connections_lower_limit: 300

# Generate certifcates for typha<->calico-node communication
typha_secure: false

calico_feature_control: {}

# Calico default BGP port
calico_bgp_listen_port: 179

# Calico FelixConfiguration options
calico_felix_reporting_interval: 0s
calico_felix_log_severity_screen: Info

# Calico container settings
calico_allow_ip_forwarding: false

# Calico IPAM strictAffinity
calico_ipam_strictaffinity: false

# Calico IPAM autoAllocateBlocks
calico_ipam_autoallocateblocks: true

# Calico IPAM maxBlocksPerHost, default 0
calico_ipam_maxblocksperhost: 0

# Calico host local IPAM (use node .spec.podCIDR)

calico_ipam_host_local: false

# Calico apiserver (only with kdd)
calico_apiserver_enabled: false

# Calico feature detect override
calico_feature_detect_override: ""

# Calico kubeconfig wait timeout in seconds
calico_kubeconfig_wait_timeout: 300

## roles/network_plugin/cilium/defaults/main.yml <==
---
cilium_min_version_required: "1.10"
# Log-level
cilium_debug: false

cilium_mtu: ""
cilium_enable_ipv4: true
cilium_enable_ipv6: false

# Enable l2 announcement from cilium to replace Metallb Ref: https://docs.cilium.io/en/v1.14/network/l2-announcements/
cilium_l2announcements: false

# Cilium agent health port
cilium_agent_health_port: "{%- if cilium_version | regex_replace('v') is version('1.11.6', '>=') -%}9879{%- else -%}9876{%- endif -%}"

# Identity allocation mode selects how identities are shared between cilium
# nodes by setting how they are stored. The options are "crd" or "kvstore".
# - "crd" stores identities in kubernetes as CRDs (custom resource definition).
#   These can be queried with:
#     `kubectl get ciliumid`
# - "kvstore" stores identities in an etcd kvstore.
# - In order to support External Workloads, "crd" is required
#   - Ref: https://docs.cilium.io/en/stable/gettingstarted/external-workloads/#setting-up-support-for-external-workloads-beta
# - KVStore operations are only required when cilium-operator is running with any of the below options:
#   - --synchronize-k8s-services
#   - --synchronize-k8s-nodes
#   - --identity-allocation-mode=kvstore
#   - Ref: https://docs.cilium.io/en/stable/internals/cilium_operator/#kvstore-operations
cilium_identity_allocation_mode: kvstore

# Etcd SSL dirs
cilium_cert_dir: /etc/cilium/certs
kube_etcd_cacert_file: ca.pem
kube_etcd_cert_file: node-{{ inventory_hostname }}.pem
kube_etcd_key_file: node-{{ inventory_hostname }}-key.pem

# Limits for apps
cilium_memory_limit: 500M
cilium_cpu_limit: 500m
cilium_memory_requests: 64M
cilium_cpu_requests: 100m

# Overlay Network Mode
cilium_tunnel_mode: vxlan

# LoadBalancer Mode (snat/dsr/hybrid) Ref: https://docs.cilium.io/en/stable/network/kubernetes/kubeproxy-free/#dsr-mode
cilium_loadbalancer_mode: snat

# -- Configure Loadbalancer IP Pools
cilium_loadbalancer_ip_pools: []

# Optional features
cilium_enable_prometheus: false
# Enable if you want to make use of hostPort mappings
cilium_enable_portmap: false
# Monitor aggregation level (none/low/medium/maximum)
cilium_monitor_aggregation: medium
# Kube Proxy Replacement mode (strict/partial)
cilium_kube_proxy_replacement: partial

# If upgrading from Cilium < 1.5, you may want to override some of these options
# to prevent service disruptions. See also:
# http://docs.cilium.io/en/stable/install/upgrade/#changes-that-may-require-action
cilium_preallocate_bpf_maps: false

# `cilium_tofqdns_enable_poller` is deprecated in 1.8, removed in 1.9
cilium_tofqdns_enable_poller: false

# `cilium_enable_legacy_services` is deprecated in 1.6, removed in 1.9
cilium_enable_legacy_services: false

# Deploy cilium even if kube_network_plugin is not cilium.
# This enables to deploy cilium alongside another CNI to replace kube-proxy.
cilium_deploy_additionally: false

# Auto direct nodes routes can be used to advertise pods routes in your cluster
# without any tunelling (with `cilium_tunnel_mode` sets to `disabled`).
# This works only if you have a L2 connectivity between all your nodes.
# You wil also have to specify the variable `cilium_native_routing_cidr` to
# make this work. Please refer to the cilium documentation for more
# information about this kind of setups.
cilium_auto_direct_node_routes: false

# Allows to explicitly specify the IPv4 CIDR for native routing.
# When specified, Cilium assumes networking for this CIDR is preconfigured and
# hands traffic destined for that range to the Linux network stack without
# applying any SNAT.
# Generally speaking, specifying a native routing CIDR implies that Cilium can
# depend on the underlying networking stack to route packets to their
# destination. To offer a concrete example, if Cilium is configured to use
# direct routing and the Kubernetes CIDR is included in the native routing CIDR,
# the user must configure the routes to reach pods, either manually or by
# setting the auto-direct-node-routes flag.
cilium_native_routing_cidr: ""

# Allows to explicitly specify the IPv6 CIDR for native routing.
cilium_native_routing_cidr_ipv6: ""

# Enable transparent network encryption.
cilium_encryption_enabled: false

# Encryption method. Can be either ipsec or wireguard.
# Only effective when `cilium_encryption_enabled` is set to true.
cilium_encryption_type: "ipsec"

# Enable encryption for pure node to node traffic.
# This option is only effective when `cilium_encryption_type` is set to `ipsec`.
cilium_ipsec_node_encryption: false

# If your kernel or distribution does not support WireGuard, Cilium agent can be configured to fall back on the user-space implementation.
# When this flag is enabled and Cilium detects that the kernel has no native support for WireGuard,
# it will fallback on the wireguard-go user-space implementation of WireGuard.
# This option is only effective when `cilium_encryption_type` is set to `wireguard`.
cilium_wireguard_userspace_fallback: false

# Enable Bandwidth Manager
# Cilium’s bandwidth manager supports the kubernetes.io/egress-bandwidth Pod annotation.
# Bandwidth enforcement currently does not work in combination with L7 Cilium Network Policies.
# In case they select the Pod at egress, then the bandwidth enforcement will be disabled for those Pods.
# Bandwidth Manager requires a v5.1.x or more recent Linux kernel.
cilium_enable_bandwidth_manager: false

# IP Masquerade Agent
# https://docs.cilium.io/en/stable/concepts/networking/masquerading/
# By default, all packets from a pod destined to an IP address outside of the cilium_native_routing_cidr range are masqueraded
cilium_ip_masq_agent_enable: false

### A packet sent from a pod to a destination which belongs to any CIDR from the nonMasqueradeCIDRs is not going to be masqueraded
cilium_non_masquerade_cidrs:
  - 10.0.0.0/8
  - 172.16.0.0/12
  - 192.168.0.0/16
  - 100.64.0.0/10
  - 192.0.0.0/24
  - 192.0.2.0/24
  - 192.88.99.0/24
  - 198.18.0.0/15
  - 198.51.100.0/24
  - 203.0.113.0/24
  - 240.0.0.0/4
### Indicates whether to masquerade traffic to the link local prefix.
### If the masqLinkLocal is not set or set to false, then 169.254.0.0/16 is appended to the non-masquerade CIDRs list.
cilium_masq_link_local: false
### A time interval at which the agent attempts to reload config from disk
cilium_ip_masq_resync_interval: 60s

# Hubble
### Enable Hubble without install
cilium_enable_hubble: false
### Enable Hubble-ui
cilium_enable_hubble_ui: "{{ cilium_enable_hubble }}"
### Enable Hubble Metrics
cilium_enable_hubble_metrics: false
### if cilium_enable_hubble_metrics: true
cilium_hubble_metrics: {}
# - dns
# - drop
# - tcp
# - flow
# - icmp
# - http
### Enable Hubble install
cilium_hubble_install: false
### Enable auto generate certs if cilium_hubble_install: true
cilium_hubble_tls_generate: false

### Capacity of Hubble events buffer. The provided value must be one less than an integer power of two and no larger than 65535
### (ie: 1, 3, ..., 2047, 4095, ..., 65535) (default 4095)
# cilium_hubble_event_buffer_capacity: 4095
### Buffer size of the channel to receive monitor events.
# cilium_hubble_event_queue_size: 50

# The default IP address management mode is "Cluster Scope".
# https://docs.cilium.io/en/stable/concepts/networking/ipam/
cilium_ipam_mode: cluster-pool

# Cluster Pod CIDRs use the kube_pods_subnet value by default.
# If your node network is in the same range you will lose connectivity to other nodes.
# Defaults to kube_pods_subnet if not set.
# cilium_pool_cidr: 10.233.64.0/18

# When cilium_enable_ipv6 is used, you need to set the IPV6 value.  Defaults to kube_pods_subnet_ipv6 if not set.
# cilium_pool_cidr_ipv6: fd85:ee78:d8a6:8607::1:0000/112

# When cilium IPAM uses the "Cluster Scope" mode, it will pre-allocate a segment of IP to each node,
# schedule the Pod to this node, and then allocate IP from here. cilium_pool_mask_size Specifies
# the size allocated from cluster Pod CIDR to node.ipam.podCIDRs
# Defaults to kube_network_node_prefix if not set.
# cilium_pool_mask_size: "24"

# cilium_pool_mask_size Specifies the size allocated to node.ipam.podCIDRs from cluster Pod IPV6 CIDR
# Defaults to kube_network_node_prefix_ipv6 if not set.
# cilium_pool_mask_size_ipv6: "120"


# Extra arguments for the Cilium agent
cilium_agent_custom_args: []

# For adding and mounting extra volumes to the cilium agent
cilium_agent_extra_volumes: []
cilium_agent_extra_volume_mounts: []

cilium_agent_extra_env_vars: []

cilium_operator_replicas: 2

# The address at which the cillium operator bind health check api
cilium_operator_api_serve_addr: "127.0.0.1:9234"

## A dictionary of extra config variables to add to cilium-config, formatted like:
##  cilium_config_extra_vars:
##    var1: "value1"
##    var2: "value2"
cilium_config_extra_vars: {}

# For adding and mounting extra volumes to the cilium operator
cilium_operator_extra_volumes: []
cilium_operator_extra_volume_mounts: []

# Extra arguments for the Cilium Operator
cilium_operator_custom_args: []

# Name of the cluster. Only relevant when building a mesh of clusters.
cilium_cluster_name: default

# Make Cilium take ownership over the `/etc/cni/net.d` directory on the node, renaming all non-Cilium CNI configurations to `*.cilium_bak`.
# This ensures no Pods can be scheduled using other CNI plugins during Cilium agent downtime.
# Available for Cilium v1.10 and up.
cilium_cni_exclusive: true

# Configure the log file for CNI logging with retention policy of 7 days.
# Disable CNI file logging by setting this field to empty explicitly.
# Available for Cilium v1.12 and up.
cilium_cni_log_file: "/var/run/cilium/cilium-cni.log"

# -- Configure cgroup related configuration
# -- Enable auto mount of cgroup2 filesystem.
# When `cilium_cgroup_auto_mount` is enabled, cgroup2 filesystem is mounted at
# `cilium_cgroup_host_root` path on the underlying host and inside the cilium agent pod.
# If users disable `cilium_cgroup_auto_mount`, it's expected that users have mounted
# cgroup2 filesystem at the specified `cilium_cgroup_auto_mount` volume, and then the
# volume will be mounted inside the cilium agent pod at the same path.
# Available for Cilium v1.11 and up
cilium_cgroup_auto_mount: true
# -- Configure cgroup root where cgroup2 filesystem is mounted on the host
cilium_cgroup_host_root: "/run/cilium/cgroupv2"

# Specifies the ratio (0.0-1.0) of total system memory to use for dynamic
# sizing of the TCP CT, non-TCP CT, NAT and policy BPF maps.
cilium_bpf_map_dynamic_size_ratio: "0.0025"

# -- Enables masquerading of IPv4 traffic leaving the node from endpoints.
# Available for Cilium v1.10 and up
cilium_enable_ipv4_masquerade: true
# -- Enables masquerading of IPv6 traffic leaving the node from endpoints.
# Available for Cilium v1.10 and up
cilium_enable_ipv6_masquerade: true

# -- Enable native IP masquerade support in eBPF
cilium_enable_bpf_masquerade: false

# -- Configure whether direct routing mode should route traffic via
# host stack (true) or directly and more efficiently out of BPF (false) if
# the kernel supports it. The latter has the implication that it will also
# bypass netfilter in the host namespace.
cilium_enable_host_legacy_routing: true

# -- Enable use of the remote node identity.
# ref: https://docs.cilium.io/en/v1.7/install/upgrade/#configmap-remote-node-identity
cilium_enable_remote_node_identity: true

# -- Enable the use of well-known identities.
cilium_enable_well_known_identities: false

# The monitor aggregation flags determine which TCP flags which, upon the
# first observation, cause monitor notifications to be generated.
#
# Only effective when monitor aggregation is set to "medium" or higher.
cilium_monitor_aggregation_flags: "all"

cilium_enable_bpf_clock_probe: true

# -- Enable BGP Control Plane
cilium_enable_bgp_control_plane: false


# -- Configure BGP Instances (New bgpv2 API v1.16+)
cilium_bgp_cluster_configs: []

# -- Configure BGP Peers (New bgpv2 API v1.16+)
cilium_bgp_peer_configs: []

# -- Configure BGP Advertisements (New bgpv2 API v1.16+)
cilium_bgp_advertisements: []

# -- Configure BGP Node Config Overrides (New bgpv2 API v1.16+)
cilium_bgp_node_config_overrides: []

# -- Configure BGP Peers (Legacy < v1.16)
cilium_bgp_peering_policies: []

# -- Whether to enable CNP status updates.
cilium_disable_cnp_status_updates: true

# Configure how long to wait for the Cilium DaemonSet to be ready again
cilium_rolling_restart_wait_retries_count: 30
cilium_rolling_restart_wait_retries_delay_seconds: 10

# Cilium changed the default metrics exporter ports in 1.12
cilium_agent_scrape_port: "{{ cilium_version | regex_replace('v') is version('1.12', '>=') | ternary('9962', '9090') }}"
cilium_operator_scrape_port: "{{ cilium_version | regex_replace('v') is version('1.12', '>=') | ternary('9963', '6942') }}"
cilium_hubble_scrape_port: "{{ cilium_version | regex_replace('v') is version('1.12', '>=') | ternary('9965', '9091') }}"

# Cilium certgen args for generate certificate for hubble mTLS
cilium_certgen_args:
  cilium-namespace: kube-system
  ca-reuse-secret: true
  ca-secret-name: hubble-ca-secret
  ca-generate: true
  ca-validity-duration: 94608000s
  hubble-server-cert-generate: true
  hubble-server-cert-common-name: '*.{{ cilium_cluster_name }}.hubble-grpc.cilium.io'
  hubble-server-cert-validity-duration: 94608000s
  hubble-server-cert-secret-name: hubble-server-certs
  hubble-relay-client-cert-generate: true
  hubble-relay-client-cert-common-name: '*.{{ cilium_cluster_name }}.hubble-grpc.cilium.io'
  hubble-relay-client-cert-validity-duration: 94608000s
  hubble-relay-client-cert-secret-name: hubble-relay-client-certs
  hubble-relay-server-cert-generate: false

# A list of extra rules variables to add to clusterrole for cilium operator, formatted like:
#   cilium_clusterrole_rules_operator_extra_vars:
#     - apiGroups:
#       - '""'
#       resources:
#       - pods
#       verbs:
#       - delete
#     - apiGroups:
#       - '""'
#       resources:
#       - nodes
#       verbs:
#       - list
#       - watch
#       resourceNames:
#       - toto
cilium_clusterrole_rules_operator_extra_vars: []
cilium_enable_host_firewall: false
cilium_policy_audit_mode: false

## roles/network_plugin/cni/defaults/main.yml <==
---
cni_bin_owner: "{{ kube_owner }}"

## roles/network_plugin/custom_cni/defaults/main.yml <==
---

custom_cni_manifests: []

custom_cni_chart_namespace: kube-system
custom_cni_chart_release_name: ""
custom_cni_chart_repository_name: ""
custom_cni_chart_repository_url: ""
custom_cni_chart_ref: ""
custom_cni_chart_version: ""
custom_cni_chart_values: {}

## roles/network_plugin/flannel/defaults/main.yml <==
---
# Flannel public IP
# The address that flannel should advertise as how to access the system
# Disabled until https://github.com/coreos/flannel/issues/712 is fixed
# flannel_public_ip: "{{ access_ip | default(ip | default(fallback_ip)) }}"

## interface that should be used for flannel operations
## This is actually an inventory cluster-level item
# flannel_interface:

## Select interface that should be used for flannel operations by regexp on Name or IP
## This is actually an inventory cluster-level item
## example: select interface with ip from net 10.0.0.0/23
## single quote and escape backslashes
# flannel_interface_regexp: '10\\.0\\.[0-2]\\.\\d{1,3}'

# You can choose what type of flannel backend to use
# please refer to flannel's docs : https://github.com/coreos/flannel/blob/master/README.md
flannel_backend_type: "vxlan"
flannel_vxlan_vni: 1
flannel_vxlan_port: 8472
flannel_vxlan_direct_routing: false

# Limits for apps
flannel_memory_limit: 500M
flannel_cpu_limit: 300m
flannel_memory_requests: 64M
flannel_cpu_requests: 150m

## roles/network_plugin/kube-ovn/defaults/main.yml <==
---
kube_ovn_db_cpu_request: 500m
kube_ovn_db_memory_request: 200Mi
kube_ovn_db_cpu_limit: 3000m
kube_ovn_db_memory_limit: 3000Mi
kube_ovn_node_cpu_request: 200m
kube_ovn_node_memory_request: 200Mi
kube_ovn_node_cpu_limit: 1000m
kube_ovn_node_memory_limit: 800Mi
kube_ovn_cni_server_cpu_request: 200m
kube_ovn_cni_server_memory_request: 200Mi
kube_ovn_cni_server_cpu_limit: 1000m
kube_ovn_cni_server_memory_limit: 1Gi
kube_ovn_controller_cpu_request: 200m
kube_ovn_controller_memory_request: 200Mi
kube_ovn_controller_cpu_limit: 1000m
kube_ovn_controller_memory_limit: 1Gi
kube_ovn_pinger_cpu_request: 100m
kube_ovn_pinger_memory_request: 200Mi
kube_ovn_pinger_cpu_limit: 200m
kube_ovn_pinger_memory_limit: 400Mi
kube_ovn_monitor_memory_request: 200Mi
kube_ovn_monitor_cpu_request: 200m
kube_ovn_monitor_memory_limit: 200Mi
kube_ovn_monitor_cpu_limit: 200m
kube_ovn_dpdk_node_cpu_request: 1000m
kube_ovn_dpdk_node_memory_request: 2Gi
kube_ovn_dpdk_node_cpu_limit: 1000m
kube_ovn_dpdk_node_memory_limit: 2Gi

kube_ovn_central_hosts: "{{ groups['kube_control_plane'] }}"
kube_ovn_central_replics: "{{ kube_ovn_central_hosts | length }}"
kube_ovn_controller_replics: "{{ kube_ovn_central_hosts | length }}"
kube_ovn_central_ips: |-
  {% for item in kube_ovn_central_hosts -%}
    {{ hostvars[item]['ip'] | default(hostvars[item]['fallback_ip']) }}{% if not loop.last %},{% endif %}
  {%- endfor %}

kube_ovn_ic_enable: false
kube_ovn_ic_autoroute: true
kube_ovn_ic_dbhost: "127.0.0.1"
kube_ovn_ic_zone: "kubernetes"

# geneve or vlan
kube_ovn_network_type: geneve

# geneve, vxlan or stt. ATTENTION: some networkpolicy cannot take effect when using vxlan and stt need custom compile ovs kernel module
kube_ovn_tunnel_type: geneve

## The nic to support container network can be a nic name or a group of regex separated by comma e.g: 'enp6s0f0,eth.*', if empty will use the nic that the default route use.
# kube_ovn_iface: eth1
## The MTU used by pod iface in overlay networks (default iface MTU - 100)
# kube_ovn_mtu: 1333

## Enable hw-offload, disable traffic mirror and set the iface to the physical port. Make sure that there is an IP address bind to the physical port.
kube_ovn_hw_offload: false
# traffic mirror
kube_ovn_traffic_mirror: false

# kube_ovn_pool_cidr_ipv6: fd85:ee78:d8a6:8607::1:0000/112
# kube_ovn_default_interface_name: eth0

kube_ovn_external_address: 8.8.8.8
kube_ovn_external_address_ipv6: 2400:3200::1
kube_ovn_external_dns: alauda.cn

# kube_ovn_default_gateway: 10.233.64.1,fd85:ee78:d8a6:8607::1:0
kube_ovn_default_gateway_check: true
kube_ovn_default_logical_gateway: false

# u2o_interconnection
kube_ovn_u2o_interconnection: false

# kube_ovn_default_exclude_ips: 10.16.0.1
kube_ovn_node_switch_cidr: 100.64.0.0/16
kube_ovn_node_switch_cidr_ipv6: fd00:100:64::/64

## vlan config, set default interface name and vlan id
# kube_ovn_default_interface_name: eth0
kube_ovn_default_vlan_id: 100
kube_ovn_vlan_name: product

## pod nic type, support: veth-pair or internal-port
kube_ovn_pod_nic_type: veth_pair

## Enable load balancer
kube_ovn_enable_lb: true

## Enable network policy support
kube_ovn_enable_np: true

## Enable external vpc support
kube_ovn_enable_external_vpc: true

## Enable checksum
kube_ovn_encap_checksum: true

## enable ssl
kube_ovn_enable_ssl: false

## dpdk
kube_ovn_dpdk_enabled: false
kube_ovn_dpdk_tunnel_iface: br-phy

## bind local ip
kube_ovn_bind_local_ip_enabled: true

## eip snat
kube_ovn_eip_snat_enabled: true

# ls dnat mod dl dst
kube_ovn_ls_dnat_mod_dl_dst: true

## keep vm ip
kube_ovn_keep_vm_ip: true

## cni config priority, default: 01
kube_ovn_cni_config_priority: '01'

## roles/network_plugin/kube-router/defaults/main.yml <==
---
# Enables Pod Networking -- Advertises and learns the routes to Pods via iBGP
kube_router_run_router: true

# Enables Network Policy -- sets up iptables to provide ingress firewall for pods
kube_router_run_firewall: true

# Enables Service Proxy -- sets up IPVS for Kubernetes Services
# see docs/kube-router.md "Caveats" section
kube_router_run_service_proxy: false

# Add Cluster IP of the service to the RIB so that it gets advertises to the BGP peers.
kube_router_advertise_cluster_ip: false

# Add External IP of service to the RIB so that it gets advertised to the BGP peers.
kube_router_advertise_external_ip: false

# Add LoadBalancer IP of service status as set by the LB provider to the RIB so that it gets advertised to the BGP peers.
kube_router_advertise_loadbalancer_ip: false

# Enables BGP graceful restarts
kube_router_bgp_graceful_restart: true

# Adjust manifest of kube-router daemonset template with DSR needed changes
kube_router_enable_dsr: false

# Array of arbitrary extra arguments to kube-router, see
# https://github.com/cloudnativelabs/kube-router/blob/master/docs/user-guide.md
kube_router_extra_args: []

# ASN number of the cluster, used when communicating with external BGP routers
kube_router_cluster_asn: ~

# ASN numbers of the BGP peer to which cluster nodes will advertise cluster ip and node's pod cidr.
kube_router_peer_router_asns: ~

# The ip address of the external router to which all nodes will peer and advertise the cluster ip and pod cidr's.
kube_router_peer_router_ips: ~

# The remote port of the external BGP to which all nodes will peer. If not set, default BGP port (179) will be used.
kube_router_peer_router_ports: ~

# Setups node CNI to allow hairpin mode, requires node reboots, see
# https://github.com/cloudnativelabs/kube-router/blob/master/docs/user-guide.md#hairpin-mode
kube_router_support_hairpin_mode: false

# Select DNS Policy ClusterFirstWithHostNet, ClusterFirst, etc.
kube_router_dns_policy: ClusterFirstWithHostNet

# Adds annotations to kubernetes nodes for advanced configuration of BGP Peers.
# https://github.com/cloudnativelabs/kube-router/blob/master/docs/bgp.md

# Array of annotations for master
kube_router_annotations_master: []

# Array of annotations for every node
kube_router_annotations_node: []

# Array of common annotations for every node
kube_router_annotations_all: []

# Enables scraping kube-router metrics with Prometheus
kube_router_enable_metrics: false

# Path to serve Prometheus metrics on
kube_router_metrics_path: /metrics

# Prometheus metrics port to use
kube_router_metrics_port: 9255

## roles/network_plugin/macvlan/defaults/main.yml <==
---
macvlan_interface: eth0
enable_nat_default_gateway: true

# sysctl_file_path to add sysctl conf to
sysctl_file_path: "/etc/sysctl.d/99-sysctl.conf"

## roles/network_plugin/multus/defaults/main.yml <==
---
multus_conf_file: "auto"
multus_cni_conf_dir_host: "/etc/cni/net.d"
multus_cni_bin_dir_host: "/opt/cni/bin"
multus_cni_run_dir_host: "/run"
multus_cni_conf_dir: "{{ ('/host', multus_cni_conf_dir_host) | join }}"
multus_cni_bin_dir: "{{ ('/host', multus_cni_bin_dir_host) | join }}"
multus_cni_run_dir: "{{ ('/host', multus_cni_run_dir_host) | join }}"
multus_kubeconfig_file_host: "{{ (multus_cni_conf_dir_host, '/multus.d/multus.kubeconfig') | join }}"
multus_namespace_isolation: false

## roles/network_plugin/weave/defaults/main.yml <==
---

# Weave's network password for encryption, if null then no network encryption.
weave_password: ~

# If set to 1, disable checking for new Weave Net versions (default is blank,
# i.e. check is enabled)
weave_checkpoint_disable: false

# Soft limit on the number of connections between peers. Defaults to 100.
weave_conn_limit: 100

# Weave Net defaults to enabling hairpin on the bridge side of the veth pair
# for containers attached. If you need to disable hairpin, e.g. your kernel is
# one of those that can panic if hairpin is enabled, then you can disable it by
# setting `HAIRPIN_MODE=false`.
weave_hairpin_mode: true

# The range of IP addresses used by Weave Net and the subnet they are placed in
# (CIDR format; default 10.32.0.0/12)
weave_ipalloc_range: "{{ kube_pods_subnet }}"

# Set to 0 to disable Network Policy Controller (default is on)
weave_expect_npc: "{{ enable_network_policy }}"

# List of addresses of peers in the Kubernetes cluster (default is to fetch the
# list from the api-server)
weave_kube_peers: ~

# Set the initialization mode of the IP Address Manager (defaults to consensus
# amongst the KUBE_PEERS)
weave_ipalloc_init: ~

# Set the IP address used as a gateway from the Weave network to the host
# network - this is useful if you are configuring the addon as a static pod.
weave_expose_ip: ~

# Address and port that the Weave Net daemon will serve Prometheus-style
# metrics on (defaults to 0.0.0.0:6782)
weave_metrics_addr: ~

# Address and port that the Weave Net daemon will serve status requests on
# (defaults to disabled)
weave_status_addr: ~

# Weave Net defaults to 1376 bytes, but you can set a smaller size if your
# underlying network has a tighter limit, or set a larger size for better
# performance if your network supports jumbo frames (e.g. 8916)
weave_mtu: 1376

# Set to 1 to preserve the client source IP address when accessing Service
# annotated with `service.spec.externalTrafficPolicy=Local`. The feature works
# only with Weave IPAM (default).
weave_no_masq_local: true

# set to nft to use nftables backend for iptables (default is iptables)
weave_iptables_backend: ~

# Extra variables that passing to launch.sh, useful for enabling seed mode, see
# https://www.weave.works/docs/net/latest/tasks/ipam/ipam/
weave_extra_args: ~

# Extra variables for weave_npc that passing to launch.sh, useful for change log level, ex --log-level=error
weave_npc_extra_args: ~

## roles/recover_control_plane/control-plane/defaults/main.yml <==
---
bin_dir: /usr/local/bin

## roles/remove-node/post-remove/defaults/main.yml <==
---
delete_node_retries: 10
delete_node_delay_seconds: 3

## roles/remove-node/pre-remove/defaults/main.yml <==
---
allow_ungraceful_removal: false
drain_grace_period: 300
drain_timeout: 360s
drain_retries: 3
drain_retry_delay_seconds: 10

## roles/reset/defaults/main.yml <==
---
flush_iptables: true
reset_restart_network: true

# crictl stop container grace period
cri_stop_containers_grace_period: 0

## roles/upgrade/post-upgrade/defaults/main.yml <==
---
# how long to wait for cilium after upgrade before uncordoning
upgrade_post_cilium_wait_timeout: 120s
upgrade_node_post_upgrade_confirm: false
upgrade_node_post_upgrade_pause_seconds: 0

## roles/upgrade/pre-upgrade/defaults/main.yml <==
---
drain_grace_period: 300
drain_timeout: 360s
drain_pod_selector: ""
drain_nodes: true
drain_retries: 3
drain_retry_delay_seconds: 10

drain_fallback_enabled: false
drain_fallback_grace_period: 300
drain_fallback_timeout: 360s
drain_fallback_retries: 0
drain_fallback_retry_delay_seconds: 10

upgrade_node_always_cordon: false
upgrade_node_uncordon_after_drain_failure: true
upgrade_node_fail_if_drain_fails: true

upgrade_node_confirm: false
upgrade_node_pause_seconds: 0

## roles/win_nodes/kubernetes_patch/defaults/main.yml <==
---

kubernetes_user_manifests_path: "{{ ansible_env.HOME }}/kube-manifests"
kube_proxy_nodeselector: "kubernetes.io/os"
